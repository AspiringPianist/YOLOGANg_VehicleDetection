{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ofokP3UXC9d",
        "outputId": "5e192fb4-74ae-4ef1-a407-bb1207d5392d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GETTING DATASET AND YAML (DATASET FIXED FOR WRONG LABELLINGS MANUALLY)"
      ],
      "metadata": {
        "id": "fYUg1ISY4FrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id \"10O-6uKWup9sCL3YoTOHox14w85WHnWzJ\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--rEOkPrX5Px",
        "outputId": "a3653916-fbfe-4b02-dc3d-021465b82de7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=10O-6uKWup9sCL3YoTOHox14w85WHnWzJ\n",
            "From (redirected): https://drive.google.com/uc?id=10O-6uKWup9sCL3YoTOHox14w85WHnWzJ&confirm=t&uuid=b3471d01-fbeb-4747-8781-108983005cff\n",
            "To: /content/dataset.zip\n",
            "100% 573M/573M [00:08<00:00, 70.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id \"1xX_bCZdtL4HLd8tFXo7cRf1FeZPxJAy_\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTSg_fWwYHkQ",
        "outputId": "7f048696-3ce5-4528-b517-f7fcf979455a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xX_bCZdtL4HLd8tFXo7cRf1FeZPxJAy_\n",
            "To: /content/data.yaml\n",
            "100% 265/265 [00:00<00:00, 1.30MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9kLNzx9YPrq",
        "outputId": "d8e82cbf-4ab9-4e42-ebaa-db5e2f95be02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: /content/dataset/images/train\r\n",
            "val: /content/dataset/images/val\r\n",
            "\r\n",
            "nc: 14\r\n",
            "names:\r\n",
            "  [\r\n",
            "    car,\r\n",
            "    bike,\r\n",
            "    auto,\r\n",
            "    rickshaw,\r\n",
            "    cycle,\r\n",
            "    bus,\r\n",
            "    minitruck,\r\n",
            "    truck,\r\n",
            "    van,\r\n",
            "    taxi,\r\n",
            "    motorvan,\r\n",
            "    toto,\r\n",
            "    train,\r\n",
            "    boat,\r\n",
            "  ]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset.zip\n",
        "!pip install ultralytics optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naXze7pIYSX4",
        "outputId": "e2327eb6-28df-472b-ff22-c4a653f59046"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: dataset/images/train/rainy day (134).jpg  \n",
            "  inflating: dataset/images/train/rainy day (135).jpg  \n",
            "  inflating: dataset/images/train/rainy day (136).jpg  \n",
            "  inflating: dataset/images/train/rainy day (137).jpg  \n",
            "  inflating: dataset/images/train/rainy day (138).jpg  \n",
            "  inflating: dataset/images/train/rainy day (139).jpg  \n",
            "  inflating: dataset/images/train/rainy day (14).jpg  \n",
            "  inflating: dataset/images/train/rainy day (140).jpg  \n",
            "  inflating: dataset/images/train/rainy day (141).jpg  \n",
            "  inflating: dataset/images/train/rainy day (142).jpg  \n",
            "  inflating: dataset/images/train/rainy day (143).jpg  \n",
            "  inflating: dataset/images/train/rainy day (144).jpg  \n",
            "  inflating: dataset/images/train/rainy day (145).jpg  \n",
            "  inflating: dataset/images/train/rainy day (146).jpg  \n",
            "  inflating: dataset/images/train/rainy day (147).jpg  \n",
            "  inflating: dataset/images/train/rainy day (148).jpg  \n",
            "  inflating: dataset/images/train/rainy day (149).jpg  \n",
            "  inflating: dataset/images/train/rainy day (15).jpg  \n",
            "  inflating: dataset/images/train/rainy day (150).jpg  \n",
            "  inflating: dataset/images/train/rainy day (151).jpg  \n",
            "  inflating: dataset/images/train/rainy day (152).jpg  \n",
            "  inflating: dataset/images/train/rainy day (153).jpg  \n",
            "  inflating: dataset/images/train/rainy day (154).jpg  \n",
            "  inflating: dataset/images/train/rainy day (155).jpg  \n",
            "  inflating: dataset/images/train/rainy day (156).jpg  \n",
            "  inflating: dataset/images/train/rainy day (157).jpg  \n",
            "  inflating: dataset/images/train/rainy day (158).jpg  \n",
            "  inflating: dataset/images/train/rainy day (159).jpg  \n",
            "  inflating: dataset/images/train/rainy day (16).jpg  \n",
            "  inflating: dataset/images/train/rainy day (160).jpg  \n",
            "  inflating: dataset/images/train/rainy day (161).jpg  \n",
            "  inflating: dataset/images/train/rainy day (162).jpg  \n",
            "  inflating: dataset/images/train/rainy day (163).jpg  \n",
            "  inflating: dataset/images/train/rainy day (164).jpg  \n",
            "  inflating: dataset/images/train/rainy day (165).jpg  \n",
            "  inflating: dataset/images/train/rainy day (166).jpg  \n",
            "  inflating: dataset/images/train/rainy day (167).jpg  \n",
            "  inflating: dataset/images/train/rainy day (168).jpg  \n",
            "  inflating: dataset/images/train/rainy day (169).jpg  \n",
            "  inflating: dataset/images/train/rainy day (17).jpg  \n",
            "  inflating: dataset/images/train/rainy day (170).jpg  \n",
            "  inflating: dataset/images/train/rainy day (171).jpg  \n",
            "  inflating: dataset/images/train/rainy day (172).jpg  \n",
            "  inflating: dataset/images/train/rainy day (173).jpg  \n",
            "  inflating: dataset/images/train/rainy day (174).jpg  \n",
            "  inflating: dataset/images/train/rainy day (175).jpg  \n",
            "  inflating: dataset/images/train/rainy day (176).jpg  \n",
            "  inflating: dataset/images/train/rainy day (177).jpg  \n",
            "  inflating: dataset/images/train/rainy day (178).jpg  \n",
            "  inflating: dataset/images/train/rainy day (179).jpg  \n",
            "  inflating: dataset/images/train/rainy day (18).jpg  \n",
            "  inflating: dataset/images/train/rainy day (180).jpg  \n",
            "  inflating: dataset/images/train/rainy day (181).jpg  \n",
            "  inflating: dataset/images/train/rainy day (182).jpg  \n",
            "  inflating: dataset/images/train/rainy day (183).jpg  \n",
            "  inflating: dataset/images/train/rainy day (184).jpg  \n",
            "  inflating: dataset/images/train/rainy day (185).jpg  \n",
            "  inflating: dataset/images/train/rainy day (186).jpg  \n",
            "  inflating: dataset/images/train/rainy day (187).jpg  \n",
            "  inflating: dataset/images/train/rainy day (188).jpg  \n",
            "  inflating: dataset/images/train/rainy day (189).jpg  \n",
            "  inflating: dataset/images/train/rainy day (19).jpg  \n",
            "  inflating: dataset/images/train/rainy day (190).jpg  \n",
            "  inflating: dataset/images/train/rainy day (191).jpg  \n",
            "  inflating: dataset/images/train/rainy day (192).jpg  \n",
            "  inflating: dataset/images/train/rainy day (193).jpg  \n",
            "  inflating: dataset/images/train/rainy day (194).jpg  \n",
            "  inflating: dataset/images/train/rainy day (195).jpg  \n",
            "  inflating: dataset/images/train/rainy day (196).jpg  \n",
            "  inflating: dataset/images/train/rainy day (197).jpg  \n",
            "  inflating: dataset/images/train/rainy day (198).jpg  \n",
            "  inflating: dataset/images/train/rainy day (199).jpg  \n",
            "  inflating: dataset/images/train/rainy day (2).jpg  \n",
            "  inflating: dataset/images/train/rainy day (20).jpg  \n",
            "  inflating: dataset/images/train/rainy day (200).jpg  \n",
            "  inflating: dataset/images/train/rainy day (201).jpg  \n",
            "  inflating: dataset/images/train/rainy day (202).jpg  \n",
            "  inflating: dataset/images/train/rainy day (203).jpg  \n",
            "  inflating: dataset/images/train/rainy day (204).jpg  \n",
            "  inflating: dataset/images/train/rainy day (205).jpg  \n",
            "  inflating: dataset/images/train/rainy day (206).jpg  \n",
            "  inflating: dataset/images/train/rainy day (207).jpg  \n",
            "  inflating: dataset/images/train/rainy day (208).jpg  \n",
            "  inflating: dataset/images/train/rainy day (209).jpg  \n",
            "  inflating: dataset/images/train/rainy day (21).jpg  \n",
            "  inflating: dataset/images/train/rainy day (210).jpg  \n",
            "  inflating: dataset/images/train/rainy day (211).jpg  \n",
            "  inflating: dataset/images/train/rainy day (212).jpg  \n",
            "  inflating: dataset/images/train/rainy day (213).jpg  \n",
            "  inflating: dataset/images/train/rainy day (214).jpg  \n",
            "  inflating: dataset/images/train/rainy day (215).jpg  \n",
            "  inflating: dataset/images/train/rainy day (216).jpg  \n",
            "  inflating: dataset/images/train/rainy day (217).jpg  \n",
            "  inflating: dataset/images/train/rainy day (218).jpg  \n",
            "  inflating: dataset/images/train/rainy day (219).jpg  \n",
            "  inflating: dataset/images/train/rainy day (22).jpg  \n",
            "  inflating: dataset/images/train/rainy day (220).jpg  \n",
            "  inflating: dataset/images/train/rainy day (221).jpg  \n",
            "  inflating: dataset/images/train/rainy day (222).jpg  \n",
            "  inflating: dataset/images/train/rainy day (223).jpg  \n",
            "  inflating: dataset/images/train/rainy day (224).jpg  \n",
            "  inflating: dataset/images/train/rainy day (225).jpg  \n",
            "  inflating: dataset/images/train/rainy day (226).jpg  \n",
            "  inflating: dataset/images/train/rainy day (227).jpg  \n",
            "  inflating: dataset/images/train/rainy day (228).jpg  \n",
            "  inflating: dataset/images/train/rainy day (229).jpg  \n",
            "  inflating: dataset/images/train/rainy day (23).jpg  \n",
            "  inflating: dataset/images/train/rainy day (230).jpg  \n",
            "  inflating: dataset/images/train/rainy day (231).jpg  \n",
            "  inflating: dataset/images/train/rainy day (232).jpg  \n",
            "  inflating: dataset/images/train/rainy day (233).jpg  \n",
            "  inflating: dataset/images/train/rainy day (234).jpg  \n",
            "  inflating: dataset/images/train/rainy day (235).jpg  \n",
            "  inflating: dataset/images/train/rainy day (236).jpg  \n",
            "  inflating: dataset/images/train/rainy day (237).jpg  \n",
            "  inflating: dataset/images/train/rainy day (238).jpg  \n",
            "  inflating: dataset/images/train/rainy day (239).jpg  \n",
            "  inflating: dataset/images/train/rainy day (24).jpg  \n",
            "  inflating: dataset/images/train/rainy day (240).jpg  \n",
            "  inflating: dataset/images/train/rainy day (241).jpg  \n",
            "  inflating: dataset/images/train/rainy day (242).jpg  \n",
            "  inflating: dataset/images/train/rainy day (243).jpg  \n",
            "  inflating: dataset/images/train/rainy day (244).jpg  \n",
            "  inflating: dataset/images/train/rainy day (245).jpg  \n",
            "  inflating: dataset/images/train/rainy day (246).jpg  \n",
            "  inflating: dataset/images/train/rainy day (247).jpg  \n",
            "  inflating: dataset/images/train/rainy day (248).jpg  \n",
            "  inflating: dataset/images/train/rainy day (249).jpg  \n",
            "  inflating: dataset/images/train/rainy day (25).jpg  \n",
            "  inflating: dataset/images/train/rainy day (250).jpg  \n",
            "  inflating: dataset/images/train/rainy day (251).jpg  \n",
            "  inflating: dataset/images/train/rainy day (252).jpg  \n",
            "  inflating: dataset/images/train/rainy day (253).jpg  \n",
            "  inflating: dataset/images/train/rainy day (254).jpg  \n",
            "  inflating: dataset/images/train/rainy day (255).jpg  \n",
            "  inflating: dataset/images/train/rainy day (256).jpg  \n",
            "  inflating: dataset/images/train/rainy day (257).jpg  \n",
            "  inflating: dataset/images/train/rainy day (258).jpg  \n",
            "  inflating: dataset/images/train/rainy day (259).jpg  \n",
            "  inflating: dataset/images/train/rainy day (26).jpg  \n",
            "  inflating: dataset/images/train/rainy day (260).jpg  \n",
            "  inflating: dataset/images/train/rainy day (261).jpg  \n",
            "  inflating: dataset/images/train/rainy day (262).jpg  \n",
            "  inflating: dataset/images/train/rainy day (263).jpg  \n",
            "  inflating: dataset/images/train/rainy day (264).jpg  \n",
            "  inflating: dataset/images/train/rainy day (265).jpg  \n",
            "  inflating: dataset/images/train/rainy day (266).jpg  \n",
            "  inflating: dataset/images/train/rainy day (267).jpg  \n",
            "  inflating: dataset/images/train/rainy day (268).jpg  \n",
            "  inflating: dataset/images/train/rainy day (269).jpg  \n",
            "  inflating: dataset/images/train/rainy day (27).jpg  \n",
            "  inflating: dataset/images/train/rainy day (270).jpg  \n",
            "  inflating: dataset/images/train/rainy day (271).jpg  \n",
            "  inflating: dataset/images/train/rainy day (272).jpg  \n",
            "  inflating: dataset/images/train/rainy day (273).jpg  \n",
            "  inflating: dataset/images/train/rainy day (274).jpg  \n",
            "  inflating: dataset/images/train/rainy day (275).jpg  \n",
            "  inflating: dataset/images/train/rainy day (276).jpg  \n",
            "  inflating: dataset/images/train/rainy day (277).jpg  \n",
            "  inflating: dataset/images/train/rainy day (278).jpg  \n",
            "  inflating: dataset/images/train/rainy day (279).jpg  \n",
            "  inflating: dataset/images/train/rainy day (28).jpg  \n",
            "  inflating: dataset/images/train/rainy day (280).jpg  \n",
            "  inflating: dataset/images/train/rainy day (281).jpg  \n",
            "  inflating: dataset/images/train/rainy day (282).jpg  \n",
            "  inflating: dataset/images/train/rainy day (283).jpg  \n",
            "  inflating: dataset/images/train/rainy day (284).jpg  \n",
            "  inflating: dataset/images/train/rainy day (285).jpg  \n",
            "  inflating: dataset/images/train/rainy day (286).jpg  \n",
            "  inflating: dataset/images/train/rainy day (287).jpg  \n",
            "  inflating: dataset/images/train/rainy day (288).jpg  \n",
            "  inflating: dataset/images/train/rainy day (289).jpg  \n",
            "  inflating: dataset/images/train/rainy day (29).jpg  \n",
            "  inflating: dataset/images/train/rainy day (290).jpg  \n",
            "  inflating: dataset/images/train/rainy day (291).jpg  \n",
            "  inflating: dataset/images/train/rainy day (292).jpg  \n",
            "  inflating: dataset/images/train/rainy day (293).jpg  \n",
            "  inflating: dataset/images/train/rainy day (294).jpg  \n",
            "  inflating: dataset/images/train/rainy day (295).jpg  \n",
            "  inflating: dataset/images/train/rainy day (296).jpg  \n",
            "  inflating: dataset/images/train/rainy day (297).jpg  \n",
            "  inflating: dataset/images/train/rainy day (298).jpg  \n",
            "  inflating: dataset/images/train/rainy day (299).jpg  \n",
            "  inflating: dataset/images/train/rainy day (3).jpg  \n",
            "  inflating: dataset/images/train/rainy day (30).jpg  \n",
            "  inflating: dataset/images/train/rainy day (300).jpg  \n",
            "  inflating: dataset/images/train/rainy day (301).jpg  \n",
            "  inflating: dataset/images/train/rainy day (302).jpg  \n",
            "  inflating: dataset/images/train/rainy day (303).jpg  \n",
            "  inflating: dataset/images/train/rainy day (304).jpg  \n",
            "  inflating: dataset/images/train/rainy day (305).jpg  \n",
            "  inflating: dataset/images/train/rainy day (306).jpg  \n",
            "  inflating: dataset/images/train/rainy day (307).jpg  \n",
            "  inflating: dataset/images/train/rainy day (308).jpg  \n",
            "  inflating: dataset/images/train/rainy day (309).jpg  \n",
            "  inflating: dataset/images/train/rainy day (31).jpg  \n",
            "  inflating: dataset/images/train/rainy day (310).jpg  \n",
            "  inflating: dataset/images/train/rainy day (311).jpg  \n",
            "  inflating: dataset/images/train/rainy day (312).jpg  \n",
            "  inflating: dataset/images/train/rainy day (313).jpg  \n",
            "  inflating: dataset/images/train/rainy day (314).jpg  \n",
            "  inflating: dataset/images/train/rainy day (315).jpg  \n",
            "  inflating: dataset/images/train/rainy day (316).jpg  \n",
            "  inflating: dataset/images/train/rainy day (317).jpg  \n",
            "  inflating: dataset/images/train/rainy day (318).jpg  \n",
            "  inflating: dataset/images/train/rainy day (319).jpg  \n",
            "  inflating: dataset/images/train/rainy day (32).jpg  \n",
            "  inflating: dataset/images/train/rainy day (320).jpg  \n",
            "  inflating: dataset/images/train/rainy day (321).jpg  \n",
            "  inflating: dataset/images/train/rainy day (322).jpg  \n",
            "  inflating: dataset/images/train/rainy day (323).jpg  \n",
            "  inflating: dataset/images/train/rainy day (324).jpg  \n",
            "  inflating: dataset/images/train/rainy day (325).jpg  \n",
            "  inflating: dataset/images/train/rainy day (326).jpg  \n",
            "  inflating: dataset/images/train/rainy day (327).jpg  \n",
            "  inflating: dataset/images/train/rainy day (328).jpg  \n",
            "  inflating: dataset/images/train/rainy day (329).jpg  \n",
            "  inflating: dataset/images/train/rainy day (33).jpg  \n",
            "  inflating: dataset/images/train/rainy day (330).jpg  \n",
            "  inflating: dataset/images/train/rainy day (331).jpg  \n",
            "  inflating: dataset/images/train/rainy day (332).jpg  \n",
            "  inflating: dataset/images/train/rainy day (333).jpg  \n",
            "  inflating: dataset/images/train/rainy day (334).jpg  \n",
            "  inflating: dataset/images/train/rainy day (335).jpg  \n",
            "  inflating: dataset/images/train/rainy day (336).jpg  \n",
            "  inflating: dataset/images/train/rainy day (337).jpg  \n",
            "  inflating: dataset/images/train/rainy day (338).jpg  \n",
            "  inflating: dataset/images/train/rainy day (339).jpg  \n",
            "  inflating: dataset/images/train/rainy day (34).jpg  \n",
            "  inflating: dataset/images/train/rainy day (340).jpg  \n",
            "  inflating: dataset/images/train/rainy day (341).jpg  \n",
            "  inflating: dataset/images/train/rainy day (342).jpg  \n",
            "  inflating: dataset/images/train/rainy day (343).jpg  \n",
            "  inflating: dataset/images/train/rainy day (344).jpg  \n",
            "  inflating: dataset/images/train/rainy day (345).jpg  \n",
            "  inflating: dataset/images/train/rainy day (346).jpg  \n",
            "  inflating: dataset/images/train/rainy day (347).jpg  \n",
            "  inflating: dataset/images/train/rainy day (348).jpg  \n",
            "  inflating: dataset/images/train/rainy day (349).jpg  \n",
            "  inflating: dataset/images/train/rainy day (35).jpg  \n",
            "  inflating: dataset/images/train/rainy day (350).jpg  \n",
            "  inflating: dataset/images/train/rainy day (351).jpg  \n",
            "  inflating: dataset/images/train/rainy day (352).jpg  \n",
            "  inflating: dataset/images/train/rainy day (353).jpg  \n",
            "  inflating: dataset/images/train/rainy day (354).jpg  \n",
            "  inflating: dataset/images/train/rainy day (355).jpg  \n",
            "  inflating: dataset/images/train/rainy day (356).jpg  \n",
            "  inflating: dataset/images/train/rainy day (357).jpg  \n",
            "  inflating: dataset/images/train/rainy day (358).jpg  \n",
            "  inflating: dataset/images/train/rainy day (359).jpg  \n",
            "  inflating: dataset/images/train/rainy day (36).jpg  \n",
            "  inflating: dataset/images/train/rainy day (360).jpg  \n",
            "  inflating: dataset/images/train/rainy day (361).jpg  \n",
            "  inflating: dataset/images/train/rainy day (362).jpg  \n",
            "  inflating: dataset/images/train/rainy day (363).jpg  \n",
            "  inflating: dataset/images/train/rainy day (364).jpg  \n",
            "  inflating: dataset/images/train/rainy day (365).jpg  \n",
            "  inflating: dataset/images/train/rainy day (366).jpg  \n",
            "  inflating: dataset/images/train/rainy day (367).jpg  \n",
            "  inflating: dataset/images/train/rainy day (368).jpg  \n",
            "  inflating: dataset/images/train/rainy day (369).jpg  \n",
            "  inflating: dataset/images/train/rainy day (37).jpg  \n",
            "  inflating: dataset/images/train/rainy day (370).jpg  \n",
            "  inflating: dataset/images/train/rainy day (371).jpg  \n",
            "  inflating: dataset/images/train/rainy day (372).jpg  \n",
            "  inflating: dataset/images/train/rainy day (373).jpg  \n",
            "  inflating: dataset/images/train/rainy day (374).jpg  \n",
            "  inflating: dataset/images/train/rainy day (375).jpg  \n",
            "  inflating: dataset/images/train/rainy day (376).jpg  \n",
            "  inflating: dataset/images/train/rainy day (377).jpg  \n",
            "  inflating: dataset/images/train/rainy day (378).jpg  \n",
            "  inflating: dataset/images/train/rainy day (379).jpg  \n",
            "  inflating: dataset/images/train/rainy day (38).jpg  \n",
            "  inflating: dataset/images/train/rainy day (380).jpg  \n",
            "  inflating: dataset/images/train/rainy day (381).jpg  \n",
            "  inflating: dataset/images/train/rainy day (382).jpg  \n",
            "  inflating: dataset/images/train/rainy day (383).jpg  \n",
            "  inflating: dataset/images/train/rainy day (384).jpg  \n",
            "  inflating: dataset/images/train/rainy day (385).jpg  \n",
            "  inflating: dataset/images/train/rainy day (386).jpg  \n",
            "  inflating: dataset/images/train/rainy day (387).jpg  \n",
            "  inflating: dataset/images/train/rainy day (388).jpg  \n",
            "  inflating: dataset/images/train/rainy day (389).jpg  \n",
            "  inflating: dataset/images/train/rainy day (39).jpg  \n",
            "  inflating: dataset/images/train/rainy day (390).jpg  \n",
            "  inflating: dataset/images/train/rainy day (391).jpg  \n",
            "  inflating: dataset/images/train/rainy day (392).jpg  \n",
            "  inflating: dataset/images/train/rainy day (393).jpg  \n",
            "  inflating: dataset/images/train/rainy day (394).jpg  \n",
            "  inflating: dataset/images/train/rainy day (395).jpg  \n",
            "  inflating: dataset/images/train/rainy day (396).jpg  \n",
            "  inflating: dataset/images/train/rainy day (397).jpg  \n",
            "  inflating: dataset/images/train/rainy day (398).jpg  \n",
            "  inflating: dataset/images/train/rainy day (399).jpg  \n",
            "  inflating: dataset/images/train/rainy day (4).jpg  \n",
            "  inflating: dataset/images/train/rainy day (40).jpg  \n",
            "  inflating: dataset/images/train/rainy day (400).jpg  \n",
            "  inflating: dataset/images/train/rainy day (401).jpg  \n",
            "  inflating: dataset/images/train/rainy day (402).jpg  \n",
            "  inflating: dataset/images/train/rainy day (403).jpg  \n",
            "  inflating: dataset/images/train/rainy day (404).jpg  \n",
            "  inflating: dataset/images/train/rainy day (405).jpg  \n",
            "  inflating: dataset/images/train/rainy day (406).jpg  \n",
            "  inflating: dataset/images/train/rainy day (407).jpg  \n",
            "  inflating: dataset/images/train/rainy day (408).jpg  \n",
            "  inflating: dataset/images/train/rainy day (409).jpg  \n",
            "  inflating: dataset/images/train/rainy day (41).jpg  \n",
            "  inflating: dataset/images/train/rainy day (410).jpg  \n",
            "  inflating: dataset/images/train/rainy day (411).jpg  \n",
            "  inflating: dataset/images/train/rainy day (412).jpg  \n",
            "  inflating: dataset/images/train/rainy day (413).jpg  \n",
            "  inflating: dataset/images/train/rainy day (414).jpg  \n",
            "  inflating: dataset/images/train/rainy day (415).jpg  \n",
            "  inflating: dataset/images/train/rainy day (416).jpg  \n",
            "  inflating: dataset/images/train/rainy day (417).jpg  \n",
            "  inflating: dataset/images/train/rainy day (418).jpg  \n",
            "  inflating: dataset/images/train/rainy day (419).jpg  \n",
            "  inflating: dataset/images/train/rainy day (42).jpg  \n",
            "  inflating: dataset/images/train/rainy day (420).jpg  \n",
            "  inflating: dataset/images/train/rainy day (421).jpg  \n",
            "  inflating: dataset/images/train/rainy day (422).jpg  \n",
            "  inflating: dataset/images/train/rainy day (423).jpg  \n",
            "  inflating: dataset/images/train/rainy day (424).jpg  \n",
            "  inflating: dataset/images/train/rainy day (425).jpg  \n",
            "  inflating: dataset/images/train/rainy day (426).jpg  \n",
            "  inflating: dataset/images/train/rainy day (427).jpg  \n",
            "  inflating: dataset/images/train/rainy day (428).jpg  \n",
            "  inflating: dataset/images/train/rainy day (429).jpg  \n",
            "  inflating: dataset/images/train/rainy day (43).jpg  \n",
            "  inflating: dataset/images/train/rainy day (430).jpg  \n",
            "  inflating: dataset/images/train/rainy day (431).jpg  \n",
            "  inflating: dataset/images/train/rainy day (432).jpg  \n",
            "  inflating: dataset/images/train/rainy day (433).jpg  \n",
            "  inflating: dataset/images/train/rainy day (434).jpg  \n",
            "  inflating: dataset/images/train/rainy day (435).jpg  \n",
            "  inflating: dataset/images/train/rainy day (436).jpg  \n",
            "  inflating: dataset/images/train/rainy day (437).jpg  \n",
            "  inflating: dataset/images/train/rainy day (438).jpg  \n",
            "  inflating: dataset/images/train/rainy day (439).jpg  \n",
            "  inflating: dataset/images/train/rainy day (44).jpg  \n",
            "  inflating: dataset/images/train/rainy day (440).jpg  \n",
            "  inflating: dataset/images/train/rainy day (441).jpg  \n",
            "  inflating: dataset/images/train/rainy day (442).jpg  \n",
            "  inflating: dataset/images/train/rainy day (443).jpg  \n",
            "  inflating: dataset/images/train/rainy day (444).jpg  \n",
            "  inflating: dataset/images/train/rainy day (445).jpg  \n",
            "  inflating: dataset/images/train/rainy day (446).jpg  \n",
            "  inflating: dataset/images/train/rainy day (447).jpg  \n",
            "  inflating: dataset/images/train/rainy day (448).jpg  \n",
            "  inflating: dataset/images/train/rainy day (449).jpg  \n",
            "  inflating: dataset/images/train/rainy day (45).jpg  \n",
            "  inflating: dataset/images/train/rainy day (450).jpg  \n",
            "  inflating: dataset/images/train/rainy day (451).jpg  \n",
            "  inflating: dataset/images/train/rainy day (452).jpg  \n",
            "  inflating: dataset/images/train/rainy day (453).jpg  \n",
            "  inflating: dataset/images/train/rainy day (454).jpg  \n",
            "  inflating: dataset/images/train/rainy day (455).jpg  \n",
            "  inflating: dataset/images/train/rainy day (456).jpg  \n",
            "  inflating: dataset/images/train/rainy day (457).jpg  \n",
            "  inflating: dataset/images/train/rainy day (458).jpg  \n",
            "  inflating: dataset/images/train/rainy day (459).jpg  \n",
            "  inflating: dataset/images/train/rainy day (46).jpg  \n",
            "  inflating: dataset/images/train/rainy day (460).jpg  \n",
            "  inflating: dataset/images/train/rainy day (461).jpg  \n",
            "  inflating: dataset/images/train/rainy day (462).jpg  \n",
            "  inflating: dataset/images/train/rainy day (463).jpg  \n",
            "  inflating: dataset/images/train/rainy day (464).jpg  \n",
            "  inflating: dataset/images/train/rainy day (465).jpg  \n",
            "  inflating: dataset/images/train/rainy day (466).jpg  \n",
            "  inflating: dataset/images/train/rainy day (467).jpg  \n",
            "  inflating: dataset/images/train/rainy day (468).jpg  \n",
            "  inflating: dataset/images/train/rainy day (469).jpg  \n",
            "  inflating: dataset/images/train/rainy day (47).jpg  \n",
            "  inflating: dataset/images/train/rainy day (470).jpg  \n",
            "  inflating: dataset/images/train/rainy day (471).jpg  \n",
            "  inflating: dataset/images/train/rainy day (472).jpg  \n",
            "  inflating: dataset/images/train/rainy day (473).jpg  \n",
            "  inflating: dataset/images/train/rainy day (474).jpg  \n",
            "  inflating: dataset/images/train/rainy day (475).jpg  \n",
            "  inflating: dataset/images/train/rainy day (476).jpg  \n",
            "  inflating: dataset/images/train/rainy day (477).jpg  \n",
            "  inflating: dataset/images/train/rainy day (478).jpg  \n",
            "  inflating: dataset/images/train/rainy day (479).jpg  \n",
            "  inflating: dataset/images/train/rainy day (48).jpg  \n",
            "  inflating: dataset/images/train/rainy day (480).jpg  \n",
            "  inflating: dataset/images/train/rainy day (481).jpg  \n",
            "  inflating: dataset/images/train/rainy day (482).jpg  \n",
            "  inflating: dataset/images/train/rainy day (483).jpg  \n",
            "  inflating: dataset/images/train/rainy day (484).jpg  \n",
            "  inflating: dataset/images/train/rainy day (485).jpg  \n",
            "  inflating: dataset/images/train/rainy day (486).jpg  \n",
            "  inflating: dataset/images/train/rainy day (487).jpg  \n",
            "  inflating: dataset/images/train/rainy day (488).jpg  \n",
            "  inflating: dataset/images/train/rainy day (489).jpg  \n",
            "  inflating: dataset/images/train/rainy day (49).jpg  \n",
            "  inflating: dataset/images/train/rainy day (490).jpg  \n",
            "  inflating: dataset/images/train/rainy day (491).jpg  \n",
            "  inflating: dataset/images/train/rainy day (492).jpg  \n",
            "  inflating: dataset/images/train/rainy day (493).jpg  \n",
            "  inflating: dataset/images/train/rainy day (494).jpg  \n",
            "  inflating: dataset/images/train/rainy day (495).jpg  \n",
            "  inflating: dataset/images/train/rainy day (496).jpg  \n",
            "  inflating: dataset/images/train/rainy day (497).jpg  \n",
            "  inflating: dataset/images/train/rainy day (498).jpg  \n",
            "  inflating: dataset/images/train/rainy day (499).jpg  \n",
            "  inflating: dataset/images/train/rainy day (5).jpg  \n",
            "  inflating: dataset/images/train/rainy day (50).jpg  \n",
            "  inflating: dataset/images/train/rainy day (500).jpg  \n",
            "  inflating: dataset/images/train/rainy day (501).jpg  \n",
            "  inflating: dataset/images/train/rainy day (502).jpg  \n",
            "  inflating: dataset/images/train/rainy day (503).jpg  \n",
            "  inflating: dataset/images/train/rainy day (504).jpg  \n",
            "  inflating: dataset/images/train/rainy day (505).jpg  \n",
            "  inflating: dataset/images/train/rainy day (506).jpg  \n",
            "  inflating: dataset/images/train/rainy day (507).jpg  \n",
            "  inflating: dataset/images/train/rainy day (508).jpg  \n",
            "  inflating: dataset/images/train/rainy day (509).jpg  \n",
            "  inflating: dataset/images/train/rainy day (51).jpg  \n",
            "  inflating: dataset/images/train/rainy day (510).jpg  \n",
            "  inflating: dataset/images/train/rainy day (511).jpg  \n",
            "  inflating: dataset/images/train/rainy day (512).jpg  \n",
            "  inflating: dataset/images/train/rainy day (513).jpg  \n",
            "  inflating: dataset/images/train/rainy day (514).jpg  \n",
            "  inflating: dataset/images/train/rainy day (515).jpg  \n",
            "  inflating: dataset/images/train/rainy day (516).jpg  \n",
            "  inflating: dataset/images/train/rainy day (517).jpg  \n",
            "  inflating: dataset/images/train/rainy day (518).jpg  \n",
            "  inflating: dataset/images/train/rainy day (519).jpg  \n",
            "  inflating: dataset/images/train/rainy day (52).jpg  \n",
            "  inflating: dataset/images/train/rainy day (520).jpg  \n",
            "  inflating: dataset/images/train/rainy day (521).jpg  \n",
            "  inflating: dataset/images/train/rainy day (522).jpg  \n",
            "  inflating: dataset/images/train/rainy day (523).jpg  \n",
            "  inflating: dataset/images/train/rainy day (524).jpg  \n",
            "  inflating: dataset/images/train/rainy day (525).jpg  \n",
            "  inflating: dataset/images/train/rainy day (526).jpg  \n",
            "  inflating: dataset/images/train/rainy day (527).jpg  \n",
            "  inflating: dataset/images/train/rainy day (528).jpg  \n",
            "  inflating: dataset/images/train/rainy day (529).jpg  \n",
            "  inflating: dataset/images/train/rainy day (53).jpg  \n",
            "  inflating: dataset/images/train/rainy day (530).jpg  \n",
            "  inflating: dataset/images/train/rainy day (531).jpg  \n",
            "  inflating: dataset/images/train/rainy day (532).jpg  \n",
            "  inflating: dataset/images/train/rainy day (533).jpg  \n",
            "  inflating: dataset/images/train/rainy day (534).jpg  \n",
            "  inflating: dataset/images/train/rainy day (535).jpg  \n",
            "  inflating: dataset/images/train/rainy day (536).jpg  \n",
            "  inflating: dataset/images/train/rainy day (537).jpg  \n",
            "  inflating: dataset/images/train/rainy day (538).jpg  \n",
            "  inflating: dataset/images/train/rainy day (539).jpg  \n",
            "  inflating: dataset/images/train/rainy day (54).jpg  \n",
            "  inflating: dataset/images/train/rainy day (540).jpg  \n",
            "  inflating: dataset/images/train/rainy day (541).jpg  \n",
            "  inflating: dataset/images/train/rainy day (542).jpg  \n",
            "  inflating: dataset/images/train/rainy day (543).jpg  \n",
            "  inflating: dataset/images/train/rainy day (544).jpg  \n",
            "  inflating: dataset/images/train/rainy day (545).jpg  \n",
            "  inflating: dataset/images/train/rainy day (546).jpg  \n",
            "  inflating: dataset/images/train/rainy day (547).jpg  \n",
            "  inflating: dataset/images/train/rainy day (548).jpg  \n",
            "  inflating: dataset/images/train/rainy day (549).jpg  \n",
            "  inflating: dataset/images/train/rainy day (55).jpg  \n",
            "  inflating: dataset/images/train/rainy day (550).jpg  \n",
            "  inflating: dataset/images/train/rainy day (551).jpg  \n",
            "  inflating: dataset/images/train/rainy day (552).jpg  \n",
            "  inflating: dataset/images/train/rainy day (553).jpg  \n",
            "  inflating: dataset/images/train/rainy day (554).jpg  \n",
            "  inflating: dataset/images/train/rainy day (555).jpg  \n",
            "  inflating: dataset/images/train/rainy day (556).jpg  \n",
            "  inflating: dataset/images/train/rainy day (557).jpg  \n",
            "  inflating: dataset/images/train/rainy day (558).jpg  \n",
            "  inflating: dataset/images/train/rainy day (559).jpg  \n",
            "  inflating: dataset/images/train/rainy day (56).jpg  \n",
            "  inflating: dataset/images/train/rainy day (560).jpg  \n",
            "  inflating: dataset/images/train/rainy day (561).jpg  \n",
            "  inflating: dataset/images/train/rainy day (562).jpg  \n",
            "  inflating: dataset/images/train/rainy day (563).jpg  \n",
            "  inflating: dataset/images/train/rainy day (564).jpg  \n",
            "  inflating: dataset/images/train/rainy day (565).jpg  \n",
            "  inflating: dataset/images/train/rainy day (566).jpg  \n",
            "  inflating: dataset/images/train/rainy day (567).jpg  \n",
            "  inflating: dataset/images/train/rainy day (568).jpg  \n",
            "  inflating: dataset/images/train/rainy day (569).jpg  \n",
            "  inflating: dataset/images/train/rainy day (57).jpg  \n",
            "  inflating: dataset/images/train/rainy day (570).jpg  \n",
            "  inflating: dataset/images/train/rainy day (571).jpg  \n",
            "  inflating: dataset/images/train/rainy day (572).jpg  \n",
            "  inflating: dataset/images/train/rainy day (573).jpg  \n",
            "  inflating: dataset/images/train/rainy day (574).jpg  \n",
            "  inflating: dataset/images/train/rainy day (575).jpg  \n",
            "  inflating: dataset/images/train/rainy day (576).jpg  \n",
            "  inflating: dataset/images/train/rainy day (577).jpg  \n",
            "  inflating: dataset/images/train/rainy day (578).jpg  \n",
            "  inflating: dataset/images/train/rainy day (579).jpg  \n",
            "  inflating: dataset/images/train/rainy day (58).jpg  \n",
            "  inflating: dataset/images/train/rainy day (580).jpg  \n",
            "  inflating: dataset/images/train/rainy day (581).jpg  \n",
            "  inflating: dataset/images/train/rainy day (582).jpg  \n",
            "  inflating: dataset/images/train/rainy day (583).jpg  \n",
            "  inflating: dataset/images/train/rainy day (584).jpg  \n",
            "  inflating: dataset/images/train/rainy day (585).jpg  \n",
            "  inflating: dataset/images/train/rainy day (586).jpg  \n",
            "  inflating: dataset/images/train/rainy day (587).jpg  \n",
            "  inflating: dataset/images/train/rainy day (588).jpg  \n",
            "  inflating: dataset/images/train/rainy day (589).jpg  \n",
            "  inflating: dataset/images/train/rainy day (59).jpg  \n",
            "  inflating: dataset/images/train/rainy day (590).jpg  \n",
            "  inflating: dataset/images/train/rainy day (591).jpg  \n",
            "  inflating: dataset/images/train/rainy day (592).jpg  \n",
            "  inflating: dataset/images/train/rainy day (593).jpg  \n",
            "  inflating: dataset/images/train/rainy day (594).jpg  \n",
            "  inflating: dataset/images/train/rainy day (595).jpg  \n",
            "  inflating: dataset/images/train/rainy day (596).jpg  \n",
            "  inflating: dataset/images/train/rainy day (597).jpg  \n",
            "  inflating: dataset/images/train/rainy day (598).jpg  \n",
            "  inflating: dataset/images/train/rainy day (599).jpg  \n",
            "  inflating: dataset/images/train/rainy day (6).jpg  \n",
            "  inflating: dataset/images/train/rainy day (60).jpg  \n",
            "  inflating: dataset/images/train/rainy day (600).jpg  \n",
            "  inflating: dataset/images/train/rainy day (601).jpg  \n",
            "  inflating: dataset/images/train/rainy day (602).jpg  \n",
            "  inflating: dataset/images/train/rainy day (603).jpg  \n",
            "  inflating: dataset/images/train/rainy day (604).jpg  \n",
            "  inflating: dataset/images/train/rainy day (605).jpg  \n",
            "  inflating: dataset/images/train/rainy day (606).jpg  \n",
            "  inflating: dataset/images/train/rainy day (607).jpg  \n",
            "  inflating: dataset/images/train/rainy day (608).jpg  \n",
            "  inflating: dataset/images/train/rainy day (609).jpg  \n",
            "  inflating: dataset/images/train/rainy day (61).jpg  \n",
            "  inflating: dataset/images/train/rainy day (610).jpg  \n",
            "  inflating: dataset/images/train/rainy day (611).jpg  \n",
            "  inflating: dataset/images/train/rainy day (612).jpg  \n",
            "  inflating: dataset/images/train/rainy day (613).jpg  \n",
            "  inflating: dataset/images/train/rainy day (614).jpg  \n",
            "  inflating: dataset/images/train/rainy day (615).jpg  \n",
            "  inflating: dataset/images/train/rainy day (616).jpg  \n",
            "  inflating: dataset/images/train/rainy day (617).jpg  \n",
            "  inflating: dataset/images/train/rainy day (618).jpg  \n",
            "  inflating: dataset/images/train/rainy day (619).jpg  \n",
            "  inflating: dataset/images/train/rainy day (62).jpg  \n",
            "  inflating: dataset/images/train/rainy day (620).jpg  \n",
            "  inflating: dataset/images/train/rainy day (621).jpg  \n",
            "  inflating: dataset/images/train/rainy day (622).jpg  \n",
            "  inflating: dataset/images/train/rainy day (623).jpg  \n",
            "  inflating: dataset/images/train/rainy day (624).jpg  \n",
            "  inflating: dataset/images/train/rainy day (625).jpg  \n",
            "  inflating: dataset/images/train/rainy day (626).jpg  \n",
            "  inflating: dataset/images/train/rainy day (627).jpg  \n",
            "  inflating: dataset/images/train/rainy day (628).jpg  \n",
            "  inflating: dataset/images/train/rainy day (629).jpg  \n",
            "  inflating: dataset/images/train/rainy day (63).jpg  \n",
            "  inflating: dataset/images/train/rainy day (630).jpg  \n",
            "  inflating: dataset/images/train/rainy day (631).jpg  \n",
            "  inflating: dataset/images/train/rainy day (632).jpg  \n",
            "  inflating: dataset/images/train/rainy day (633).jpg  \n",
            "  inflating: dataset/images/train/rainy day (634).jpg  \n",
            "  inflating: dataset/images/train/rainy day (635).jpg  \n",
            "  inflating: dataset/images/train/rainy day (636).jpg  \n",
            "  inflating: dataset/images/train/rainy day (637).jpg  \n",
            "  inflating: dataset/images/train/rainy day (638).jpg  \n",
            "  inflating: dataset/images/train/rainy day (639).jpg  \n",
            "  inflating: dataset/images/train/rainy day (64).jpg  \n",
            "  inflating: dataset/images/train/rainy day (640).jpg  \n",
            "  inflating: dataset/images/train/rainy day (641).jpg  \n",
            "  inflating: dataset/images/train/rainy day (642).jpg  \n",
            "  inflating: dataset/images/train/rainy day (643).jpg  \n",
            "  inflating: dataset/images/train/rainy day (644).jpg  \n",
            "  inflating: dataset/images/train/rainy day (645).jpg  \n",
            "  inflating: dataset/images/train/rainy day (646).jpg  \n",
            "  inflating: dataset/images/train/rainy day (647).jpg  \n",
            "  inflating: dataset/images/train/rainy day (648).jpg  \n",
            "  inflating: dataset/images/train/rainy day (649).jpg  \n",
            "  inflating: dataset/images/train/rainy day (65).jpg  \n",
            "  inflating: dataset/images/train/rainy day (650).jpg  \n",
            "  inflating: dataset/images/train/rainy day (66).jpg  \n",
            "  inflating: dataset/images/train/rainy day (67).jpg  \n",
            "  inflating: dataset/images/train/rainy day (68).jpg  \n",
            "  inflating: dataset/images/train/rainy day (69).jpg  \n",
            "  inflating: dataset/images/train/rainy day (7).jpg  \n",
            "  inflating: dataset/images/train/rainy day (70).jpg  \n",
            "  inflating: dataset/images/train/rainy day (71).jpg  \n",
            "  inflating: dataset/images/train/rainy day (72).jpg  \n",
            "  inflating: dataset/images/train/rainy day (73).jpg  \n",
            "  inflating: dataset/images/train/rainy day (74).jpg  \n",
            "  inflating: dataset/images/train/rainy day (75).jpg  \n",
            "  inflating: dataset/images/train/rainy day (76).jpg  \n",
            "  inflating: dataset/images/train/rainy day (77).jpg  \n",
            "  inflating: dataset/images/train/rainy day (78).jpg  \n",
            "  inflating: dataset/images/train/rainy day (79).jpg  \n",
            "  inflating: dataset/images/train/rainy day (8).jpg  \n",
            "  inflating: dataset/images/train/rainy day (80).jpg  \n",
            "  inflating: dataset/images/train/rainy day (81).jpg  \n",
            "  inflating: dataset/images/train/rainy day (82).jpg  \n",
            "  inflating: dataset/images/train/rainy day (83).jpg  \n",
            "  inflating: dataset/images/train/rainy day (84).jpg  \n",
            "  inflating: dataset/images/train/rainy day (85).jpg  \n",
            "  inflating: dataset/images/train/rainy day (86).jpg  \n",
            "  inflating: dataset/images/train/rainy day (87).jpg  \n",
            "  inflating: dataset/images/train/rainy day (88).jpg  \n",
            "  inflating: dataset/images/train/rainy day (89).jpg  \n",
            "  inflating: dataset/images/train/rainy day (9).jpg  \n",
            "  inflating: dataset/images/train/rainy day (90).jpg  \n",
            "  inflating: dataset/images/train/rainy day (91).jpg  \n",
            "  inflating: dataset/images/train/rainy day (92).jpg  \n",
            "  inflating: dataset/images/train/rainy day (93).jpg  \n",
            "  inflating: dataset/images/train/rainy day (94).jpg  \n",
            "  inflating: dataset/images/train/rainy day (95).jpg  \n",
            "  inflating: dataset/images/train/rainy day (96).jpg  \n",
            "  inflating: dataset/images/train/rainy day (97).jpg  \n",
            "  inflating: dataset/images/train/rainy day (98).jpg  \n",
            "  inflating: dataset/images/train/rainy day (99).jpg  \n",
            "  inflating: dataset/images/train/rainynight (1).jpg  \n",
            "  inflating: dataset/images/train/rainynight (10).jpg  \n",
            "  inflating: dataset/images/train/rainynight (100).jpg  \n",
            "  inflating: dataset/images/train/rainynight (101).jpg  \n",
            "  inflating: dataset/images/train/rainynight (102).jpg  \n",
            "  inflating: dataset/images/train/rainynight (103).jpg  \n",
            "  inflating: dataset/images/train/rainynight (104).jpg  \n",
            "  inflating: dataset/images/train/rainynight (105).jpg  \n",
            "  inflating: dataset/images/train/rainynight (106).jpg  \n",
            "  inflating: dataset/images/train/rainynight (107).jpg  \n",
            "  inflating: dataset/images/train/rainynight (108).jpg  \n",
            "  inflating: dataset/images/train/rainynight (109).jpg  \n",
            "  inflating: dataset/images/train/rainynight (11).jpg  \n",
            "  inflating: dataset/images/train/rainynight (110).jpg  \n",
            "  inflating: dataset/images/train/rainynight (111).jpg  \n",
            "  inflating: dataset/images/train/rainynight (112).jpg  \n",
            "  inflating: dataset/images/train/rainynight (113).jpg  \n",
            "  inflating: dataset/images/train/rainynight (114).jpg  \n",
            "  inflating: dataset/images/train/rainynight (115).jpg  \n",
            "  inflating: dataset/images/train/rainynight (116).jpg  \n",
            "  inflating: dataset/images/train/rainynight (117).jpg  \n",
            "  inflating: dataset/images/train/rainynight (118).jpg  \n",
            "  inflating: dataset/images/train/rainynight (119).jpg  \n",
            "  inflating: dataset/images/train/rainynight (12).jpg  \n",
            "  inflating: dataset/images/train/rainynight (120).jpg  \n",
            "  inflating: dataset/images/train/rainynight (121).jpg  \n",
            "  inflating: dataset/images/train/rainynight (122).jpg  \n",
            "  inflating: dataset/images/train/rainynight (123).jpg  \n",
            "  inflating: dataset/images/train/rainynight (124).jpg  \n",
            "  inflating: dataset/images/train/rainynight (125).jpg  \n",
            "  inflating: dataset/images/train/rainynight (126).jpg  \n",
            "  inflating: dataset/images/train/rainynight (127).jpg  \n",
            "  inflating: dataset/images/train/rainynight (128).jpg  \n",
            "  inflating: dataset/images/train/rainynight (129).jpg  \n",
            "  inflating: dataset/images/train/rainynight (13).jpg  \n",
            "  inflating: dataset/images/train/rainynight (130).jpg  \n",
            "  inflating: dataset/images/train/rainynight (131).jpg  \n",
            "  inflating: dataset/images/train/rainynight (132).jpg  \n",
            "  inflating: dataset/images/train/rainynight (133).jpg  \n",
            "  inflating: dataset/images/train/rainynight (134).jpg  \n",
            "  inflating: dataset/images/train/rainynight (135).jpg  \n",
            "  inflating: dataset/images/train/rainynight (136).jpg  \n",
            "  inflating: dataset/images/train/rainynight (137).jpg  \n",
            "  inflating: dataset/images/train/rainynight (138).jpg  \n",
            "  inflating: dataset/images/train/rainynight (139).jpg  \n",
            "  inflating: dataset/images/train/rainynight (14).jpg  \n",
            "  inflating: dataset/images/train/rainynight (140).jpg  \n",
            "  inflating: dataset/images/train/rainynight (141).jpg  \n",
            "  inflating: dataset/images/train/rainynight (142).jpg  \n",
            "  inflating: dataset/images/train/rainynight (143).jpg  \n",
            "  inflating: dataset/images/train/rainynight (144).jpg  \n",
            "  inflating: dataset/images/train/rainynight (145).jpg  \n",
            "  inflating: dataset/images/train/rainynight (146).jpg  \n",
            "  inflating: dataset/images/train/rainynight (147).jpg  \n",
            "  inflating: dataset/images/train/rainynight (148).jpg  \n",
            "  inflating: dataset/images/train/rainynight (149).jpg  \n",
            "  inflating: dataset/images/train/rainynight (15).jpg  \n",
            "  inflating: dataset/images/train/rainynight (150).jpg  \n",
            "  inflating: dataset/images/train/rainynight (151).jpg  \n",
            "  inflating: dataset/images/train/rainynight (152).jpg  \n",
            "  inflating: dataset/images/train/rainynight (153).jpg  \n",
            "  inflating: dataset/images/train/rainynight (154).jpg  \n",
            "  inflating: dataset/images/train/rainynight (155).jpg  \n",
            "  inflating: dataset/images/train/rainynight (156).jpg  \n",
            "  inflating: dataset/images/train/rainynight (157).jpg  \n",
            "  inflating: dataset/images/train/rainynight (158).jpg  \n",
            "  inflating: dataset/images/train/rainynight (159).jpg  \n",
            "  inflating: dataset/images/train/rainynight (16).jpg  \n",
            "  inflating: dataset/images/train/rainynight (160).jpg  \n",
            "  inflating: dataset/images/train/rainynight (161).jpg  \n",
            "  inflating: dataset/images/train/rainynight (162).jpg  \n",
            "  inflating: dataset/images/train/rainynight (163).jpg  \n",
            "  inflating: dataset/images/train/rainynight (164).jpg  \n",
            "  inflating: dataset/images/train/rainynight (165).jpg  \n",
            "  inflating: dataset/images/train/rainynight (166).jpg  \n",
            "  inflating: dataset/images/train/rainynight (167).jpg  \n",
            "  inflating: dataset/images/train/rainynight (168).jpg  \n",
            "  inflating: dataset/images/train/rainynight (169).jpg  \n",
            "  inflating: dataset/images/train/rainynight (17).jpg  \n",
            "  inflating: dataset/images/train/rainynight (170).jpg  \n",
            "  inflating: dataset/images/train/rainynight (171).jpg  \n",
            "  inflating: dataset/images/train/rainynight (172).jpg  \n",
            "  inflating: dataset/images/train/rainynight (173).jpg  \n",
            "  inflating: dataset/images/train/rainynight (174).jpg  \n",
            "  inflating: dataset/images/train/rainynight (175).jpg  \n",
            "  inflating: dataset/images/train/rainynight (176).jpg  \n",
            "  inflating: dataset/images/train/rainynight (177).jpg  \n",
            "  inflating: dataset/images/train/rainynight (178).jpg  \n",
            "  inflating: dataset/images/train/rainynight (179).jpg  \n",
            "  inflating: dataset/images/train/rainynight (18).jpg  \n",
            "  inflating: dataset/images/train/rainynight (180).jpg  \n",
            "  inflating: dataset/images/train/rainynight (181).jpg  \n",
            "  inflating: dataset/images/train/rainynight (182).jpg  \n",
            "  inflating: dataset/images/train/rainynight (183).jpg  \n",
            "  inflating: dataset/images/train/rainynight (184).jpg  \n",
            "  inflating: dataset/images/train/rainynight (185).jpg  \n",
            "  inflating: dataset/images/train/rainynight (186).jpg  \n",
            "  inflating: dataset/images/train/rainynight (187).jpg  \n",
            "  inflating: dataset/images/train/rainynight (188).jpg  \n",
            "  inflating: dataset/images/train/rainynight (189).jpg  \n",
            "  inflating: dataset/images/train/rainynight (19).jpg  \n",
            "  inflating: dataset/images/train/rainynight (190).jpg  \n",
            "  inflating: dataset/images/train/rainynight (191).jpg  \n",
            "  inflating: dataset/images/train/rainynight (192).jpg  \n",
            "  inflating: dataset/images/train/rainynight (193).jpg  \n",
            "  inflating: dataset/images/train/rainynight (194).jpg  \n",
            "  inflating: dataset/images/train/rainynight (195).jpg  \n",
            "  inflating: dataset/images/train/rainynight (196).jpg  \n",
            "  inflating: dataset/images/train/rainynight (197).jpg  \n",
            "  inflating: dataset/images/train/rainynight (198).jpg  \n",
            "  inflating: dataset/images/train/rainynight (199).jpg  \n",
            "  inflating: dataset/images/train/rainynight (2).jpg  \n",
            "  inflating: dataset/images/train/rainynight (20).jpg  \n",
            "  inflating: dataset/images/train/rainynight (200).jpg  \n",
            "  inflating: dataset/images/train/rainynight (201).jpg  \n",
            "  inflating: dataset/images/train/rainynight (202).jpg  \n",
            "  inflating: dataset/images/train/rainynight (203).jpg  \n",
            "  inflating: dataset/images/train/rainynight (204).jpg  \n",
            "  inflating: dataset/images/train/rainynight (205).jpg  \n",
            "  inflating: dataset/images/train/rainynight (206).jpg  \n",
            "  inflating: dataset/images/train/rainynight (207).jpg  \n",
            "  inflating: dataset/images/train/rainynight (208).jpg  \n",
            "  inflating: dataset/images/train/rainynight (209).jpg  \n",
            "  inflating: dataset/images/train/rainynight (21).jpg  \n",
            "  inflating: dataset/images/train/rainynight (210).jpg  \n",
            "  inflating: dataset/images/train/rainynight (211).jpg  \n",
            "  inflating: dataset/images/train/rainynight (212).jpg  \n",
            "  inflating: dataset/images/train/rainynight (213).jpg  \n",
            "  inflating: dataset/images/train/rainynight (214).jpg  \n",
            "  inflating: dataset/images/train/rainynight (215).jpg  \n",
            "  inflating: dataset/images/train/rainynight (216).jpg  \n",
            "  inflating: dataset/images/train/rainynight (217).jpg  \n",
            "  inflating: dataset/images/train/rainynight (218).jpg  \n",
            "  inflating: dataset/images/train/rainynight (219).jpg  \n",
            "  inflating: dataset/images/train/rainynight (22).jpg  \n",
            "  inflating: dataset/images/train/rainynight (220).jpg  \n",
            "  inflating: dataset/images/train/rainynight (221).jpg  \n",
            "  inflating: dataset/images/train/rainynight (222).jpg  \n",
            "  inflating: dataset/images/train/rainynight (223).jpg  \n",
            "  inflating: dataset/images/train/rainynight (224).jpg  \n",
            "  inflating: dataset/images/train/rainynight (225).jpg  \n",
            "  inflating: dataset/images/train/rainynight (226).jpg  \n",
            "  inflating: dataset/images/train/rainynight (227).jpg  \n",
            "  inflating: dataset/images/train/rainynight (228).jpg  \n",
            "  inflating: dataset/images/train/rainynight (229).jpg  \n",
            "  inflating: dataset/images/train/rainynight (23).jpg  \n",
            "  inflating: dataset/images/train/rainynight (230).jpg  \n",
            "  inflating: dataset/images/train/rainynight (231).jpg  \n",
            "  inflating: dataset/images/train/rainynight (232).jpg  \n",
            "  inflating: dataset/images/train/rainynight (233).jpg  \n",
            "  inflating: dataset/images/train/rainynight (234).jpg  \n",
            "  inflating: dataset/images/train/rainynight (235).jpg  \n",
            "  inflating: dataset/images/train/rainynight (236).jpg  \n",
            "  inflating: dataset/images/train/rainynight (237).jpg  \n",
            "  inflating: dataset/images/train/rainynight (238).jpg  \n",
            "  inflating: dataset/images/train/rainynight (239).jpg  \n",
            "  inflating: dataset/images/train/rainynight (24).jpg  \n",
            "  inflating: dataset/images/train/rainynight (240).jpg  \n",
            "  inflating: dataset/images/train/rainynight (241).jpg  \n",
            "  inflating: dataset/images/train/rainynight (242).jpg  \n",
            "  inflating: dataset/images/train/rainynight (243).jpg  \n",
            "  inflating: dataset/images/train/rainynight (244).jpg  \n",
            "  inflating: dataset/images/train/rainynight (245).jpg  \n",
            "  inflating: dataset/images/train/rainynight (246).jpg  \n",
            "  inflating: dataset/images/train/rainynight (247).jpg  \n",
            "  inflating: dataset/images/train/rainynight (248).jpg  \n",
            "  inflating: dataset/images/train/rainynight (249).jpg  \n",
            "  inflating: dataset/images/train/rainynight (25).jpg  \n",
            "  inflating: dataset/images/train/rainynight (250).jpg  \n",
            "  inflating: dataset/images/train/rainynight (251).jpg  \n",
            "  inflating: dataset/images/train/rainynight (252).jpg  \n",
            "  inflating: dataset/images/train/rainynight (253).jpg  \n",
            "  inflating: dataset/images/train/rainynight (254).jpg  \n",
            "  inflating: dataset/images/train/rainynight (255).jpg  \n",
            "  inflating: dataset/images/train/rainynight (256).jpg  \n",
            "  inflating: dataset/images/train/rainynight (257).jpg  \n",
            "  inflating: dataset/images/train/rainynight (258).jpg  \n",
            "  inflating: dataset/images/train/rainynight (259).jpg  \n",
            "  inflating: dataset/images/train/rainynight (26).jpg  \n",
            "  inflating: dataset/images/train/rainynight (260).jpg  \n",
            "  inflating: dataset/images/train/rainynight (261).jpg  \n",
            "  inflating: dataset/images/train/rainynight (262).jpg  \n",
            "  inflating: dataset/images/train/rainynight (263).jpg  \n",
            "  inflating: dataset/images/train/rainynight (264).jpg  \n",
            "  inflating: dataset/images/train/rainynight (265).jpg  \n",
            "  inflating: dataset/images/train/rainynight (266).jpg  \n",
            "  inflating: dataset/images/train/rainynight (267).jpg  \n",
            "  inflating: dataset/images/train/rainynight (268).jpg  \n",
            "  inflating: dataset/images/train/rainynight (269).jpg  \n",
            "  inflating: dataset/images/train/rainynight (27).jpg  \n",
            "  inflating: dataset/images/train/rainynight (270).jpg  \n",
            "  inflating: dataset/images/train/rainynight (271).jpg  \n",
            "  inflating: dataset/images/train/rainynight (272).jpg  \n",
            "  inflating: dataset/images/train/rainynight (273).jpg  \n",
            "  inflating: dataset/images/train/rainynight (274).jpg  \n",
            "  inflating: dataset/images/train/rainynight (275).jpg  \n",
            "  inflating: dataset/images/train/rainynight (276).jpg  \n",
            "  inflating: dataset/images/train/rainynight (277).jpg  \n",
            "  inflating: dataset/images/train/rainynight (278).jpg  \n",
            "  inflating: dataset/images/train/rainynight (279).jpg  \n",
            "  inflating: dataset/images/train/rainynight (28).jpg  \n",
            "  inflating: dataset/images/train/rainynight (280).jpg  \n",
            "  inflating: dataset/images/train/rainynight (281).jpg  \n",
            "  inflating: dataset/images/train/rainynight (282).jpg  \n",
            "  inflating: dataset/images/train/rainynight (283).jpg  \n",
            "  inflating: dataset/images/train/rainynight (284).jpg  \n",
            "  inflating: dataset/images/train/rainynight (285).jpg  \n",
            "  inflating: dataset/images/train/rainynight (286).jpg  \n",
            "  inflating: dataset/images/train/rainynight (287).jpg  \n",
            "  inflating: dataset/images/train/rainynight (288).jpg  \n",
            "  inflating: dataset/images/train/rainynight (289).jpg  \n",
            "  inflating: dataset/images/train/rainynight (29).jpg  \n",
            "  inflating: dataset/images/train/rainynight (290).jpg  \n",
            "  inflating: dataset/images/train/rainynight (291).jpg  \n",
            "  inflating: dataset/images/train/rainynight (292).jpg  \n",
            "  inflating: dataset/images/train/rainynight (293).jpg  \n",
            "  inflating: dataset/images/train/rainynight (294).jpg  \n",
            "  inflating: dataset/images/train/rainynight (295).jpg  \n",
            "  inflating: dataset/images/train/rainynight (296).jpg  \n",
            "  inflating: dataset/images/train/rainynight (297).jpg  \n",
            "  inflating: dataset/images/train/rainynight (298).jpg  \n",
            "  inflating: dataset/images/train/rainynight (299).jpg  \n",
            "  inflating: dataset/images/train/rainynight (3).jpg  \n",
            "  inflating: dataset/images/train/rainynight (30).jpg  \n",
            "  inflating: dataset/images/train/rainynight (300).jpg  \n",
            "  inflating: dataset/images/train/rainynight (301).jpg  \n",
            "  inflating: dataset/images/train/rainynight (302).jpg  \n",
            "  inflating: dataset/images/train/rainynight (303).jpg  \n",
            "  inflating: dataset/images/train/rainynight (304).jpg  \n",
            "  inflating: dataset/images/train/rainynight (305).jpg  \n",
            "  inflating: dataset/images/train/rainynight (306).jpg  \n",
            "  inflating: dataset/images/train/rainynight (307).jpg  \n",
            "  inflating: dataset/images/train/rainynight (308).jpg  \n",
            "  inflating: dataset/images/train/rainynight (309).jpg  \n",
            "  inflating: dataset/images/train/rainynight (31).jpg  \n",
            "  inflating: dataset/images/train/rainynight (310).jpg  \n",
            "  inflating: dataset/images/train/rainynight (311).jpg  \n",
            "  inflating: dataset/images/train/rainynight (312).jpg  \n",
            "  inflating: dataset/images/train/rainynight (313).jpg  \n",
            "  inflating: dataset/images/train/rainynight (314).jpg  \n",
            "  inflating: dataset/images/train/rainynight (315).jpg  \n",
            "  inflating: dataset/images/train/rainynight (316).jpg  \n",
            "  inflating: dataset/images/train/rainynight (317).jpg  \n",
            "  inflating: dataset/images/train/rainynight (318).jpg  \n",
            "  inflating: dataset/images/train/rainynight (319).jpg  \n",
            "  inflating: dataset/images/train/rainynight (32).jpg  \n",
            "  inflating: dataset/images/train/rainynight (320).jpg  \n",
            "  inflating: dataset/images/train/rainynight (321).jpg  \n",
            "  inflating: dataset/images/train/rainynight (322).jpg  \n",
            "  inflating: dataset/images/train/rainynight (323).jpg  \n",
            "  inflating: dataset/images/train/rainynight (324).jpg  \n",
            "  inflating: dataset/images/train/rainynight (325).jpg  \n",
            "  inflating: dataset/images/train/rainynight (326).jpg  \n",
            "  inflating: dataset/images/train/rainynight (327).jpg  \n",
            "  inflating: dataset/images/train/rainynight (328).jpg  \n",
            "  inflating: dataset/images/train/rainynight (329).jpg  \n",
            "  inflating: dataset/images/train/rainynight (33).jpg  \n",
            "  inflating: dataset/images/train/rainynight (330).jpg  \n",
            "  inflating: dataset/images/train/rainynight (331).jpg  \n",
            "  inflating: dataset/images/train/rainynight (332).jpg  \n",
            "  inflating: dataset/images/train/rainynight (333).jpg  \n",
            "  inflating: dataset/images/train/rainynight (334).jpg  \n",
            "  inflating: dataset/images/train/rainynight (335).jpg  \n",
            "  inflating: dataset/images/train/rainynight (336).jpg  \n",
            "  inflating: dataset/images/train/rainynight (337).jpg  \n",
            "  inflating: dataset/images/train/rainynight (338).jpg  \n",
            "  inflating: dataset/images/train/rainynight (339).jpg  \n",
            "  inflating: dataset/images/train/rainynight (34).jpg  \n",
            "  inflating: dataset/images/train/rainynight (340).jpg  \n",
            "  inflating: dataset/images/train/rainynight (341).jpg  \n",
            "  inflating: dataset/images/train/rainynight (342).jpg  \n",
            "  inflating: dataset/images/train/rainynight (343).jpg  \n",
            "  inflating: dataset/images/train/rainynight (344).jpg  \n",
            "  inflating: dataset/images/train/rainynight (345).jpg  \n",
            "  inflating: dataset/images/train/rainynight (346).jpg  \n",
            "  inflating: dataset/images/train/rainynight (347).jpg  \n",
            "  inflating: dataset/images/train/rainynight (348).jpg  \n",
            "  inflating: dataset/images/train/rainynight (349).jpg  \n",
            "  inflating: dataset/images/train/rainynight (35).jpg  \n",
            "  inflating: dataset/images/train/rainynight (350).jpg  \n",
            "  inflating: dataset/images/train/rainynight (351).jpg  \n",
            "  inflating: dataset/images/train/rainynight (352).jpg  \n",
            "  inflating: dataset/images/train/rainynight (353).jpg  \n",
            "  inflating: dataset/images/train/rainynight (354).jpg  \n",
            "  inflating: dataset/images/train/rainynight (355).jpg  \n",
            "  inflating: dataset/images/train/rainynight (356).jpg  \n",
            "  inflating: dataset/images/train/rainynight (357).jpg  \n",
            "  inflating: dataset/images/train/rainynight (358).jpg  \n",
            "  inflating: dataset/images/train/rainynight (359).jpg  \n",
            "  inflating: dataset/images/train/rainynight (36).jpg  \n",
            "  inflating: dataset/images/train/rainynight (360).jpg  \n",
            "  inflating: dataset/images/train/rainynight (361).jpg  \n",
            "  inflating: dataset/images/train/rainynight (362).jpg  \n",
            "  inflating: dataset/images/train/rainynight (363).jpg  \n",
            "  inflating: dataset/images/train/rainynight (364).jpg  \n",
            "  inflating: dataset/images/train/rainynight (365).jpg  \n",
            "  inflating: dataset/images/train/rainynight (366).jpg  \n",
            "  inflating: dataset/images/train/rainynight (367).jpg  \n",
            "  inflating: dataset/images/train/rainynight (368).jpg  \n",
            "  inflating: dataset/images/train/rainynight (369).jpg  \n",
            "  inflating: dataset/images/train/rainynight (37).jpg  \n",
            "  inflating: dataset/images/train/rainynight (370).jpg  \n",
            "  inflating: dataset/images/train/rainynight (371).jpg  \n",
            "  inflating: dataset/images/train/rainynight (372).jpg  \n",
            "  inflating: dataset/images/train/rainynight (373).jpg  \n",
            "  inflating: dataset/images/train/rainynight (374).jpg  \n",
            "  inflating: dataset/images/train/rainynight (375).jpg  \n",
            "  inflating: dataset/images/train/rainynight (376).jpg  \n",
            "  inflating: dataset/images/train/rainynight (377).jpg  \n",
            "  inflating: dataset/images/train/rainynight (378).jpg  \n",
            "  inflating: dataset/images/train/rainynight (379).jpg  \n",
            "  inflating: dataset/images/train/rainynight (38).jpg  \n",
            "  inflating: dataset/images/train/rainynight (380).jpg  \n",
            "  inflating: dataset/images/train/rainynight (381).jpg  \n",
            "  inflating: dataset/images/train/rainynight (382).jpg  \n",
            "  inflating: dataset/images/train/rainynight (383).jpg  \n",
            "  inflating: dataset/images/train/rainynight (384).jpg  \n",
            "  inflating: dataset/images/train/rainynight (385).jpg  \n",
            "  inflating: dataset/images/train/rainynight (386).jpg  \n",
            "  inflating: dataset/images/train/rainynight (387).jpg  \n",
            "  inflating: dataset/images/train/rainynight (388).jpg  \n",
            "  inflating: dataset/images/train/rainynight (389).jpg  \n",
            "  inflating: dataset/images/train/rainynight (39).jpg  \n",
            "  inflating: dataset/images/train/rainynight (390).jpg  \n",
            "  inflating: dataset/images/train/rainynight (391).jpg  \n",
            "  inflating: dataset/images/train/rainynight (392).jpg  \n",
            "  inflating: dataset/images/train/rainynight (393).jpg  \n",
            "  inflating: dataset/images/train/rainynight (394).jpg  \n",
            "  inflating: dataset/images/train/rainynight (395).jpg  \n",
            "  inflating: dataset/images/train/rainynight (396).jpg  \n",
            "  inflating: dataset/images/train/rainynight (397).jpg  \n",
            "  inflating: dataset/images/train/rainynight (398).jpg  \n",
            "  inflating: dataset/images/train/rainynight (399).jpg  \n",
            "  inflating: dataset/images/train/rainynight (4).jpg  \n",
            "  inflating: dataset/images/train/rainynight (40).jpg  \n",
            "  inflating: dataset/images/train/rainynight (400).jpg  \n",
            "  inflating: dataset/images/train/rainynight (401).jpg  \n",
            "  inflating: dataset/images/train/rainynight (402).jpg  \n",
            "  inflating: dataset/images/train/rainynight (403).jpg  \n",
            "  inflating: dataset/images/train/rainynight (404).jpg  \n",
            "  inflating: dataset/images/train/rainynight (405).jpg  \n",
            "  inflating: dataset/images/train/rainynight (406).jpg  \n",
            "  inflating: dataset/images/train/rainynight (407).jpg  \n",
            "  inflating: dataset/images/train/rainynight (408).jpg  \n",
            "  inflating: dataset/images/train/rainynight (409).jpg  \n",
            "  inflating: dataset/images/train/rainynight (41).jpg  \n",
            "  inflating: dataset/images/train/rainynight (410).jpg  \n",
            "  inflating: dataset/images/train/rainynight (411).jpg  \n",
            "  inflating: dataset/images/train/rainynight (412).jpg  \n",
            "  inflating: dataset/images/train/rainynight (413).jpg  \n",
            "  inflating: dataset/images/train/rainynight (414).jpg  \n",
            "  inflating: dataset/images/train/rainynight (415).jpg  \n",
            "  inflating: dataset/images/train/rainynight (416).jpg  \n",
            "  inflating: dataset/images/train/rainynight (417).jpg  \n",
            "  inflating: dataset/images/train/rainynight (418).jpg  \n",
            "  inflating: dataset/images/train/rainynight (419).jpg  \n",
            "  inflating: dataset/images/train/rainynight (42).jpg  \n",
            "  inflating: dataset/images/train/rainynight (420).jpg  \n",
            "  inflating: dataset/images/train/rainynight (421).jpg  \n",
            "  inflating: dataset/images/train/rainynight (422).jpg  \n",
            "  inflating: dataset/images/train/rainynight (423).jpg  \n",
            "  inflating: dataset/images/train/rainynight (424).jpg  \n",
            "  inflating: dataset/images/train/rainynight (425).jpg  \n",
            "  inflating: dataset/images/train/rainynight (426).jpg  \n",
            "  inflating: dataset/images/train/rainynight (427).jpg  \n",
            "  inflating: dataset/images/train/rainynight (428).jpg  \n",
            "  inflating: dataset/images/train/rainynight (429).jpg  \n",
            "  inflating: dataset/images/train/rainynight (43).jpg  \n",
            "  inflating: dataset/images/train/rainynight (430).jpg  \n",
            "  inflating: dataset/images/train/rainynight (431).jpg  \n",
            "  inflating: dataset/images/train/rainynight (432).jpg  \n",
            "  inflating: dataset/images/train/rainynight (433).jpg  \n",
            "  inflating: dataset/images/train/rainynight (434).jpg  \n",
            "  inflating: dataset/images/train/rainynight (435).jpg  \n",
            "  inflating: dataset/images/train/rainynight (436).jpg  \n",
            "  inflating: dataset/images/train/rainynight (437).jpg  \n",
            "  inflating: dataset/images/train/rainynight (438).jpg  \n",
            "  inflating: dataset/images/train/rainynight (439).jpg  \n",
            "  inflating: dataset/images/train/rainynight (44).jpg  \n",
            "  inflating: dataset/images/train/rainynight (440).jpg  \n",
            "  inflating: dataset/images/train/rainynight (441).jpg  \n",
            "  inflating: dataset/images/train/rainynight (442).jpg  \n",
            "  inflating: dataset/images/train/rainynight (443).jpg  \n",
            "  inflating: dataset/images/train/rainynight (444).jpg  \n",
            "  inflating: dataset/images/train/rainynight (445).jpg  \n",
            "  inflating: dataset/images/train/rainynight (446).jpg  \n",
            "  inflating: dataset/images/train/rainynight (447).jpg  \n",
            "  inflating: dataset/images/train/rainynight (448).jpg  \n",
            "  inflating: dataset/images/train/rainynight (449).jpg  \n",
            "  inflating: dataset/images/train/rainynight (45).jpg  \n",
            "  inflating: dataset/images/train/rainynight (450).jpg  \n",
            "  inflating: dataset/images/train/rainynight (451).jpg  \n",
            "  inflating: dataset/images/train/rainynight (452).jpg  \n",
            "  inflating: dataset/images/train/rainynight (453).jpg  \n",
            "  inflating: dataset/images/train/rainynight (454).jpg  \n",
            "  inflating: dataset/images/train/rainynight (455).jpg  \n",
            "  inflating: dataset/images/train/rainynight (456).jpg  \n",
            "  inflating: dataset/images/train/rainynight (457).jpg  \n",
            "  inflating: dataset/images/train/rainynight (458).jpg  \n",
            "  inflating: dataset/images/train/rainynight (459).jpg  \n",
            "  inflating: dataset/images/train/rainynight (46).jpg  \n",
            "  inflating: dataset/images/train/rainynight (460).jpg  \n",
            "  inflating: dataset/images/train/rainynight (461).jpg  \n",
            "  inflating: dataset/images/train/rainynight (462).jpg  \n",
            "  inflating: dataset/images/train/rainynight (463).jpg  \n",
            "  inflating: dataset/images/train/rainynight (464).jpg  \n",
            "  inflating: dataset/images/train/rainynight (465).jpg  \n",
            "  inflating: dataset/images/train/rainynight (466).jpg  \n",
            "  inflating: dataset/images/train/rainynight (467).jpg  \n",
            "  inflating: dataset/images/train/rainynight (468).jpg  \n",
            "  inflating: dataset/images/train/rainynight (469).jpg  \n",
            "  inflating: dataset/images/train/rainynight (47).jpg  \n",
            "  inflating: dataset/images/train/rainynight (470).jpg  \n",
            "  inflating: dataset/images/train/rainynight (471).jpg  \n",
            "  inflating: dataset/images/train/rainynight (472).jpg  \n",
            "  inflating: dataset/images/train/rainynight (473).jpg  \n",
            "  inflating: dataset/images/train/rainynight (474).jpg  \n",
            "  inflating: dataset/images/train/rainynight (475).jpg  \n",
            "  inflating: dataset/images/train/rainynight (476).jpg  \n",
            "  inflating: dataset/images/train/rainynight (477).jpg  \n",
            "  inflating: dataset/images/train/rainynight (478).jpg  \n",
            "  inflating: dataset/images/train/rainynight (479).jpg  \n",
            "  inflating: dataset/images/train/rainynight (48).jpg  \n",
            "  inflating: dataset/images/train/rainynight (480).jpg  \n",
            "  inflating: dataset/images/train/rainynight (481).jpg  \n",
            "  inflating: dataset/images/train/rainynight (482).jpg  \n",
            "  inflating: dataset/images/train/rainynight (483).jpg  \n",
            "  inflating: dataset/images/train/rainynight (484).jpg  \n",
            "  inflating: dataset/images/train/rainynight (485).jpg  \n",
            "  inflating: dataset/images/train/rainynight (486).jpg  \n",
            "  inflating: dataset/images/train/rainynight (487).jpg  \n",
            "  inflating: dataset/images/train/rainynight (488).jpg  \n",
            "  inflating: dataset/images/train/rainynight (489).jpg  \n",
            "  inflating: dataset/images/train/rainynight (49).jpg  \n",
            "  inflating: dataset/images/train/rainynight (490).jpg  \n",
            "  inflating: dataset/images/train/rainynight (491).jpg  \n",
            "  inflating: dataset/images/train/rainynight (492).jpg  \n",
            "  inflating: dataset/images/train/rainynight (493).jpg  \n",
            "  inflating: dataset/images/train/rainynight (494).jpg  \n",
            "  inflating: dataset/images/train/rainynight (495).jpg  \n",
            "  inflating: dataset/images/train/rainynight (496).jpg  \n",
            "  inflating: dataset/images/train/rainynight (497).jpg  \n",
            "  inflating: dataset/images/train/rainynight (498).jpg  \n",
            "  inflating: dataset/images/train/rainynight (499).jpg  \n",
            "  inflating: dataset/images/train/rainynight (5).jpg  \n",
            "  inflating: dataset/images/train/rainynight (50).jpg  \n",
            "  inflating: dataset/images/train/rainynight (500).jpg  \n",
            "  inflating: dataset/images/train/rainynight (501).jpg  \n",
            "  inflating: dataset/images/train/rainynight (502).jpg  \n",
            "  inflating: dataset/images/train/rainynight (503).jpg  \n",
            "  inflating: dataset/images/train/rainynight (504).jpg  \n",
            "  inflating: dataset/images/train/rainynight (505).jpg  \n",
            "  inflating: dataset/images/train/rainynight (506).jpg  \n",
            "  inflating: dataset/images/train/rainynight (507).jpg  \n",
            "  inflating: dataset/images/train/rainynight (508).jpg  \n",
            "  inflating: dataset/images/train/rainynight (509).jpg  \n",
            "  inflating: dataset/images/train/rainynight (51).jpg  \n",
            "  inflating: dataset/images/train/rainynight (510).jpg  \n",
            "  inflating: dataset/images/train/rainynight (511).jpg  \n",
            "  inflating: dataset/images/train/rainynight (512).jpg  \n",
            "  inflating: dataset/images/train/rainynight (513).jpg  \n",
            "  inflating: dataset/images/train/rainynight (514).jpg  \n",
            "  inflating: dataset/images/train/rainynight (515).jpg  \n",
            "  inflating: dataset/images/train/rainynight (516).jpg  \n",
            "  inflating: dataset/images/train/rainynight (517).jpg  \n",
            "  inflating: dataset/images/train/rainynight (518).jpg  \n",
            "  inflating: dataset/images/train/rainynight (519).jpg  \n",
            "  inflating: dataset/images/train/rainynight (52).jpg  \n",
            "  inflating: dataset/images/train/rainynight (520).jpg  \n",
            "  inflating: dataset/images/train/rainynight (521).jpg  \n",
            "  inflating: dataset/images/train/rainynight (522).jpg  \n",
            "  inflating: dataset/images/train/rainynight (523).jpg  \n",
            "  inflating: dataset/images/train/rainynight (524).jpg  \n",
            "  inflating: dataset/images/train/rainynight (525).jpg  \n",
            "  inflating: dataset/images/train/rainynight (526).jpg  \n",
            "  inflating: dataset/images/train/rainynight (527).jpg  \n",
            "  inflating: dataset/images/train/rainynight (528).jpg  \n",
            "  inflating: dataset/images/train/rainynight (529).jpg  \n",
            "  inflating: dataset/images/train/rainynight (53).jpg  \n",
            "  inflating: dataset/images/train/rainynight (530).jpg  \n",
            "  inflating: dataset/images/train/rainynight (531).jpg  \n",
            "  inflating: dataset/images/train/rainynight (532).jpg  \n",
            "  inflating: dataset/images/train/rainynight (533).jpg  \n",
            "  inflating: dataset/images/train/rainynight (534).jpg  \n",
            "  inflating: dataset/images/train/rainynight (535).jpg  \n",
            "  inflating: dataset/images/train/rainynight (536).jpg  \n",
            "  inflating: dataset/images/train/rainynight (537).jpg  \n",
            "  inflating: dataset/images/train/rainynight (538).jpg  \n",
            "  inflating: dataset/images/train/rainynight (539).jpg  \n",
            "  inflating: dataset/images/train/rainynight (54).jpg  \n",
            "  inflating: dataset/images/train/rainynight (540).jpg  \n",
            "  inflating: dataset/images/train/rainynight (541).jpg  \n",
            "  inflating: dataset/images/train/rainynight (542).jpg  \n",
            "  inflating: dataset/images/train/rainynight (543).jpg  \n",
            "  inflating: dataset/images/train/rainynight (544).jpg  \n",
            "  inflating: dataset/images/train/rainynight (545).jpg  \n",
            "  inflating: dataset/images/train/rainynight (546).jpg  \n",
            "  inflating: dataset/images/train/rainynight (547).jpg  \n",
            "  inflating: dataset/images/train/rainynight (548).jpg  \n",
            "  inflating: dataset/images/train/rainynight (549).jpg  \n",
            "  inflating: dataset/images/train/rainynight (55).jpg  \n",
            "  inflating: dataset/images/train/rainynight (550).jpg  \n",
            "  inflating: dataset/images/train/rainynight (551).jpg  \n",
            "  inflating: dataset/images/train/rainynight (552).jpg  \n",
            "  inflating: dataset/images/train/rainynight (553).jpg  \n",
            "  inflating: dataset/images/train/rainynight (554).jpg  \n",
            "  inflating: dataset/images/train/rainynight (555).jpg  \n",
            "  inflating: dataset/images/train/rainynight (556).jpg  \n",
            "  inflating: dataset/images/train/rainynight (557).jpg  \n",
            "  inflating: dataset/images/train/rainynight (558).jpg  \n",
            "  inflating: dataset/images/train/rainynight (559).jpg  \n",
            "  inflating: dataset/images/train/rainynight (56).jpg  \n",
            "  inflating: dataset/images/train/rainynight (560).jpg  \n",
            "  inflating: dataset/images/train/rainynight (561).jpg  \n",
            "  inflating: dataset/images/train/rainynight (562).jpg  \n",
            "  inflating: dataset/images/train/rainynight (563).jpg  \n",
            "  inflating: dataset/images/train/rainynight (564).jpg  \n",
            "  inflating: dataset/images/train/rainynight (565).jpg  \n",
            "  inflating: dataset/images/train/rainynight (566).jpg  \n",
            "  inflating: dataset/images/train/rainynight (567).jpg  \n",
            "  inflating: dataset/images/train/rainynight (568).jpg  \n",
            "  inflating: dataset/images/train/rainynight (569).jpg  \n",
            "  inflating: dataset/images/train/rainynight (57).jpg  \n",
            "  inflating: dataset/images/train/rainynight (570).jpg  \n",
            "  inflating: dataset/images/train/rainynight (571).jpg  \n",
            "  inflating: dataset/images/train/rainynight (572).jpg  \n",
            "  inflating: dataset/images/train/rainynight (573).jpg  \n",
            "  inflating: dataset/images/train/rainynight (574).jpg  \n",
            "  inflating: dataset/images/train/rainynight (575).jpg  \n",
            "  inflating: dataset/images/train/rainynight (576).jpg  \n",
            "  inflating: dataset/images/train/rainynight (577).jpg  \n",
            "  inflating: dataset/images/train/rainynight (578).jpg  \n",
            "  inflating: dataset/images/train/rainynight (579).jpg  \n",
            "  inflating: dataset/images/train/rainynight (58).jpg  \n",
            "  inflating: dataset/images/train/rainynight (580).jpg  \n",
            "  inflating: dataset/images/train/rainynight (581).jpg  \n",
            "  inflating: dataset/images/train/rainynight (582).jpg  \n",
            "  inflating: dataset/images/train/rainynight (583).jpg  \n",
            "  inflating: dataset/images/train/rainynight (584).jpg  \n",
            "  inflating: dataset/images/train/rainynight (585).jpg  \n",
            "  inflating: dataset/images/train/rainynight (586).jpg  \n",
            "  inflating: dataset/images/train/rainynight (587).jpg  \n",
            "  inflating: dataset/images/train/rainynight (588).jpg  \n",
            "  inflating: dataset/images/train/rainynight (589).jpg  \n",
            "  inflating: dataset/images/train/rainynight (59).jpg  \n",
            "  inflating: dataset/images/train/rainynight (590).jpg  \n",
            "  inflating: dataset/images/train/rainynight (591).jpg  \n",
            "  inflating: dataset/images/train/rainynight (592).jpg  \n",
            "  inflating: dataset/images/train/rainynight (593).jpg  \n",
            "  inflating: dataset/images/train/rainynight (594).jpg  \n",
            "  inflating: dataset/images/train/rainynight (595).jpg  \n",
            "  inflating: dataset/images/train/rainynight (596).jpg  \n",
            "  inflating: dataset/images/train/rainynight (597).jpg  \n",
            "  inflating: dataset/images/train/rainynight (598).jpg  \n",
            "  inflating: dataset/images/train/rainynight (599).jpg  \n",
            "  inflating: dataset/images/train/rainynight (6).jpg  \n",
            "  inflating: dataset/images/train/rainynight (60).jpg  \n",
            "  inflating: dataset/images/train/rainynight (600).jpg  \n",
            "  inflating: dataset/images/train/rainynight (601).jpg  \n",
            "  inflating: dataset/images/train/rainynight (602).jpg  \n",
            "  inflating: dataset/images/train/rainynight (603).jpg  \n",
            "  inflating: dataset/images/train/rainynight (604).jpg  \n",
            "  inflating: dataset/images/train/rainynight (605).jpg  \n",
            "  inflating: dataset/images/train/rainynight (606).jpg  \n",
            "  inflating: dataset/images/train/rainynight (607).jpg  \n",
            "  inflating: dataset/images/train/rainynight (608).jpg  \n",
            "  inflating: dataset/images/train/rainynight (609).jpg  \n",
            "  inflating: dataset/images/train/rainynight (61).jpg  \n",
            "  inflating: dataset/images/train/rainynight (610).jpg  \n",
            "  inflating: dataset/images/train/rainynight (611).jpg  \n",
            "  inflating: dataset/images/train/rainynight (612).jpg  \n",
            "  inflating: dataset/images/train/rainynight (613).jpg  \n",
            "  inflating: dataset/images/train/rainynight (614).jpg  \n",
            "  inflating: dataset/images/train/rainynight (615).jpg  \n",
            "  inflating: dataset/images/train/rainynight (616).jpg  \n",
            "  inflating: dataset/images/train/rainynight (617).jpg  \n",
            "  inflating: dataset/images/train/rainynight (618).jpg  \n",
            "  inflating: dataset/images/train/rainynight (619).jpg  \n",
            "  inflating: dataset/images/train/rainynight (62).jpg  \n",
            "  inflating: dataset/images/train/rainynight (620).jpg  \n",
            "  inflating: dataset/images/train/rainynight (621).jpg  \n",
            "  inflating: dataset/images/train/rainynight (622).jpg  \n",
            "  inflating: dataset/images/train/rainynight (623).jpg  \n",
            "  inflating: dataset/images/train/rainynight (624).jpg  \n",
            "  inflating: dataset/images/train/rainynight (625).jpg  \n",
            "  inflating: dataset/images/train/rainynight (626).jpg  \n",
            "  inflating: dataset/images/train/rainynight (627).jpg  \n",
            "  inflating: dataset/images/train/rainynight (628).jpg  \n",
            "  inflating: dataset/images/train/rainynight (629).jpg  \n",
            "  inflating: dataset/images/train/rainynight (63).jpg  \n",
            "  inflating: dataset/images/train/rainynight (630).jpg  \n",
            "  inflating: dataset/images/train/rainynight (631).jpg  \n",
            "  inflating: dataset/images/train/rainynight (632).jpg  \n",
            "  inflating: dataset/images/train/rainynight (633).jpg  \n",
            "  inflating: dataset/images/train/rainynight (634).jpg  \n",
            "  inflating: dataset/images/train/rainynight (635).jpg  \n",
            "  inflating: dataset/images/train/rainynight (636).jpg  \n",
            "  inflating: dataset/images/train/rainynight (637).jpg  \n",
            "  inflating: dataset/images/train/rainynight (638).jpg  \n",
            "  inflating: dataset/images/train/rainynight (639).jpg  \n",
            "  inflating: dataset/images/train/rainynight (64).jpg  \n",
            "  inflating: dataset/images/train/rainynight (640).jpg  \n",
            "  inflating: dataset/images/train/rainynight (641).jpg  \n",
            "  inflating: dataset/images/train/rainynight (642).jpg  \n",
            "  inflating: dataset/images/train/rainynight (643).jpg  \n",
            "  inflating: dataset/images/train/rainynight (644).jpg  \n",
            "  inflating: dataset/images/train/rainynight (645).jpg  \n",
            "  inflating: dataset/images/train/rainynight (646).jpg  \n",
            "  inflating: dataset/images/train/rainynight (647).jpg  \n",
            "  inflating: dataset/images/train/rainynight (648).jpg  \n",
            "  inflating: dataset/images/train/rainynight (649).jpg  \n",
            "  inflating: dataset/images/train/rainynight (65).jpg  \n",
            "  inflating: dataset/images/train/rainynight (650).jpg  \n",
            "  inflating: dataset/images/train/rainynight (66).jpg  \n",
            "  inflating: dataset/images/train/rainynight (67).jpg  \n",
            "  inflating: dataset/images/train/rainynight (68).jpg  \n",
            "  inflating: dataset/images/train/rainynight (69).jpg  \n",
            "  inflating: dataset/images/train/rainynight (7).jpg  \n",
            "  inflating: dataset/images/train/rainynight (70).jpg  \n",
            "  inflating: dataset/images/train/rainynight (71).jpg  \n",
            "  inflating: dataset/images/train/rainynight (72).jpg  \n",
            "  inflating: dataset/images/train/rainynight (73).jpg  \n",
            "  inflating: dataset/images/train/rainynight (74).jpg  \n",
            "  inflating: dataset/images/train/rainynight (75).jpg  \n",
            "  inflating: dataset/images/train/rainynight (76).jpg  \n",
            "  inflating: dataset/images/train/rainynight (77).jpg  \n",
            "  inflating: dataset/images/train/rainynight (78).jpg  \n",
            "  inflating: dataset/images/train/rainynight (79).jpg  \n",
            "  inflating: dataset/images/train/rainynight (8).jpg  \n",
            " extracting: dataset/images/train/rainynight (80).jpg  \n",
            "  inflating: dataset/images/train/rainynight (81).jpg  \n",
            "  inflating: dataset/images/train/rainynight (82).jpg  \n",
            "  inflating: dataset/images/train/rainynight (83).jpg  \n",
            "  inflating: dataset/images/train/rainynight (84).jpg  \n",
            "  inflating: dataset/images/train/rainynight (85).jpg  \n",
            "  inflating: dataset/images/train/rainynight (86).jpg  \n",
            "  inflating: dataset/images/train/rainynight (87).jpg  \n",
            "  inflating: dataset/images/train/rainynight (88).jpg  \n",
            "  inflating: dataset/images/train/rainynight (89).jpg  \n",
            "  inflating: dataset/images/train/rainynight (9).jpg  \n",
            "  inflating: dataset/images/train/rainynight (90).jpg  \n",
            "  inflating: dataset/images/train/rainynight (91).jpg  \n",
            "  inflating: dataset/images/train/rainynight (92).jpg  \n",
            "  inflating: dataset/images/train/rainynight (93).jpg  \n",
            "  inflating: dataset/images/train/rainynight (94).jpg  \n",
            "  inflating: dataset/images/train/rainynight (95).jpg  \n",
            "  inflating: dataset/images/train/rainynight (96).jpg  \n",
            "  inflating: dataset/images/train/rainynight (97).jpg  \n",
            "  inflating: dataset/images/train/rainynight (98).jpg  \n",
            "  inflating: dataset/images/train/rainynight (99).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (1).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (10).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (100).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (103).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (104).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (105).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (106).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (11).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (117).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (118).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (119).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (12).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (120).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (121).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (122).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (123).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (124).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (125).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (126).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (127).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (128).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (129).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (13).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (130).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (131).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (132).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (133).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (134).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (135).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (136).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (137).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (138).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (139).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (14).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (140).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (141).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (142).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (143).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (144).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (145).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (147).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (148).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (149).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (15).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (150).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (151).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (152).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (153).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (154).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (155).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (156).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (157).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (158).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (159).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (16).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (160).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (161).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (162).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (163).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (164).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (165).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (166).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (167).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (168).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (169).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (17).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (170).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (171).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (173).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (174).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (175).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (176).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (177).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (179).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (18).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (180).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (181).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (182).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (184).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (185).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (186).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (187).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (188).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (189).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (19).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (190).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (191).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (192).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (193).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (194).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (195).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (196).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (197).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (198).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (199).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (2).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (20).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (200).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (202).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (203).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (204).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (21).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (213).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (215).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (216).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (217).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (219).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (22).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (220).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (221).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (222).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (224).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (229).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (23).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (230).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (231).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (232).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (233).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (234).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (236).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (237).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (24).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (240).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (244).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (246).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (248).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (25).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (250).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (254).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (258).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (26).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (260).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (261).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (263).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (268).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (27).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (270).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (272).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (273).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (277).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (279).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (28).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (280).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (281).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (284).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (285).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (287).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (288).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (29).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (290).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (291).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (293).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (294).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (296).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (3).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (30).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (300).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (301).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (303).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (304).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (305).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (306).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (307).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (31).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (310).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (311).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (314).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (316).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (318).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (319).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (32).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (320).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (323).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (324).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (327).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (329).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (33).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (330).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (332).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (333).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (336).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (337).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (34).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (342).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (344).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (347).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (349).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (35).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (350).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (351).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (352).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (353).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (354).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (355).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (356).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (357).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (358).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (359).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (36).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (360).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (361).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (362).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (363).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (364).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (365).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (366).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (367).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (368).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (369).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (37).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (370).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (371).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (372).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (373).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (374).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (376).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (378).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (379).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (38).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (380).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (381).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (382).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (384).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (385).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (386).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (387).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (388).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (39).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (390).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (391).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (392).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (393).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (394).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (395).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (396).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (397).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (398).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (399).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (4).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (40).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (400).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (401).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (402).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (403).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (404).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (405).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (406).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (407).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (408).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (41).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (410).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (412).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (413).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (414).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (416).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (417).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (419).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (422).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (423).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (424).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (425).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (426).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (427).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (428).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (429).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (43).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (431).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (432).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (433).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (434).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (435).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (436).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (437).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (439).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (44).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (440).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (443).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (444).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (445).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (447).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (45).jpg  \n",
            " extracting: dataset/images/train/Sunny-Day (450).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (451).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (452).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (453).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (454).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (456).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (457).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (458).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (459).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (46).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (463).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (464).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (466).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (467).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (468).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (47).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (470).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (471).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (472).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (473).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (474).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (476).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (477).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (478).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (479).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (48).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (480).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (481).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (482).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (483).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (484).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (485).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (486).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (487).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (488).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (489).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (49).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (490).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (491).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (493).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (494).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (495).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (496).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (497).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (498).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (499).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (5).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (50).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (500).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (501).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (503).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (504).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (505).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (506).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (507).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (508).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (509).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (51).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (510).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (511).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (512).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (513).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (514).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (515).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (516).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (517).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (519).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (52).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (520).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (521).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (522).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (523).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (524).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (525).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (527).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (528).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (529).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (53).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (530).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (531).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (532).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (533).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (534).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (535).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (536).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (537).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (538).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (539).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (54).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (540).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (541).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (542).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (543).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (544).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (545).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (546).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (547).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (548).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (549).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (55).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (551).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (552).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (554).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (555).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (556).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (560).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (562).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (566).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (567).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (57).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (570).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (571).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (574).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (575).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (576).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (578).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (579).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (58).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (580).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (582).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (584).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (585).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (586).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (588).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (591).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (593).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (594).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (595).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (596).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (599).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (6).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (60).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (600).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (601).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (602).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (603).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (604).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (605).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (606).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (607).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (608).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (61).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (610).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (612).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (613).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (614).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (615).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (616).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (617).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (618).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (619).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (62).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (620).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (621).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (622).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (623).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (624).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (625).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (626).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (627).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (628).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (629).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (63).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (630).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (631).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (632).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (634).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (635).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (636).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (637).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (638).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (639).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (64).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (640).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (641).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (643).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (644).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (646).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (647).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (649).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (65).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (650).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (651).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (652).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (653).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (654).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (655).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (656).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (657).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (658).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (659).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (66).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (660).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (661).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (664).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (665).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (666).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (667).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (668).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (669).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (67).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (670).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (671).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (675).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (677).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (678).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (679).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (68).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (680).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (681).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (682).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (683).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (684).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (686).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (687).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (689).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (69).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (690).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (7).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (70).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (71).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (72).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (74).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (75).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (77).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (78).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (79).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (8).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (80).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (81).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (85).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (86).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (87).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (88).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (89).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (9).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (90).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (93).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (94).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (95).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day (96).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(691).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(692).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(693).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(694).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(695).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(696).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(697).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(698).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(699).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(700).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(701).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(702).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(703).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(704).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(705).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(706).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(707).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(708).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(709).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(710).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(711).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(712).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(713).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(714).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(715).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(716).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(717).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(718).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(719).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(720).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(721).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(722).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(723).jpg  \n",
            "  inflating: dataset/images/train/Sunny-Day(724).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(725).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(726).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(727).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(728).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(729).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(730).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(731).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(732).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(733).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(734).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(735).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(736).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(737).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(738).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(739).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(740).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(741).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(742).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(743).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(744).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(745).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(746).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(747).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(748).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(749).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(750).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(751).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(752).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(753).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(754).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(755).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(756).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(757).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(758).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(759).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(760).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(761).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(762).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(763).jpeg  \n",
            " extracting: dataset/images/train/Sunny-Day(764).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(765).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(766).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(767).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(768).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(769).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(770).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(771).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(772).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(773).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(774).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(775).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(776).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(777).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(778).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(779).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(780).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(781).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(782).jpeg  \n",
            " extracting: dataset/images/train/Sunny-Day(783).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(784).jpeg  \n",
            " extracting: dataset/images/train/Sunny-Day(785).jpeg  \n",
            " extracting: dataset/images/train/Sunny-Day(786).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(787).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(788).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(789).jpeg  \n",
            " extracting: dataset/images/train/Sunny-Day(790).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(791).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(792).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(793).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(794).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(795).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(796).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(797).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(798).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(799).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(800).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(801).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(802).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(803).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(804).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(805).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(806).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(807).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(808).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(809).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(810).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(811).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(812).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(813).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(814).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(815).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(816).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(817).jpeg  \n",
            "  inflating: dataset/images/train/Sunny-Day(818).jpeg  \n",
            "   creating: dataset/images/val/\n",
            "  inflating: dataset/images/val/night (651).jpg  \n",
            "  inflating: dataset/images/val/night (652).jpg  \n",
            "  inflating: dataset/images/val/night (653).jpg  \n",
            "  inflating: dataset/images/val/night (654).jpg  \n",
            "  inflating: dataset/images/val/night (655).jpg  \n",
            "  inflating: dataset/images/val/night (656).jpg  \n",
            "  inflating: dataset/images/val/night (657).jpg  \n",
            "  inflating: dataset/images/val/night (658).jpg  \n",
            "  inflating: dataset/images/val/night (659).jpg  \n",
            "  inflating: dataset/images/val/night (660).jpg  \n",
            "  inflating: dataset/images/val/night (661).jpg  \n",
            "  inflating: dataset/images/val/night (662).jpg  \n",
            "  inflating: dataset/images/val/night (663).jpg  \n",
            "  inflating: dataset/images/val/night (664).jpg  \n",
            "  inflating: dataset/images/val/night (665).jpg  \n",
            "  inflating: dataset/images/val/night (666).jpg  \n",
            "  inflating: dataset/images/val/night (667).jpg  \n",
            "  inflating: dataset/images/val/night (668).jpg  \n",
            "  inflating: dataset/images/val/night (669).jpg  \n",
            "  inflating: dataset/images/val/night (670).jpg  \n",
            "  inflating: dataset/images/val/night (671).jpg  \n",
            "  inflating: dataset/images/val/night (672).jpg  \n",
            "  inflating: dataset/images/val/night (673).jpg  \n",
            "  inflating: dataset/images/val/night (674).jpg  \n",
            "  inflating: dataset/images/val/night (675).jpg  \n",
            "  inflating: dataset/images/val/night (676).jpg  \n",
            "  inflating: dataset/images/val/night (677).jpg  \n",
            "  inflating: dataset/images/val/night (678).jpg  \n",
            "  inflating: dataset/images/val/night (679).jpg  \n",
            "  inflating: dataset/images/val/night (680).jpg  \n",
            "  inflating: dataset/images/val/night (681).jpg  \n",
            "  inflating: dataset/images/val/night (682).jpg  \n",
            "  inflating: dataset/images/val/night (683).jpg  \n",
            "  inflating: dataset/images/val/night (684).jpg  \n",
            "  inflating: dataset/images/val/night (685).jpg  \n",
            "  inflating: dataset/images/val/night (686).jpg  \n",
            "  inflating: dataset/images/val/night (687).jpg  \n",
            "  inflating: dataset/images/val/night (688).jpg  \n",
            "  inflating: dataset/images/val/night (689).jpg  \n",
            "  inflating: dataset/images/val/night (690).jpg  \n",
            "  inflating: dataset/images/val/night (691).jpg  \n",
            "  inflating: dataset/images/val/night (692).jpg  \n",
            "  inflating: dataset/images/val/night (693).jpg  \n",
            "  inflating: dataset/images/val/night (694).jpg  \n",
            "  inflating: dataset/images/val/night (695).jpg  \n",
            "  inflating: dataset/images/val/night (696).jpg  \n",
            "  inflating: dataset/images/val/night (697).jpg  \n",
            "  inflating: dataset/images/val/night (698).jpg  \n",
            "  inflating: dataset/images/val/night (699).jpg  \n",
            "  inflating: dataset/images/val/night (700).jpg  \n",
            "  inflating: dataset/images/val/rainy day (651).jpg  \n",
            "  inflating: dataset/images/val/rainy day (652).jpg  \n",
            "  inflating: dataset/images/val/rainy day (653).jpg  \n",
            "  inflating: dataset/images/val/rainy day (654).jpg  \n",
            "  inflating: dataset/images/val/rainy day (655).jpg  \n",
            "  inflating: dataset/images/val/rainy day (656).jpg  \n",
            "  inflating: dataset/images/val/rainy day (657).jpg  \n",
            "  inflating: dataset/images/val/rainy day (658).jpg  \n",
            "  inflating: dataset/images/val/rainy day (659).jpg  \n",
            "  inflating: dataset/images/val/rainy day (660).jpg  \n",
            "  inflating: dataset/images/val/rainy day (661).jpg  \n",
            "  inflating: dataset/images/val/rainy day (662).jpg  \n",
            "  inflating: dataset/images/val/rainy day (663).jpg  \n",
            "  inflating: dataset/images/val/rainy day (664).jpg  \n",
            "  inflating: dataset/images/val/rainy day (665).jpg  \n",
            "  inflating: dataset/images/val/rainy day (666).jpg  \n",
            "  inflating: dataset/images/val/rainy day (667).jpg  \n",
            "  inflating: dataset/images/val/rainy day (668).jpg  \n",
            "  inflating: dataset/images/val/rainy day (669).jpg  \n",
            "  inflating: dataset/images/val/rainy day (670).jpg  \n",
            "  inflating: dataset/images/val/rainy day (671).jpg  \n",
            "  inflating: dataset/images/val/rainy day (672).jpg  \n",
            "  inflating: dataset/images/val/rainy day (673).jpg  \n",
            "  inflating: dataset/images/val/rainy day (674).jpg  \n",
            "  inflating: dataset/images/val/rainy day (675).jpg  \n",
            "  inflating: dataset/images/val/rainy day (676).jpg  \n",
            "  inflating: dataset/images/val/rainy day (677).jpg  \n",
            "  inflating: dataset/images/val/rainy day (678).jpg  \n",
            "  inflating: dataset/images/val/rainy day (679).jpg  \n",
            "  inflating: dataset/images/val/rainy day (680).jpg  \n",
            "  inflating: dataset/images/val/rainy day (681).jpg  \n",
            "  inflating: dataset/images/val/rainy day (682).jpg  \n",
            "  inflating: dataset/images/val/rainy day (683).jpg  \n",
            "  inflating: dataset/images/val/rainy day (684).jpg  \n",
            "  inflating: dataset/images/val/rainy day (685).jpg  \n",
            "  inflating: dataset/images/val/rainy day (686).jpg  \n",
            "  inflating: dataset/images/val/rainy day (687).jpg  \n",
            "  inflating: dataset/images/val/rainy day (688).jpg  \n",
            "  inflating: dataset/images/val/rainy day (689).jpg  \n",
            "  inflating: dataset/images/val/rainy day (690).jpg  \n",
            "  inflating: dataset/images/val/rainy day (691).jpg  \n",
            "  inflating: dataset/images/val/rainy day (692).jpg  \n",
            "  inflating: dataset/images/val/rainy day (693).jpg  \n",
            "  inflating: dataset/images/val/rainy day (694).jpg  \n",
            "  inflating: dataset/images/val/rainy day (695).jpg  \n",
            "  inflating: dataset/images/val/rainy day (696).jpg  \n",
            "  inflating: dataset/images/val/rainy day (697).jpg  \n",
            "  inflating: dataset/images/val/rainy day (698).jpg  \n",
            "  inflating: dataset/images/val/rainy day (699).jpg  \n",
            "  inflating: dataset/images/val/rainy day (700).jpg  \n",
            "  inflating: dataset/images/val/rainynight (651).jpg  \n",
            "  inflating: dataset/images/val/rainynight (652).jpg  \n",
            "  inflating: dataset/images/val/rainynight (653).jpg  \n",
            "  inflating: dataset/images/val/rainynight (654).jpg  \n",
            "  inflating: dataset/images/val/rainynight (655).jpg  \n",
            "  inflating: dataset/images/val/rainynight (656).jpg  \n",
            "  inflating: dataset/images/val/rainynight (657).jpg  \n",
            "  inflating: dataset/images/val/rainynight (658).jpg  \n",
            "  inflating: dataset/images/val/rainynight (659).jpg  \n",
            "  inflating: dataset/images/val/rainynight (660).jpg  \n",
            "  inflating: dataset/images/val/rainynight (661).jpg  \n",
            "  inflating: dataset/images/val/rainynight (662).jpg  \n",
            "  inflating: dataset/images/val/rainynight (663).jpg  \n",
            "  inflating: dataset/images/val/rainynight (664).jpg  \n",
            "  inflating: dataset/images/val/rainynight (665).jpg  \n",
            "  inflating: dataset/images/val/rainynight (666).jpg  \n",
            "  inflating: dataset/images/val/rainynight (667).jpg  \n",
            "  inflating: dataset/images/val/rainynight (668).jpg  \n",
            "  inflating: dataset/images/val/rainynight (669).jpg  \n",
            "  inflating: dataset/images/val/rainynight (670).jpg  \n",
            "  inflating: dataset/images/val/rainynight (671).jpg  \n",
            "  inflating: dataset/images/val/rainynight (672).jpg  \n",
            "  inflating: dataset/images/val/rainynight (673).jpg  \n",
            "  inflating: dataset/images/val/rainynight (674).jpg  \n",
            "  inflating: dataset/images/val/rainynight (675).jpg  \n",
            "  inflating: dataset/images/val/rainynight (676).jpg  \n",
            "  inflating: dataset/images/val/rainynight (677).jpg  \n",
            "  inflating: dataset/images/val/rainynight (678).jpg  \n",
            "  inflating: dataset/images/val/rainynight (679).jpg  \n",
            "  inflating: dataset/images/val/rainynight (680).jpg  \n",
            "  inflating: dataset/images/val/rainynight (681).jpg  \n",
            "  inflating: dataset/images/val/rainynight (682).jpg  \n",
            "  inflating: dataset/images/val/rainynight (683).jpg  \n",
            "  inflating: dataset/images/val/rainynight (684).jpg  \n",
            "  inflating: dataset/images/val/rainynight (685).jpg  \n",
            "  inflating: dataset/images/val/rainynight (686).jpg  \n",
            "  inflating: dataset/images/val/rainynight (687).jpg  \n",
            "  inflating: dataset/images/val/rainynight (688).jpg  \n",
            "  inflating: dataset/images/val/rainynight (689).jpg  \n",
            "  inflating: dataset/images/val/rainynight (690).jpg  \n",
            "  inflating: dataset/images/val/rainynight (691).jpg  \n",
            "  inflating: dataset/images/val/rainynight (692).jpg  \n",
            "  inflating: dataset/images/val/rainynight (693).jpg  \n",
            "  inflating: dataset/images/val/rainynight (694).jpg  \n",
            "  inflating: dataset/images/val/rainynight (695).jpg  \n",
            "  inflating: dataset/images/val/rainynight (696).jpg  \n",
            "  inflating: dataset/images/val/rainynight (697).jpg  \n",
            "  inflating: dataset/images/val/rainynight (698).jpg  \n",
            "  inflating: dataset/images/val/rainynight (699).jpg  \n",
            "  inflating: dataset/images/val/rainynight (700).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (1).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (10).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (11).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (12).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (13).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (14).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (15).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (16).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (17).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (18).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (19).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (2).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (20).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (21).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (22).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (23).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (24).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (25).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (26).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (27).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (28).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (29).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (3).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (30).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (31).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (32).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (33).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (34).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (35).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (36).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (37).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (38).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (39).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (4).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (40).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (41).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (42).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (43).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (44).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (45).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (46).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (47).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (48).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (49).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (5).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (50).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (6).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (7).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (8).jpg  \n",
            "  inflating: dataset/images/val/sunnayday1 (9).jpg  \n",
            "   creating: dataset/labels/\n",
            "   creating: dataset/labels/train/\n",
            "  inflating: dataset/labels/train/night (1).txt  \n",
            "  inflating: dataset/labels/train/night (10).txt  \n",
            "  inflating: dataset/labels/train/night (100).txt  \n",
            "  inflating: dataset/labels/train/night (101).txt  \n",
            "  inflating: dataset/labels/train/night (102).txt  \n",
            "  inflating: dataset/labels/train/night (103).txt  \n",
            "  inflating: dataset/labels/train/night (104).txt  \n",
            " extracting: dataset/labels/train/night (105).txt  \n",
            "  inflating: dataset/labels/train/night (106).txt  \n",
            "  inflating: dataset/labels/train/night (107).txt  \n",
            " extracting: dataset/labels/train/night (108).txt  \n",
            " extracting: dataset/labels/train/night (109).txt  \n",
            "  inflating: dataset/labels/train/night (11).txt  \n",
            "  inflating: dataset/labels/train/night (110).txt  \n",
            "  inflating: dataset/labels/train/night (111).txt  \n",
            " extracting: dataset/labels/train/night (112).txt  \n",
            " extracting: dataset/labels/train/night (113).txt  \n",
            " extracting: dataset/labels/train/night (114).txt  \n",
            " extracting: dataset/labels/train/night (115).txt  \n",
            "  inflating: dataset/labels/train/night (116).txt  \n",
            "  inflating: dataset/labels/train/night (117).txt  \n",
            " extracting: dataset/labels/train/night (118).txt  \n",
            "  inflating: dataset/labels/train/night (119).txt  \n",
            "  inflating: dataset/labels/train/night (12).txt  \n",
            "  inflating: dataset/labels/train/night (120).txt  \n",
            "  inflating: dataset/labels/train/night (121).txt  \n",
            "  inflating: dataset/labels/train/night (122).txt  \n",
            "  inflating: dataset/labels/train/night (123).txt  \n",
            "  inflating: dataset/labels/train/night (124).txt  \n",
            "  inflating: dataset/labels/train/night (125).txt  \n",
            "  inflating: dataset/labels/train/night (126).txt  \n",
            "  inflating: dataset/labels/train/night (127).txt  \n",
            "  inflating: dataset/labels/train/night (128).txt  \n",
            "  inflating: dataset/labels/train/night (129).txt  \n",
            "  inflating: dataset/labels/train/night (13).txt  \n",
            "  inflating: dataset/labels/train/night (130).txt  \n",
            "  inflating: dataset/labels/train/night (131).txt  \n",
            "  inflating: dataset/labels/train/night (132).txt  \n",
            "  inflating: dataset/labels/train/night (133).txt  \n",
            "  inflating: dataset/labels/train/night (134).txt  \n",
            "  inflating: dataset/labels/train/night (135).txt  \n",
            "  inflating: dataset/labels/train/night (136).txt  \n",
            "  inflating: dataset/labels/train/night (137).txt  \n",
            "  inflating: dataset/labels/train/night (138).txt  \n",
            "  inflating: dataset/labels/train/night (139).txt  \n",
            "  inflating: dataset/labels/train/night (14).txt  \n",
            "  inflating: dataset/labels/train/night (140).txt  \n",
            "  inflating: dataset/labels/train/night (141).txt  \n",
            "  inflating: dataset/labels/train/night (142).txt  \n",
            "  inflating: dataset/labels/train/night (143).txt  \n",
            "  inflating: dataset/labels/train/night (144).txt  \n",
            "  inflating: dataset/labels/train/night (145).txt  \n",
            "  inflating: dataset/labels/train/night (146).txt  \n",
            "  inflating: dataset/labels/train/night (147).txt  \n",
            "  inflating: dataset/labels/train/night (148).txt  \n",
            "  inflating: dataset/labels/train/night (149).txt  \n",
            "  inflating: dataset/labels/train/night (15).txt  \n",
            "  inflating: dataset/labels/train/night (150).txt  \n",
            "  inflating: dataset/labels/train/night (151).txt  \n",
            "  inflating: dataset/labels/train/night (152).txt  \n",
            "  inflating: dataset/labels/train/night (153).txt  \n",
            "  inflating: dataset/labels/train/night (154).txt  \n",
            "  inflating: dataset/labels/train/night (155).txt  \n",
            "  inflating: dataset/labels/train/night (156).txt  \n",
            "  inflating: dataset/labels/train/night (157).txt  \n",
            "  inflating: dataset/labels/train/night (158).txt  \n",
            "  inflating: dataset/labels/train/night (159).txt  \n",
            "  inflating: dataset/labels/train/night (16).txt  \n",
            "  inflating: dataset/labels/train/night (160).txt  \n",
            "  inflating: dataset/labels/train/night (161).txt  \n",
            "  inflating: dataset/labels/train/night (162).txt  \n",
            "  inflating: dataset/labels/train/night (163).txt  \n",
            "  inflating: dataset/labels/train/night (164).txt  \n",
            "  inflating: dataset/labels/train/night (165).txt  \n",
            "  inflating: dataset/labels/train/night (166).txt  \n",
            "  inflating: dataset/labels/train/night (167).txt  \n",
            "  inflating: dataset/labels/train/night (168).txt  \n",
            "  inflating: dataset/labels/train/night (169).txt  \n",
            "  inflating: dataset/labels/train/night (17).txt  \n",
            "  inflating: dataset/labels/train/night (170).txt  \n",
            "  inflating: dataset/labels/train/night (171).txt  \n",
            "  inflating: dataset/labels/train/night (172).txt  \n",
            "  inflating: dataset/labels/train/night (173).txt  \n",
            "  inflating: dataset/labels/train/night (174).txt  \n",
            "  inflating: dataset/labels/train/night (175).txt  \n",
            "  inflating: dataset/labels/train/night (176).txt  \n",
            "  inflating: dataset/labels/train/night (177).txt  \n",
            "  inflating: dataset/labels/train/night (178).txt  \n",
            "  inflating: dataset/labels/train/night (179).txt  \n",
            "  inflating: dataset/labels/train/night (18).txt  \n",
            "  inflating: dataset/labels/train/night (180).txt  \n",
            "  inflating: dataset/labels/train/night (181).txt  \n",
            "  inflating: dataset/labels/train/night (182).txt  \n",
            "  inflating: dataset/labels/train/night (183).txt  \n",
            "  inflating: dataset/labels/train/night (184).txt  \n",
            "  inflating: dataset/labels/train/night (185).txt  \n",
            "  inflating: dataset/labels/train/night (186).txt  \n",
            "  inflating: dataset/labels/train/night (187).txt  \n",
            "  inflating: dataset/labels/train/night (188).txt  \n",
            "  inflating: dataset/labels/train/night (189).txt  \n",
            "  inflating: dataset/labels/train/night (19).txt  \n",
            "  inflating: dataset/labels/train/night (190).txt  \n",
            "  inflating: dataset/labels/train/night (191).txt  \n",
            "  inflating: dataset/labels/train/night (192).txt  \n",
            "  inflating: dataset/labels/train/night (193).txt  \n",
            "  inflating: dataset/labels/train/night (194).txt  \n",
            "  inflating: dataset/labels/train/night (195).txt  \n",
            "  inflating: dataset/labels/train/night (196).txt  \n",
            "  inflating: dataset/labels/train/night (197).txt  \n",
            "  inflating: dataset/labels/train/night (198).txt  \n",
            "  inflating: dataset/labels/train/night (199).txt  \n",
            "  inflating: dataset/labels/train/night (2).txt  \n",
            "  inflating: dataset/labels/train/night (20).txt  \n",
            "  inflating: dataset/labels/train/night (200).txt  \n",
            "  inflating: dataset/labels/train/night (201).txt  \n",
            "  inflating: dataset/labels/train/night (202).txt  \n",
            "  inflating: dataset/labels/train/night (203).txt  \n",
            "  inflating: dataset/labels/train/night (204).txt  \n",
            "  inflating: dataset/labels/train/night (205).txt  \n",
            "  inflating: dataset/labels/train/night (206).txt  \n",
            "  inflating: dataset/labels/train/night (207).txt  \n",
            "  inflating: dataset/labels/train/night (208).txt  \n",
            "  inflating: dataset/labels/train/night (209).txt  \n",
            "  inflating: dataset/labels/train/night (21).txt  \n",
            "  inflating: dataset/labels/train/night (210).txt  \n",
            "  inflating: dataset/labels/train/night (211).txt  \n",
            "  inflating: dataset/labels/train/night (212).txt  \n",
            "  inflating: dataset/labels/train/night (213).txt  \n",
            "  inflating: dataset/labels/train/night (214).txt  \n",
            "  inflating: dataset/labels/train/night (215).txt  \n",
            "  inflating: dataset/labels/train/night (216).txt  \n",
            "  inflating: dataset/labels/train/night (217).txt  \n",
            "  inflating: dataset/labels/train/night (218).txt  \n",
            "  inflating: dataset/labels/train/night (219).txt  \n",
            "  inflating: dataset/labels/train/night (22).txt  \n",
            "  inflating: dataset/labels/train/night (220).txt  \n",
            "  inflating: dataset/labels/train/night (221).txt  \n",
            "  inflating: dataset/labels/train/night (222).txt  \n",
            "  inflating: dataset/labels/train/night (223).txt  \n",
            "  inflating: dataset/labels/train/night (224).txt  \n",
            "  inflating: dataset/labels/train/night (225).txt  \n",
            "  inflating: dataset/labels/train/night (226).txt  \n",
            "  inflating: dataset/labels/train/night (227).txt  \n",
            "  inflating: dataset/labels/train/night (228).txt  \n",
            "  inflating: dataset/labels/train/night (229).txt  \n",
            "  inflating: dataset/labels/train/night (23).txt  \n",
            "  inflating: dataset/labels/train/night (230).txt  \n",
            "  inflating: dataset/labels/train/night (231).txt  \n",
            "  inflating: dataset/labels/train/night (232).txt  \n",
            "  inflating: dataset/labels/train/night (233).txt  \n",
            "  inflating: dataset/labels/train/night (234).txt  \n",
            "  inflating: dataset/labels/train/night (235).txt  \n",
            "  inflating: dataset/labels/train/night (236).txt  \n",
            "  inflating: dataset/labels/train/night (237).txt  \n",
            "  inflating: dataset/labels/train/night (238).txt  \n",
            "  inflating: dataset/labels/train/night (239).txt  \n",
            "  inflating: dataset/labels/train/night (24).txt  \n",
            "  inflating: dataset/labels/train/night (240).txt  \n",
            "  inflating: dataset/labels/train/night (241).txt  \n",
            "  inflating: dataset/labels/train/night (242).txt  \n",
            "  inflating: dataset/labels/train/night (243).txt  \n",
            "  inflating: dataset/labels/train/night (244).txt  \n",
            "  inflating: dataset/labels/train/night (245).txt  \n",
            "  inflating: dataset/labels/train/night (246).txt  \n",
            "  inflating: dataset/labels/train/night (247).txt  \n",
            "  inflating: dataset/labels/train/night (248).txt  \n",
            "  inflating: dataset/labels/train/night (249).txt  \n",
            "  inflating: dataset/labels/train/night (25).txt  \n",
            "  inflating: dataset/labels/train/night (250).txt  \n",
            "  inflating: dataset/labels/train/night (251).txt  \n",
            "  inflating: dataset/labels/train/night (252).txt  \n",
            "  inflating: dataset/labels/train/night (253).txt  \n",
            "  inflating: dataset/labels/train/night (254).txt  \n",
            "  inflating: dataset/labels/train/night (255).txt  \n",
            "  inflating: dataset/labels/train/night (256).txt  \n",
            "  inflating: dataset/labels/train/night (257).txt  \n",
            "  inflating: dataset/labels/train/night (258).txt  \n",
            "  inflating: dataset/labels/train/night (259).txt  \n",
            "  inflating: dataset/labels/train/night (26).txt  \n",
            "  inflating: dataset/labels/train/night (260).txt  \n",
            "  inflating: dataset/labels/train/night (261).txt  \n",
            "  inflating: dataset/labels/train/night (262).txt  \n",
            "  inflating: dataset/labels/train/night (263).txt  \n",
            "  inflating: dataset/labels/train/night (264).txt  \n",
            "  inflating: dataset/labels/train/night (265).txt  \n",
            "  inflating: dataset/labels/train/night (266).txt  \n",
            "  inflating: dataset/labels/train/night (267).txt  \n",
            "  inflating: dataset/labels/train/night (268).txt  \n",
            "  inflating: dataset/labels/train/night (269).txt  \n",
            "  inflating: dataset/labels/train/night (27).txt  \n",
            "  inflating: dataset/labels/train/night (270).txt  \n",
            "  inflating: dataset/labels/train/night (271).txt  \n",
            "  inflating: dataset/labels/train/night (272).txt  \n",
            "  inflating: dataset/labels/train/night (273).txt  \n",
            "  inflating: dataset/labels/train/night (274).txt  \n",
            "  inflating: dataset/labels/train/night (275).txt  \n",
            "  inflating: dataset/labels/train/night (276).txt  \n",
            "  inflating: dataset/labels/train/night (277).txt  \n",
            "  inflating: dataset/labels/train/night (278).txt  \n",
            "  inflating: dataset/labels/train/night (279).txt  \n",
            "  inflating: dataset/labels/train/night (28).txt  \n",
            "  inflating: dataset/labels/train/night (280).txt  \n",
            "  inflating: dataset/labels/train/night (281).txt  \n",
            "  inflating: dataset/labels/train/night (282).txt  \n",
            "  inflating: dataset/labels/train/night (283).txt  \n",
            "  inflating: dataset/labels/train/night (284).txt  \n",
            "  inflating: dataset/labels/train/night (285).txt  \n",
            "  inflating: dataset/labels/train/night (286).txt  \n",
            "  inflating: dataset/labels/train/night (287).txt  \n",
            "  inflating: dataset/labels/train/night (288).txt  \n",
            "  inflating: dataset/labels/train/night (289).txt  \n",
            "  inflating: dataset/labels/train/night (29).txt  \n",
            "  inflating: dataset/labels/train/night (290).txt  \n",
            "  inflating: dataset/labels/train/night (291).txt  \n",
            "  inflating: dataset/labels/train/night (292).txt  \n",
            "  inflating: dataset/labels/train/night (293).txt  \n",
            "  inflating: dataset/labels/train/night (294).txt  \n",
            "  inflating: dataset/labels/train/night (295).txt  \n",
            "  inflating: dataset/labels/train/night (296).txt  \n",
            "  inflating: dataset/labels/train/night (297).txt  \n",
            "  inflating: dataset/labels/train/night (298).txt  \n",
            "  inflating: dataset/labels/train/night (299).txt  \n",
            "  inflating: dataset/labels/train/night (3).txt  \n",
            "  inflating: dataset/labels/train/night (30).txt  \n",
            "  inflating: dataset/labels/train/night (300).txt  \n",
            "  inflating: dataset/labels/train/night (301).txt  \n",
            "  inflating: dataset/labels/train/night (302).txt  \n",
            "  inflating: dataset/labels/train/night (303).txt  \n",
            "  inflating: dataset/labels/train/night (304).txt  \n",
            "  inflating: dataset/labels/train/night (305).txt  \n",
            "  inflating: dataset/labels/train/night (306).txt  \n",
            "  inflating: dataset/labels/train/night (307).txt  \n",
            "  inflating: dataset/labels/train/night (308).txt  \n",
            "  inflating: dataset/labels/train/night (309).txt  \n",
            "  inflating: dataset/labels/train/night (31).txt  \n",
            "  inflating: dataset/labels/train/night (310).txt  \n",
            "  inflating: dataset/labels/train/night (311).txt  \n",
            "  inflating: dataset/labels/train/night (312).txt  \n",
            "  inflating: dataset/labels/train/night (313).txt  \n",
            "  inflating: dataset/labels/train/night (314).txt  \n",
            "  inflating: dataset/labels/train/night (315).txt  \n",
            "  inflating: dataset/labels/train/night (316).txt  \n",
            "  inflating: dataset/labels/train/night (317).txt  \n",
            "  inflating: dataset/labels/train/night (318).txt  \n",
            "  inflating: dataset/labels/train/night (319).txt  \n",
            "  inflating: dataset/labels/train/night (32).txt  \n",
            "  inflating: dataset/labels/train/night (320).txt  \n",
            "  inflating: dataset/labels/train/night (321).txt  \n",
            "  inflating: dataset/labels/train/night (322).txt  \n",
            "  inflating: dataset/labels/train/night (323).txt  \n",
            "  inflating: dataset/labels/train/night (324).txt  \n",
            "  inflating: dataset/labels/train/night (325).txt  \n",
            "  inflating: dataset/labels/train/night (326).txt  \n",
            "  inflating: dataset/labels/train/night (327).txt  \n",
            "  inflating: dataset/labels/train/night (328).txt  \n",
            "  inflating: dataset/labels/train/night (329).txt  \n",
            "  inflating: dataset/labels/train/night (33).txt  \n",
            "  inflating: dataset/labels/train/night (330).txt  \n",
            "  inflating: dataset/labels/train/night (331).txt  \n",
            "  inflating: dataset/labels/train/night (332).txt  \n",
            "  inflating: dataset/labels/train/night (333).txt  \n",
            "  inflating: dataset/labels/train/night (334).txt  \n",
            "  inflating: dataset/labels/train/night (335).txt  \n",
            "  inflating: dataset/labels/train/night (336).txt  \n",
            "  inflating: dataset/labels/train/night (337).txt  \n",
            "  inflating: dataset/labels/train/night (338).txt  \n",
            "  inflating: dataset/labels/train/night (339).txt  \n",
            "  inflating: dataset/labels/train/night (34).txt  \n",
            "  inflating: dataset/labels/train/night (340).txt  \n",
            "  inflating: dataset/labels/train/night (341).txt  \n",
            "  inflating: dataset/labels/train/night (342).txt  \n",
            "  inflating: dataset/labels/train/night (343).txt  \n",
            "  inflating: dataset/labels/train/night (344).txt  \n",
            "  inflating: dataset/labels/train/night (345).txt  \n",
            "  inflating: dataset/labels/train/night (346).txt  \n",
            "  inflating: dataset/labels/train/night (347).txt  \n",
            "  inflating: dataset/labels/train/night (348).txt  \n",
            "  inflating: dataset/labels/train/night (349).txt  \n",
            "  inflating: dataset/labels/train/night (35).txt  \n",
            "  inflating: dataset/labels/train/night (350).txt  \n",
            "  inflating: dataset/labels/train/night (351).txt  \n",
            "  inflating: dataset/labels/train/night (352).txt  \n",
            "  inflating: dataset/labels/train/night (353).txt  \n",
            "  inflating: dataset/labels/train/night (354).txt  \n",
            "  inflating: dataset/labels/train/night (355).txt  \n",
            "  inflating: dataset/labels/train/night (356).txt  \n",
            "  inflating: dataset/labels/train/night (357).txt  \n",
            "  inflating: dataset/labels/train/night (358).txt  \n",
            "  inflating: dataset/labels/train/night (359).txt  \n",
            "  inflating: dataset/labels/train/night (36).txt  \n",
            "  inflating: dataset/labels/train/night (360).txt  \n",
            "  inflating: dataset/labels/train/night (361).txt  \n",
            "  inflating: dataset/labels/train/night (362).txt  \n",
            "  inflating: dataset/labels/train/night (363).txt  \n",
            "  inflating: dataset/labels/train/night (364).txt  \n",
            "  inflating: dataset/labels/train/night (365).txt  \n",
            "  inflating: dataset/labels/train/night (366).txt  \n",
            "  inflating: dataset/labels/train/night (367).txt  \n",
            "  inflating: dataset/labels/train/night (368).txt  \n",
            "  inflating: dataset/labels/train/night (369).txt  \n",
            "  inflating: dataset/labels/train/night (37).txt  \n",
            "  inflating: dataset/labels/train/night (370).txt  \n",
            "  inflating: dataset/labels/train/night (371).txt  \n",
            "  inflating: dataset/labels/train/night (372).txt  \n",
            "  inflating: dataset/labels/train/night (373).txt  \n",
            "  inflating: dataset/labels/train/night (374).txt  \n",
            "  inflating: dataset/labels/train/night (375).txt  \n",
            "  inflating: dataset/labels/train/night (376).txt  \n",
            "  inflating: dataset/labels/train/night (377).txt  \n",
            "  inflating: dataset/labels/train/night (378).txt  \n",
            "  inflating: dataset/labels/train/night (379).txt  \n",
            "  inflating: dataset/labels/train/night (38).txt  \n",
            "  inflating: dataset/labels/train/night (380).txt  \n",
            "  inflating: dataset/labels/train/night (381).txt  \n",
            "  inflating: dataset/labels/train/night (382).txt  \n",
            "  inflating: dataset/labels/train/night (383).txt  \n",
            "  inflating: dataset/labels/train/night (384).txt  \n",
            "  inflating: dataset/labels/train/night (385).txt  \n",
            "  inflating: dataset/labels/train/night (386).txt  \n",
            "  inflating: dataset/labels/train/night (387).txt  \n",
            "  inflating: dataset/labels/train/night (388).txt  \n",
            "  inflating: dataset/labels/train/night (389).txt  \n",
            "  inflating: dataset/labels/train/night (39).txt  \n",
            "  inflating: dataset/labels/train/night (390).txt  \n",
            "  inflating: dataset/labels/train/night (391).txt  \n",
            "  inflating: dataset/labels/train/night (392).txt  \n",
            "  inflating: dataset/labels/train/night (393).txt  \n",
            "  inflating: dataset/labels/train/night (394).txt  \n",
            "  inflating: dataset/labels/train/night (395).txt  \n",
            "  inflating: dataset/labels/train/night (396).txt  \n",
            "  inflating: dataset/labels/train/night (397).txt  \n",
            "  inflating: dataset/labels/train/night (398).txt  \n",
            "  inflating: dataset/labels/train/night (399).txt  \n",
            "  inflating: dataset/labels/train/night (4).txt  \n",
            "  inflating: dataset/labels/train/night (40).txt  \n",
            "  inflating: dataset/labels/train/night (400).txt  \n",
            "  inflating: dataset/labels/train/night (401).txt  \n",
            "  inflating: dataset/labels/train/night (402).txt  \n",
            "  inflating: dataset/labels/train/night (403).txt  \n",
            "  inflating: dataset/labels/train/night (404).txt  \n",
            "  inflating: dataset/labels/train/night (405).txt  \n",
            "  inflating: dataset/labels/train/night (406).txt  \n",
            "  inflating: dataset/labels/train/night (407).txt  \n",
            "  inflating: dataset/labels/train/night (408).txt  \n",
            "  inflating: dataset/labels/train/night (409).txt  \n",
            "  inflating: dataset/labels/train/night (41).txt  \n",
            "  inflating: dataset/labels/train/night (410).txt  \n",
            "  inflating: dataset/labels/train/night (411).txt  \n",
            "  inflating: dataset/labels/train/night (412).txt  \n",
            "  inflating: dataset/labels/train/night (413).txt  \n",
            "  inflating: dataset/labels/train/night (414).txt  \n",
            "  inflating: dataset/labels/train/night (415).txt  \n",
            "  inflating: dataset/labels/train/night (416).txt  \n",
            "  inflating: dataset/labels/train/night (417).txt  \n",
            "  inflating: dataset/labels/train/night (418).txt  \n",
            "  inflating: dataset/labels/train/night (419).txt  \n",
            "  inflating: dataset/labels/train/night (42).txt  \n",
            "  inflating: dataset/labels/train/night (420).txt  \n",
            "  inflating: dataset/labels/train/night (421).txt  \n",
            "  inflating: dataset/labels/train/night (422).txt  \n",
            "  inflating: dataset/labels/train/night (423).txt  \n",
            "  inflating: dataset/labels/train/night (424).txt  \n",
            "  inflating: dataset/labels/train/night (425).txt  \n",
            "  inflating: dataset/labels/train/night (426).txt  \n",
            "  inflating: dataset/labels/train/night (427).txt  \n",
            "  inflating: dataset/labels/train/night (428).txt  \n",
            "  inflating: dataset/labels/train/night (429).txt  \n",
            "  inflating: dataset/labels/train/night (43).txt  \n",
            "  inflating: dataset/labels/train/night (430).txt  \n",
            "  inflating: dataset/labels/train/night (431).txt  \n",
            "  inflating: dataset/labels/train/night (432).txt  \n",
            "  inflating: dataset/labels/train/night (433).txt  \n",
            "  inflating: dataset/labels/train/night (434).txt  \n",
            "  inflating: dataset/labels/train/night (435).txt  \n",
            "  inflating: dataset/labels/train/night (436).txt  \n",
            "  inflating: dataset/labels/train/night (437).txt  \n",
            "  inflating: dataset/labels/train/night (438).txt  \n",
            "  inflating: dataset/labels/train/night (439).txt  \n",
            "  inflating: dataset/labels/train/night (44).txt  \n",
            "  inflating: dataset/labels/train/night (440).txt  \n",
            "  inflating: dataset/labels/train/night (441).txt  \n",
            "  inflating: dataset/labels/train/night (442).txt  \n",
            "  inflating: dataset/labels/train/night (443).txt  \n",
            "  inflating: dataset/labels/train/night (444).txt  \n",
            "  inflating: dataset/labels/train/night (445).txt  \n",
            "  inflating: dataset/labels/train/night (446).txt  \n",
            "  inflating: dataset/labels/train/night (447).txt  \n",
            "  inflating: dataset/labels/train/night (448).txt  \n",
            "  inflating: dataset/labels/train/night (449).txt  \n",
            "  inflating: dataset/labels/train/night (45).txt  \n",
            "  inflating: dataset/labels/train/night (450).txt  \n",
            "  inflating: dataset/labels/train/night (451).txt  \n",
            "  inflating: dataset/labels/train/night (452).txt  \n",
            "  inflating: dataset/labels/train/night (453).txt  \n",
            "  inflating: dataset/labels/train/night (454).txt  \n",
            "  inflating: dataset/labels/train/night (455).txt  \n",
            "  inflating: dataset/labels/train/night (456).txt  \n",
            "  inflating: dataset/labels/train/night (457).txt  \n",
            "  inflating: dataset/labels/train/night (458).txt  \n",
            "  inflating: dataset/labels/train/night (459).txt  \n",
            "  inflating: dataset/labels/train/night (46).txt  \n",
            "  inflating: dataset/labels/train/night (460).txt  \n",
            "  inflating: dataset/labels/train/night (461).txt  \n",
            "  inflating: dataset/labels/train/night (462).txt  \n",
            "  inflating: dataset/labels/train/night (463).txt  \n",
            "  inflating: dataset/labels/train/night (464).txt  \n",
            "  inflating: dataset/labels/train/night (465).txt  \n",
            "  inflating: dataset/labels/train/night (466).txt  \n",
            "  inflating: dataset/labels/train/night (467).txt  \n",
            "  inflating: dataset/labels/train/night (468).txt  \n",
            "  inflating: dataset/labels/train/night (469).txt  \n",
            "  inflating: dataset/labels/train/night (47).txt  \n",
            "  inflating: dataset/labels/train/night (470).txt  \n",
            "  inflating: dataset/labels/train/night (471).txt  \n",
            "  inflating: dataset/labels/train/night (472).txt  \n",
            "  inflating: dataset/labels/train/night (473).txt  \n",
            "  inflating: dataset/labels/train/night (474).txt  \n",
            "  inflating: dataset/labels/train/night (475).txt  \n",
            "  inflating: dataset/labels/train/night (476).txt  \n",
            "  inflating: dataset/labels/train/night (477).txt  \n",
            "  inflating: dataset/labels/train/night (478).txt  \n",
            "  inflating: dataset/labels/train/night (479).txt  \n",
            "  inflating: dataset/labels/train/night (48).txt  \n",
            "  inflating: dataset/labels/train/night (480).txt  \n",
            "  inflating: dataset/labels/train/night (481).txt  \n",
            "  inflating: dataset/labels/train/night (482).txt  \n",
            "  inflating: dataset/labels/train/night (483).txt  \n",
            "  inflating: dataset/labels/train/night (484).txt  \n",
            "  inflating: dataset/labels/train/night (485).txt  \n",
            "  inflating: dataset/labels/train/night (486).txt  \n",
            "  inflating: dataset/labels/train/night (487).txt  \n",
            "  inflating: dataset/labels/train/night (488).txt  \n",
            "  inflating: dataset/labels/train/night (489).txt  \n",
            "  inflating: dataset/labels/train/night (49).txt  \n",
            "  inflating: dataset/labels/train/night (490).txt  \n",
            "  inflating: dataset/labels/train/night (491).txt  \n",
            "  inflating: dataset/labels/train/night (492).txt  \n",
            "  inflating: dataset/labels/train/night (493).txt  \n",
            "  inflating: dataset/labels/train/night (494).txt  \n",
            "  inflating: dataset/labels/train/night (495).txt  \n",
            "  inflating: dataset/labels/train/night (496).txt  \n",
            "  inflating: dataset/labels/train/night (497).txt  \n",
            "  inflating: dataset/labels/train/night (498).txt  \n",
            "  inflating: dataset/labels/train/night (499).txt  \n",
            " extracting: dataset/labels/train/night (5).txt  \n",
            " extracting: dataset/labels/train/night (50).txt  \n",
            "  inflating: dataset/labels/train/night (500).txt  \n",
            "  inflating: dataset/labels/train/night (501).txt  \n",
            "  inflating: dataset/labels/train/night (502).txt  \n",
            "  inflating: dataset/labels/train/night (503).txt  \n",
            "  inflating: dataset/labels/train/night (504).txt  \n",
            "  inflating: dataset/labels/train/night (505).txt  \n",
            "  inflating: dataset/labels/train/night (506).txt  \n",
            "  inflating: dataset/labels/train/night (507).txt  \n",
            "  inflating: dataset/labels/train/night (508).txt  \n",
            "  inflating: dataset/labels/train/night (509).txt  \n",
            " extracting: dataset/labels/train/night (51).txt  \n",
            "  inflating: dataset/labels/train/night (510).txt  \n",
            "  inflating: dataset/labels/train/night (511).txt  \n",
            "  inflating: dataset/labels/train/night (512).txt  \n",
            "  inflating: dataset/labels/train/night (513).txt  \n",
            "  inflating: dataset/labels/train/night (514).txt  \n",
            "  inflating: dataset/labels/train/night (515).txt  \n",
            "  inflating: dataset/labels/train/night (516).txt  \n",
            "  inflating: dataset/labels/train/night (517).txt  \n",
            "  inflating: dataset/labels/train/night (518).txt  \n",
            "  inflating: dataset/labels/train/night (519).txt  \n",
            " extracting: dataset/labels/train/night (52).txt  \n",
            " extracting: dataset/labels/train/night (520).txt  \n",
            " extracting: dataset/labels/train/night (521).txt  \n",
            "  inflating: dataset/labels/train/night (522).txt  \n",
            "  inflating: dataset/labels/train/night (523).txt  \n",
            "  inflating: dataset/labels/train/night (524).txt  \n",
            "  inflating: dataset/labels/train/night (525).txt  \n",
            "  inflating: dataset/labels/train/night (526).txt  \n",
            "  inflating: dataset/labels/train/night (527).txt  \n",
            "  inflating: dataset/labels/train/night (528).txt  \n",
            "  inflating: dataset/labels/train/night (529).txt  \n",
            " extracting: dataset/labels/train/night (53).txt  \n",
            "  inflating: dataset/labels/train/night (530).txt  \n",
            "  inflating: dataset/labels/train/night (531).txt  \n",
            "  inflating: dataset/labels/train/night (532).txt  \n",
            "  inflating: dataset/labels/train/night (533).txt  \n",
            "  inflating: dataset/labels/train/night (534).txt  \n",
            "  inflating: dataset/labels/train/night (535).txt  \n",
            "  inflating: dataset/labels/train/night (536).txt  \n",
            "  inflating: dataset/labels/train/night (537).txt  \n",
            "  inflating: dataset/labels/train/night (538).txt  \n",
            "  inflating: dataset/labels/train/night (539).txt  \n",
            " extracting: dataset/labels/train/night (54).txt  \n",
            "  inflating: dataset/labels/train/night (540).txt  \n",
            "  inflating: dataset/labels/train/night (541).txt  \n",
            "  inflating: dataset/labels/train/night (542).txt  \n",
            "  inflating: dataset/labels/train/night (543).txt  \n",
            "  inflating: dataset/labels/train/night (544).txt  \n",
            "  inflating: dataset/labels/train/night (545).txt  \n",
            "  inflating: dataset/labels/train/night (546).txt  \n",
            "  inflating: dataset/labels/train/night (547).txt  \n",
            "  inflating: dataset/labels/train/night (548).txt  \n",
            "  inflating: dataset/labels/train/night (549).txt  \n",
            " extracting: dataset/labels/train/night (55).txt  \n",
            "  inflating: dataset/labels/train/night (550).txt  \n",
            "  inflating: dataset/labels/train/night (551).txt  \n",
            "  inflating: dataset/labels/train/night (552).txt  \n",
            "  inflating: dataset/labels/train/night (553).txt  \n",
            "  inflating: dataset/labels/train/night (554).txt  \n",
            "  inflating: dataset/labels/train/night (555).txt  \n",
            "  inflating: dataset/labels/train/night (556).txt  \n",
            "  inflating: dataset/labels/train/night (557).txt  \n",
            "  inflating: dataset/labels/train/night (558).txt  \n",
            "  inflating: dataset/labels/train/night (559).txt  \n",
            " extracting: dataset/labels/train/night (56).txt  \n",
            "  inflating: dataset/labels/train/night (560).txt  \n",
            "  inflating: dataset/labels/train/night (561).txt  \n",
            "  inflating: dataset/labels/train/night (562).txt  \n",
            "  inflating: dataset/labels/train/night (563).txt  \n",
            "  inflating: dataset/labels/train/night (564).txt  \n",
            "  inflating: dataset/labels/train/night (565).txt  \n",
            "  inflating: dataset/labels/train/night (566).txt  \n",
            "  inflating: dataset/labels/train/night (567).txt  \n",
            "  inflating: dataset/labels/train/night (568).txt  \n",
            "  inflating: dataset/labels/train/night (569).txt  \n",
            " extracting: dataset/labels/train/night (57).txt  \n",
            "  inflating: dataset/labels/train/night (570).txt  \n",
            "  inflating: dataset/labels/train/night (571).txt  \n",
            "  inflating: dataset/labels/train/night (572).txt  \n",
            "  inflating: dataset/labels/train/night (573).txt  \n",
            "  inflating: dataset/labels/train/night (574).txt  \n",
            "  inflating: dataset/labels/train/night (575).txt  \n",
            "  inflating: dataset/labels/train/night (576).txt  \n",
            "  inflating: dataset/labels/train/night (577).txt  \n",
            "  inflating: dataset/labels/train/night (578).txt  \n",
            "  inflating: dataset/labels/train/night (579).txt  \n",
            " extracting: dataset/labels/train/night (58).txt  \n",
            "  inflating: dataset/labels/train/night (580).txt  \n",
            "  inflating: dataset/labels/train/night (581).txt  \n",
            "  inflating: dataset/labels/train/night (582).txt  \n",
            "  inflating: dataset/labels/train/night (583).txt  \n",
            "  inflating: dataset/labels/train/night (584).txt  \n",
            "  inflating: dataset/labels/train/night (585).txt  \n",
            "  inflating: dataset/labels/train/night (586).txt  \n",
            "  inflating: dataset/labels/train/night (587).txt  \n",
            "  inflating: dataset/labels/train/night (588).txt  \n",
            "  inflating: dataset/labels/train/night (589).txt  \n",
            "  inflating: dataset/labels/train/night (59).txt  \n",
            "  inflating: dataset/labels/train/night (590).txt  \n",
            "  inflating: dataset/labels/train/night (591).txt  \n",
            "  inflating: dataset/labels/train/night (592).txt  \n",
            "  inflating: dataset/labels/train/night (593).txt  \n",
            "  inflating: dataset/labels/train/night (594).txt  \n",
            "  inflating: dataset/labels/train/night (595).txt  \n",
            "  inflating: dataset/labels/train/night (596).txt  \n",
            "  inflating: dataset/labels/train/night (597).txt  \n",
            "  inflating: dataset/labels/train/night (598).txt  \n",
            "  inflating: dataset/labels/train/night (599).txt  \n",
            "  inflating: dataset/labels/train/night (6).txt  \n",
            "  inflating: dataset/labels/train/night (60).txt  \n",
            "  inflating: dataset/labels/train/night (600).txt  \n",
            "  inflating: dataset/labels/train/night (601).txt  \n",
            "  inflating: dataset/labels/train/night (602).txt  \n",
            "  inflating: dataset/labels/train/night (603).txt  \n",
            "  inflating: dataset/labels/train/night (604).txt  \n",
            "  inflating: dataset/labels/train/night (605).txt  \n",
            "  inflating: dataset/labels/train/night (606).txt  \n",
            "  inflating: dataset/labels/train/night (607).txt  \n",
            "  inflating: dataset/labels/train/night (608).txt  \n",
            "  inflating: dataset/labels/train/night (609).txt  \n",
            "  inflating: dataset/labels/train/night (61).txt  \n",
            "  inflating: dataset/labels/train/night (610).txt  \n",
            "  inflating: dataset/labels/train/night (611).txt  \n",
            "  inflating: dataset/labels/train/night (612).txt  \n",
            "  inflating: dataset/labels/train/night (613).txt  \n",
            "  inflating: dataset/labels/train/night (614).txt  \n",
            "  inflating: dataset/labels/train/night (615).txt  \n",
            "  inflating: dataset/labels/train/night (616).txt  \n",
            "  inflating: dataset/labels/train/night (617).txt  \n",
            "  inflating: dataset/labels/train/night (618).txt  \n",
            "  inflating: dataset/labels/train/night (619).txt  \n",
            "  inflating: dataset/labels/train/night (62).txt  \n",
            "  inflating: dataset/labels/train/night (620).txt  \n",
            "  inflating: dataset/labels/train/night (621).txt  \n",
            "  inflating: dataset/labels/train/night (622).txt  \n",
            "  inflating: dataset/labels/train/night (623).txt  \n",
            "  inflating: dataset/labels/train/night (624).txt  \n",
            "  inflating: dataset/labels/train/night (625).txt  \n",
            "  inflating: dataset/labels/train/night (626).txt  \n",
            "  inflating: dataset/labels/train/night (627).txt  \n",
            "  inflating: dataset/labels/train/night (628).txt  \n",
            "  inflating: dataset/labels/train/night (629).txt  \n",
            "  inflating: dataset/labels/train/night (63).txt  \n",
            "  inflating: dataset/labels/train/night (630).txt  \n",
            " extracting: dataset/labels/train/night (631).txt  \n",
            " extracting: dataset/labels/train/night (632).txt  \n",
            " extracting: dataset/labels/train/night (633).txt  \n",
            "  inflating: dataset/labels/train/night (634).txt  \n",
            "  inflating: dataset/labels/train/night (635).txt  \n",
            "  inflating: dataset/labels/train/night (636).txt  \n",
            "  inflating: dataset/labels/train/night (637).txt  \n",
            "  inflating: dataset/labels/train/night (638).txt  \n",
            "  inflating: dataset/labels/train/night (639).txt  \n",
            "  inflating: dataset/labels/train/night (64).txt  \n",
            "  inflating: dataset/labels/train/night (640).txt  \n",
            "  inflating: dataset/labels/train/night (641).txt  \n",
            "  inflating: dataset/labels/train/night (642).txt  \n",
            "  inflating: dataset/labels/train/night (643).txt  \n",
            "  inflating: dataset/labels/train/night (644).txt  \n",
            "  inflating: dataset/labels/train/night (645).txt  \n",
            "  inflating: dataset/labels/train/night (646).txt  \n",
            "  inflating: dataset/labels/train/night (647).txt  \n",
            "  inflating: dataset/labels/train/night (648).txt  \n",
            "  inflating: dataset/labels/train/night (649).txt  \n",
            "  inflating: dataset/labels/train/night (65).txt  \n",
            "  inflating: dataset/labels/train/night (650).txt  \n",
            "  inflating: dataset/labels/train/night (66).txt  \n",
            "  inflating: dataset/labels/train/night (67).txt  \n",
            "  inflating: dataset/labels/train/night (68).txt  \n",
            "  inflating: dataset/labels/train/night (69).txt  \n",
            "  inflating: dataset/labels/train/night (7).txt  \n",
            "  inflating: dataset/labels/train/night (70).txt  \n",
            " extracting: dataset/labels/train/night (71).txt  \n",
            "  inflating: dataset/labels/train/night (72).txt  \n",
            " extracting: dataset/labels/train/night (73).txt  \n",
            "  inflating: dataset/labels/train/night (74).txt  \n",
            "  inflating: dataset/labels/train/night (75).txt  \n",
            "  inflating: dataset/labels/train/night (76).txt  \n",
            "  inflating: dataset/labels/train/night (77).txt  \n",
            "  inflating: dataset/labels/train/night (78).txt  \n",
            " extracting: dataset/labels/train/night (79).txt  \n",
            "  inflating: dataset/labels/train/night (8).txt  \n",
            "  inflating: dataset/labels/train/night (80).txt  \n",
            "  inflating: dataset/labels/train/night (81).txt  \n",
            "  inflating: dataset/labels/train/night (82).txt  \n",
            "  inflating: dataset/labels/train/night (83).txt  \n",
            "  inflating: dataset/labels/train/night (84).txt  \n",
            "  inflating: dataset/labels/train/night (85).txt  \n",
            "  inflating: dataset/labels/train/night (86).txt  \n",
            "  inflating: dataset/labels/train/night (87).txt  \n",
            "  inflating: dataset/labels/train/night (88).txt  \n",
            "  inflating: dataset/labels/train/night (89).txt  \n",
            "  inflating: dataset/labels/train/night (9).txt  \n",
            "  inflating: dataset/labels/train/night (90).txt  \n",
            "  inflating: dataset/labels/train/night (91).txt  \n",
            "  inflating: dataset/labels/train/night (92).txt  \n",
            "  inflating: dataset/labels/train/night (93).txt  \n",
            "  inflating: dataset/labels/train/night (94).txt  \n",
            "  inflating: dataset/labels/train/night (95).txt  \n",
            "  inflating: dataset/labels/train/night (96).txt  \n",
            "  inflating: dataset/labels/train/night (97).txt  \n",
            "  inflating: dataset/labels/train/night (98).txt  \n",
            "  inflating: dataset/labels/train/night (99).txt  \n",
            "  inflating: dataset/labels/train/rainy day (1).txt  \n",
            "  inflating: dataset/labels/train/rainy day (10).txt  \n",
            "  inflating: dataset/labels/train/rainy day (100).txt  \n",
            "  inflating: dataset/labels/train/rainy day (101).txt  \n",
            "  inflating: dataset/labels/train/rainy day (102).txt  \n",
            "  inflating: dataset/labels/train/rainy day (103).txt  \n",
            "  inflating: dataset/labels/train/rainy day (104).txt  \n",
            "  inflating: dataset/labels/train/rainy day (105).txt  \n",
            "  inflating: dataset/labels/train/rainy day (106).txt  \n",
            "  inflating: dataset/labels/train/rainy day (107).txt  \n",
            "  inflating: dataset/labels/train/rainy day (108).txt  \n",
            "  inflating: dataset/labels/train/rainy day (109).txt  \n",
            "  inflating: dataset/labels/train/rainy day (11).txt  \n",
            "  inflating: dataset/labels/train/rainy day (110).txt  \n",
            "  inflating: dataset/labels/train/rainy day (111).txt  \n",
            "  inflating: dataset/labels/train/rainy day (112).txt  \n",
            "  inflating: dataset/labels/train/rainy day (113).txt  \n",
            "  inflating: dataset/labels/train/rainy day (114).txt  \n",
            "  inflating: dataset/labels/train/rainy day (115).txt  \n",
            "  inflating: dataset/labels/train/rainy day (116).txt  \n",
            "  inflating: dataset/labels/train/rainy day (117).txt  \n",
            "  inflating: dataset/labels/train/rainy day (118).txt  \n",
            "  inflating: dataset/labels/train/rainy day (119).txt  \n",
            "  inflating: dataset/labels/train/rainy day (12).txt  \n",
            "  inflating: dataset/labels/train/rainy day (120).txt  \n",
            "  inflating: dataset/labels/train/rainy day (121).txt  \n",
            "  inflating: dataset/labels/train/rainy day (122).txt  \n",
            "  inflating: dataset/labels/train/rainy day (123).txt  \n",
            "  inflating: dataset/labels/train/rainy day (124).txt  \n",
            "  inflating: dataset/labels/train/rainy day (125).txt  \n",
            "  inflating: dataset/labels/train/rainy day (126).txt  \n",
            "  inflating: dataset/labels/train/rainy day (127).txt  \n",
            "  inflating: dataset/labels/train/rainy day (128).txt  \n",
            "  inflating: dataset/labels/train/rainy day (129).txt  \n",
            "  inflating: dataset/labels/train/rainy day (13).txt  \n",
            "  inflating: dataset/labels/train/rainy day (130).txt  \n",
            "  inflating: dataset/labels/train/rainy day (131).txt  \n",
            "  inflating: dataset/labels/train/rainy day (132).txt  \n",
            "  inflating: dataset/labels/train/rainy day (133).txt  \n",
            "  inflating: dataset/labels/train/rainy day (134).txt  \n",
            "  inflating: dataset/labels/train/rainy day (135).txt  \n",
            "  inflating: dataset/labels/train/rainy day (136).txt  \n",
            "  inflating: dataset/labels/train/rainy day (137).txt  \n",
            "  inflating: dataset/labels/train/rainy day (138).txt  \n",
            "  inflating: dataset/labels/train/rainy day (139).txt  \n",
            "  inflating: dataset/labels/train/rainy day (14).txt  \n",
            "  inflating: dataset/labels/train/rainy day (140).txt  \n",
            "  inflating: dataset/labels/train/rainy day (141).txt  \n",
            "  inflating: dataset/labels/train/rainy day (142).txt  \n",
            "  inflating: dataset/labels/train/rainy day (143).txt  \n",
            "  inflating: dataset/labels/train/rainy day (144).txt  \n",
            "  inflating: dataset/labels/train/rainy day (145).txt  \n",
            "  inflating: dataset/labels/train/rainy day (146).txt  \n",
            "  inflating: dataset/labels/train/rainy day (147).txt  \n",
            "  inflating: dataset/labels/train/rainy day (148).txt  \n",
            "  inflating: dataset/labels/train/rainy day (149).txt  \n",
            "  inflating: dataset/labels/train/rainy day (15).txt  \n",
            "  inflating: dataset/labels/train/rainy day (150).txt  \n",
            "  inflating: dataset/labels/train/rainy day (151).txt  \n",
            "  inflating: dataset/labels/train/rainy day (152).txt  \n",
            "  inflating: dataset/labels/train/rainy day (153).txt  \n",
            "  inflating: dataset/labels/train/rainy day (154).txt  \n",
            "  inflating: dataset/labels/train/rainy day (155).txt  \n",
            "  inflating: dataset/labels/train/rainy day (156).txt  \n",
            "  inflating: dataset/labels/train/rainy day (157).txt  \n",
            "  inflating: dataset/labels/train/rainy day (158).txt  \n",
            "  inflating: dataset/labels/train/rainy day (159).txt  \n",
            "  inflating: dataset/labels/train/rainy day (16).txt  \n",
            "  inflating: dataset/labels/train/rainy day (160).txt  \n",
            "  inflating: dataset/labels/train/rainy day (161).txt  \n",
            "  inflating: dataset/labels/train/rainy day (162).txt  \n",
            "  inflating: dataset/labels/train/rainy day (163).txt  \n",
            "  inflating: dataset/labels/train/rainy day (164).txt  \n",
            "  inflating: dataset/labels/train/rainy day (165).txt  \n",
            "  inflating: dataset/labels/train/rainy day (166).txt  \n",
            "  inflating: dataset/labels/train/rainy day (167).txt  \n",
            "  inflating: dataset/labels/train/rainy day (168).txt  \n",
            "  inflating: dataset/labels/train/rainy day (169).txt  \n",
            "  inflating: dataset/labels/train/rainy day (17).txt  \n",
            "  inflating: dataset/labels/train/rainy day (170).txt  \n",
            "  inflating: dataset/labels/train/rainy day (171).txt  \n",
            "  inflating: dataset/labels/train/rainy day (172).txt  \n",
            "  inflating: dataset/labels/train/rainy day (173).txt  \n",
            "  inflating: dataset/labels/train/rainy day (174).txt  \n",
            "  inflating: dataset/labels/train/rainy day (175).txt  \n",
            "  inflating: dataset/labels/train/rainy day (176).txt  \n",
            "  inflating: dataset/labels/train/rainy day (177).txt  \n",
            "  inflating: dataset/labels/train/rainy day (178).txt  \n",
            "  inflating: dataset/labels/train/rainy day (179).txt  \n",
            "  inflating: dataset/labels/train/rainy day (18).txt  \n",
            "  inflating: dataset/labels/train/rainy day (180).txt  \n",
            "  inflating: dataset/labels/train/rainy day (181).txt  \n",
            "  inflating: dataset/labels/train/rainy day (182).txt  \n",
            "  inflating: dataset/labels/train/rainy day (183).txt  \n",
            "  inflating: dataset/labels/train/rainy day (184).txt  \n",
            "  inflating: dataset/labels/train/rainy day (185).txt  \n",
            "  inflating: dataset/labels/train/rainy day (186).txt  \n",
            "  inflating: dataset/labels/train/rainy day (187).txt  \n",
            "  inflating: dataset/labels/train/rainy day (188).txt  \n",
            "  inflating: dataset/labels/train/rainy day (189).txt  \n",
            "  inflating: dataset/labels/train/rainy day (19).txt  \n",
            "  inflating: dataset/labels/train/rainy day (190).txt  \n",
            "  inflating: dataset/labels/train/rainy day (191).txt  \n",
            "  inflating: dataset/labels/train/rainy day (192).txt  \n",
            "  inflating: dataset/labels/train/rainy day (193).txt  \n",
            "  inflating: dataset/labels/train/rainy day (194).txt  \n",
            "  inflating: dataset/labels/train/rainy day (195).txt  \n",
            " extracting: dataset/labels/train/rainy day (196).txt  \n",
            "  inflating: dataset/labels/train/rainy day (197).txt  \n",
            "  inflating: dataset/labels/train/rainy day (198).txt  \n",
            "  inflating: dataset/labels/train/rainy day (199).txt  \n",
            "  inflating: dataset/labels/train/rainy day (2).txt  \n",
            "  inflating: dataset/labels/train/rainy day (20).txt  \n",
            "  inflating: dataset/labels/train/rainy day (200).txt  \n",
            " extracting: dataset/labels/train/rainy day (201).txt  \n",
            "  inflating: dataset/labels/train/rainy day (202).txt  \n",
            "  inflating: dataset/labels/train/rainy day (203).txt  \n",
            "  inflating: dataset/labels/train/rainy day (204).txt  \n",
            "  inflating: dataset/labels/train/rainy day (205).txt  \n",
            "  inflating: dataset/labels/train/rainy day (206).txt  \n",
            "  inflating: dataset/labels/train/rainy day (207).txt  \n",
            "  inflating: dataset/labels/train/rainy day (208).txt  \n",
            "  inflating: dataset/labels/train/rainy day (209).txt  \n",
            "  inflating: dataset/labels/train/rainy day (21).txt  \n",
            "  inflating: dataset/labels/train/rainy day (210).txt  \n",
            "  inflating: dataset/labels/train/rainy day (211).txt  \n",
            "  inflating: dataset/labels/train/rainy day (212).txt  \n",
            "  inflating: dataset/labels/train/rainy day (213).txt  \n",
            "  inflating: dataset/labels/train/rainy day (214).txt  \n",
            "  inflating: dataset/labels/train/rainy day (215).txt  \n",
            "  inflating: dataset/labels/train/rainy day (216).txt  \n",
            "  inflating: dataset/labels/train/rainy day (217).txt  \n",
            "  inflating: dataset/labels/train/rainy day (218).txt  \n",
            "  inflating: dataset/labels/train/rainy day (219).txt  \n",
            "  inflating: dataset/labels/train/rainy day (22).txt  \n",
            "  inflating: dataset/labels/train/rainy day (220).txt  \n",
            "  inflating: dataset/labels/train/rainy day (221).txt  \n",
            "  inflating: dataset/labels/train/rainy day (222).txt  \n",
            "  inflating: dataset/labels/train/rainy day (223).txt  \n",
            "  inflating: dataset/labels/train/rainy day (224).txt  \n",
            "  inflating: dataset/labels/train/rainy day (225).txt  \n",
            "  inflating: dataset/labels/train/rainy day (226).txt  \n",
            "  inflating: dataset/labels/train/rainy day (227).txt  \n",
            "  inflating: dataset/labels/train/rainy day (228).txt  \n",
            "  inflating: dataset/labels/train/rainy day (229).txt  \n",
            "  inflating: dataset/labels/train/rainy day (23).txt  \n",
            "  inflating: dataset/labels/train/rainy day (230).txt  \n",
            "  inflating: dataset/labels/train/rainy day (231).txt  \n",
            "  inflating: dataset/labels/train/rainy day (232).txt  \n",
            "  inflating: dataset/labels/train/rainy day (233).txt  \n",
            "  inflating: dataset/labels/train/rainy day (234).txt  \n",
            "  inflating: dataset/labels/train/rainy day (235).txt  \n",
            "  inflating: dataset/labels/train/rainy day (236).txt  \n",
            "  inflating: dataset/labels/train/rainy day (237).txt  \n",
            "  inflating: dataset/labels/train/rainy day (238).txt  \n",
            "  inflating: dataset/labels/train/rainy day (239).txt  \n",
            "  inflating: dataset/labels/train/rainy day (24).txt  \n",
            "  inflating: dataset/labels/train/rainy day (240).txt  \n",
            "  inflating: dataset/labels/train/rainy day (241).txt  \n",
            "  inflating: dataset/labels/train/rainy day (242).txt  \n",
            "  inflating: dataset/labels/train/rainy day (243).txt  \n",
            "  inflating: dataset/labels/train/rainy day (244).txt  \n",
            "  inflating: dataset/labels/train/rainy day (245).txt  \n",
            "  inflating: dataset/labels/train/rainy day (246).txt  \n",
            "  inflating: dataset/labels/train/rainy day (247).txt  \n",
            "  inflating: dataset/labels/train/rainy day (248).txt  \n",
            "  inflating: dataset/labels/train/rainy day (249).txt  \n",
            "  inflating: dataset/labels/train/rainy day (25).txt  \n",
            "  inflating: dataset/labels/train/rainy day (250).txt  \n",
            "  inflating: dataset/labels/train/rainy day (251).txt  \n",
            "  inflating: dataset/labels/train/rainy day (252).txt  \n",
            "  inflating: dataset/labels/train/rainy day (253).txt  \n",
            "  inflating: dataset/labels/train/rainy day (254).txt  \n",
            "  inflating: dataset/labels/train/rainy day (255).txt  \n",
            "  inflating: dataset/labels/train/rainy day (256).txt  \n",
            "  inflating: dataset/labels/train/rainy day (257).txt  \n",
            "  inflating: dataset/labels/train/rainy day (258).txt  \n",
            "  inflating: dataset/labels/train/rainy day (259).txt  \n",
            "  inflating: dataset/labels/train/rainy day (26).txt  \n",
            "  inflating: dataset/labels/train/rainy day (260).txt  \n",
            "  inflating: dataset/labels/train/rainy day (261).txt  \n",
            "  inflating: dataset/labels/train/rainy day (262).txt  \n",
            "  inflating: dataset/labels/train/rainy day (263).txt  \n",
            "  inflating: dataset/labels/train/rainy day (264).txt  \n",
            "  inflating: dataset/labels/train/rainy day (265).txt  \n",
            "  inflating: dataset/labels/train/rainy day (266).txt  \n",
            "  inflating: dataset/labels/train/rainy day (267).txt  \n",
            "  inflating: dataset/labels/train/rainy day (268).txt  \n",
            "  inflating: dataset/labels/train/rainy day (269).txt  \n",
            " extracting: dataset/labels/train/rainy day (27).txt  \n",
            "  inflating: dataset/labels/train/rainy day (270).txt  \n",
            "  inflating: dataset/labels/train/rainy day (271).txt  \n",
            "  inflating: dataset/labels/train/rainy day (272).txt  \n",
            "  inflating: dataset/labels/train/rainy day (273).txt  \n",
            "  inflating: dataset/labels/train/rainy day (274).txt  \n",
            " extracting: dataset/labels/train/rainy day (275).txt  \n",
            "  inflating: dataset/labels/train/rainy day (276).txt  \n",
            " extracting: dataset/labels/train/rainy day (277).txt  \n",
            " extracting: dataset/labels/train/rainy day (278).txt  \n",
            " extracting: dataset/labels/train/rainy day (279).txt  \n",
            "  inflating: dataset/labels/train/rainy day (28).txt  \n",
            " extracting: dataset/labels/train/rainy day (280).txt  \n",
            " extracting: dataset/labels/train/rainy day (281).txt  \n",
            "  inflating: dataset/labels/train/rainy day (282).txt  \n",
            " extracting: dataset/labels/train/rainy day (283).txt  \n",
            " extracting: dataset/labels/train/rainy day (284).txt  \n",
            " extracting: dataset/labels/train/rainy day (285).txt  \n",
            " extracting: dataset/labels/train/rainy day (286).txt  \n",
            " extracting: dataset/labels/train/rainy day (287).txt  \n",
            "  inflating: dataset/labels/train/rainy day (288).txt  \n",
            "  inflating: dataset/labels/train/rainy day (289).txt  \n",
            " extracting: dataset/labels/train/rainy day (29).txt  \n",
            "  inflating: dataset/labels/train/rainy day (290).txt  \n",
            "  inflating: dataset/labels/train/rainy day (291).txt  \n",
            "  inflating: dataset/labels/train/rainy day (292).txt  \n",
            "  inflating: dataset/labels/train/rainy day (293).txt  \n",
            "  inflating: dataset/labels/train/rainy day (294).txt  \n",
            "  inflating: dataset/labels/train/rainy day (295).txt  \n",
            "  inflating: dataset/labels/train/rainy day (296).txt  \n",
            "  inflating: dataset/labels/train/rainy day (297).txt  \n",
            "  inflating: dataset/labels/train/rainy day (298).txt  \n",
            "  inflating: dataset/labels/train/rainy day (299).txt  \n",
            "  inflating: dataset/labels/train/rainy day (3).txt  \n",
            "  inflating: dataset/labels/train/rainy day (30).txt  \n",
            " extracting: dataset/labels/train/rainy day (300).txt  \n",
            "  inflating: dataset/labels/train/rainy day (301).txt  \n",
            "  inflating: dataset/labels/train/rainy day (302).txt  \n",
            "  inflating: dataset/labels/train/rainy day (303).txt  \n",
            "  inflating: dataset/labels/train/rainy day (304).txt  \n",
            " extracting: dataset/labels/train/rainy day (305).txt  \n",
            "  inflating: dataset/labels/train/rainy day (306).txt  \n",
            "  inflating: dataset/labels/train/rainy day (307).txt  \n",
            "  inflating: dataset/labels/train/rainy day (308).txt  \n",
            "  inflating: dataset/labels/train/rainy day (309).txt  \n",
            " extracting: dataset/labels/train/rainy day (31).txt  \n",
            "  inflating: dataset/labels/train/rainy day (310).txt  \n",
            "  inflating: dataset/labels/train/rainy day (311).txt  \n",
            "  inflating: dataset/labels/train/rainy day (312).txt  \n",
            "  inflating: dataset/labels/train/rainy day (313).txt  \n",
            "  inflating: dataset/labels/train/rainy day (314).txt  \n",
            "  inflating: dataset/labels/train/rainy day (315).txt  \n",
            "  inflating: dataset/labels/train/rainy day (316).txt  \n",
            "  inflating: dataset/labels/train/rainy day (317).txt  \n",
            "  inflating: dataset/labels/train/rainy day (318).txt  \n",
            "  inflating: dataset/labels/train/rainy day (319).txt  \n",
            " extracting: dataset/labels/train/rainy day (32).txt  \n",
            "  inflating: dataset/labels/train/rainy day (320).txt  \n",
            "  inflating: dataset/labels/train/rainy day (321).txt  \n",
            "  inflating: dataset/labels/train/rainy day (322).txt  \n",
            "  inflating: dataset/labels/train/rainy day (323).txt  \n",
            "  inflating: dataset/labels/train/rainy day (324).txt  \n",
            "  inflating: dataset/labels/train/rainy day (325).txt  \n",
            "  inflating: dataset/labels/train/rainy day (326).txt  \n",
            "  inflating: dataset/labels/train/rainy day (327).txt  \n",
            "  inflating: dataset/labels/train/rainy day (328).txt  \n",
            "  inflating: dataset/labels/train/rainy day (329).txt  \n",
            " extracting: dataset/labels/train/rainy day (33).txt  \n",
            "  inflating: dataset/labels/train/rainy day (330).txt  \n",
            "  inflating: dataset/labels/train/rainy day (331).txt  \n",
            "  inflating: dataset/labels/train/rainy day (332).txt  \n",
            "  inflating: dataset/labels/train/rainy day (333).txt  \n",
            "  inflating: dataset/labels/train/rainy day (334).txt  \n",
            "  inflating: dataset/labels/train/rainy day (335).txt  \n",
            "  inflating: dataset/labels/train/rainy day (336).txt  \n",
            "  inflating: dataset/labels/train/rainy day (337).txt  \n",
            "  inflating: dataset/labels/train/rainy day (338).txt  \n",
            "  inflating: dataset/labels/train/rainy day (339).txt  \n",
            " extracting: dataset/labels/train/rainy day (34).txt  \n",
            "  inflating: dataset/labels/train/rainy day (340).txt  \n",
            "  inflating: dataset/labels/train/rainy day (341).txt  \n",
            "  inflating: dataset/labels/train/rainy day (342).txt  \n",
            "  inflating: dataset/labels/train/rainy day (343).txt  \n",
            "  inflating: dataset/labels/train/rainy day (344).txt  \n",
            "  inflating: dataset/labels/train/rainy day (345).txt  \n",
            "  inflating: dataset/labels/train/rainy day (346).txt  \n",
            "  inflating: dataset/labels/train/rainy day (347).txt  \n",
            " extracting: dataset/labels/train/rainy day (348).txt  \n",
            "  inflating: dataset/labels/train/rainy day (349).txt  \n",
            " extracting: dataset/labels/train/rainy day (35).txt  \n",
            "  inflating: dataset/labels/train/rainy day (350).txt  \n",
            "  inflating: dataset/labels/train/rainy day (351).txt  \n",
            "  inflating: dataset/labels/train/rainy day (352).txt  \n",
            "  inflating: dataset/labels/train/rainy day (353).txt  \n",
            "  inflating: dataset/labels/train/rainy day (354).txt  \n",
            "  inflating: dataset/labels/train/rainy day (355).txt  \n",
            "  inflating: dataset/labels/train/rainy day (356).txt  \n",
            "  inflating: dataset/labels/train/rainy day (357).txt  \n",
            "  inflating: dataset/labels/train/rainy day (358).txt  \n",
            "  inflating: dataset/labels/train/rainy day (359).txt  \n",
            "  inflating: dataset/labels/train/rainy day (36).txt  \n",
            "  inflating: dataset/labels/train/rainy day (360).txt  \n",
            "  inflating: dataset/labels/train/rainy day (361).txt  \n",
            "  inflating: dataset/labels/train/rainy day (362).txt  \n",
            "  inflating: dataset/labels/train/rainy day (363).txt  \n",
            "  inflating: dataset/labels/train/rainy day (364).txt  \n",
            "  inflating: dataset/labels/train/rainy day (365).txt  \n",
            "  inflating: dataset/labels/train/rainy day (366).txt  \n",
            "  inflating: dataset/labels/train/rainy day (367).txt  \n",
            "  inflating: dataset/labels/train/rainy day (368).txt  \n",
            "  inflating: dataset/labels/train/rainy day (369).txt  \n",
            "  inflating: dataset/labels/train/rainy day (37).txt  \n",
            "  inflating: dataset/labels/train/rainy day (370).txt  \n",
            "  inflating: dataset/labels/train/rainy day (371).txt  \n",
            "  inflating: dataset/labels/train/rainy day (372).txt  \n",
            "  inflating: dataset/labels/train/rainy day (373).txt  \n",
            "  inflating: dataset/labels/train/rainy day (374).txt  \n",
            "  inflating: dataset/labels/train/rainy day (375).txt  \n",
            "  inflating: dataset/labels/train/rainy day (376).txt  \n",
            "  inflating: dataset/labels/train/rainy day (377).txt  \n",
            "  inflating: dataset/labels/train/rainy day (378).txt  \n",
            "  inflating: dataset/labels/train/rainy day (379).txt  \n",
            "  inflating: dataset/labels/train/rainy day (38).txt  \n",
            "  inflating: dataset/labels/train/rainy day (380).txt  \n",
            "  inflating: dataset/labels/train/rainy day (381).txt  \n",
            " extracting: dataset/labels/train/rainy day (382).txt  \n",
            "  inflating: dataset/labels/train/rainy day (383).txt  \n",
            " extracting: dataset/labels/train/rainy day (384).txt  \n",
            " extracting: dataset/labels/train/rainy day (385).txt  \n",
            " extracting: dataset/labels/train/rainy day (386).txt  \n",
            " extracting: dataset/labels/train/rainy day (387).txt  \n",
            "  inflating: dataset/labels/train/rainy day (388).txt  \n",
            "  inflating: dataset/labels/train/rainy day (389).txt  \n",
            "  inflating: dataset/labels/train/rainy day (39).txt  \n",
            "  inflating: dataset/labels/train/rainy day (390).txt  \n",
            "  inflating: dataset/labels/train/rainy day (391).txt  \n",
            "  inflating: dataset/labels/train/rainy day (392).txt  \n",
            "  inflating: dataset/labels/train/rainy day (393).txt  \n",
            "  inflating: dataset/labels/train/rainy day (394).txt  \n",
            "  inflating: dataset/labels/train/rainy day (395).txt  \n",
            "  inflating: dataset/labels/train/rainy day (396).txt  \n",
            "  inflating: dataset/labels/train/rainy day (397).txt  \n",
            "  inflating: dataset/labels/train/rainy day (398).txt  \n",
            "  inflating: dataset/labels/train/rainy day (399).txt  \n",
            "  inflating: dataset/labels/train/rainy day (4).txt  \n",
            "  inflating: dataset/labels/train/rainy day (40).txt  \n",
            "  inflating: dataset/labels/train/rainy day (400).txt  \n",
            "  inflating: dataset/labels/train/rainy day (401).txt  \n",
            "  inflating: dataset/labels/train/rainy day (402).txt  \n",
            "  inflating: dataset/labels/train/rainy day (403).txt  \n",
            "  inflating: dataset/labels/train/rainy day (404).txt  \n",
            "  inflating: dataset/labels/train/rainy day (405).txt  \n",
            "  inflating: dataset/labels/train/rainy day (406).txt  \n",
            "  inflating: dataset/labels/train/rainy day (407).txt  \n",
            "  inflating: dataset/labels/train/rainy day (408).txt  \n",
            "  inflating: dataset/labels/train/rainy day (409).txt  \n",
            "  inflating: dataset/labels/train/rainy day (41).txt  \n",
            "  inflating: dataset/labels/train/rainy day (410).txt  \n",
            "  inflating: dataset/labels/train/rainy day (411).txt  \n",
            "  inflating: dataset/labels/train/rainy day (412).txt  \n",
            "  inflating: dataset/labels/train/rainy day (413).txt  \n",
            "  inflating: dataset/labels/train/rainy day (414).txt  \n",
            "  inflating: dataset/labels/train/rainy day (415).txt  \n",
            "  inflating: dataset/labels/train/rainy day (416).txt  \n",
            "  inflating: dataset/labels/train/rainy day (417).txt  \n",
            "  inflating: dataset/labels/train/rainy day (418).txt  \n",
            "  inflating: dataset/labels/train/rainy day (419).txt  \n",
            "  inflating: dataset/labels/train/rainy day (42).txt  \n",
            "  inflating: dataset/labels/train/rainy day (420).txt  \n",
            "  inflating: dataset/labels/train/rainy day (421).txt  \n",
            "  inflating: dataset/labels/train/rainy day (422).txt  \n",
            "  inflating: dataset/labels/train/rainy day (423).txt  \n",
            "  inflating: dataset/labels/train/rainy day (424).txt  \n",
            "  inflating: dataset/labels/train/rainy day (425).txt  \n",
            "  inflating: dataset/labels/train/rainy day (426).txt  \n",
            "  inflating: dataset/labels/train/rainy day (427).txt  \n",
            " extracting: dataset/labels/train/rainy day (428).txt  \n",
            "  inflating: dataset/labels/train/rainy day (429).txt  \n",
            "  inflating: dataset/labels/train/rainy day (43).txt  \n",
            "  inflating: dataset/labels/train/rainy day (430).txt  \n",
            " extracting: dataset/labels/train/rainy day (431).txt  \n",
            "  inflating: dataset/labels/train/rainy day (432).txt  \n",
            " extracting: dataset/labels/train/rainy day (433).txt  \n",
            " extracting: dataset/labels/train/rainy day (434).txt  \n",
            " extracting: dataset/labels/train/rainy day (435).txt  \n",
            " extracting: dataset/labels/train/rainy day (436).txt  \n",
            "  inflating: dataset/labels/train/rainy day (437).txt  \n",
            "  inflating: dataset/labels/train/rainy day (438).txt  \n",
            "  inflating: dataset/labels/train/rainy day (439).txt  \n",
            "  inflating: dataset/labels/train/rainy day (44).txt  \n",
            "  inflating: dataset/labels/train/rainy day (440).txt  \n",
            "  inflating: dataset/labels/train/rainy day (441).txt  \n",
            "  inflating: dataset/labels/train/rainy day (442).txt  \n",
            " extracting: dataset/labels/train/rainy day (443).txt  \n",
            " extracting: dataset/labels/train/rainy day (444).txt  \n",
            " extracting: dataset/labels/train/rainy day (445).txt  \n",
            " extracting: dataset/labels/train/rainy day (446).txt  \n",
            " extracting: dataset/labels/train/rainy day (447).txt  \n",
            "  inflating: dataset/labels/train/rainy day (448).txt  \n",
            "  inflating: dataset/labels/train/rainy day (449).txt  \n",
            "  inflating: dataset/labels/train/rainy day (45).txt  \n",
            "  inflating: dataset/labels/train/rainy day (450).txt  \n",
            "  inflating: dataset/labels/train/rainy day (451).txt  \n",
            "  inflating: dataset/labels/train/rainy day (452).txt  \n",
            "  inflating: dataset/labels/train/rainy day (453).txt  \n",
            "  inflating: dataset/labels/train/rainy day (454).txt  \n",
            "  inflating: dataset/labels/train/rainy day (455).txt  \n",
            "  inflating: dataset/labels/train/rainy day (456).txt  \n",
            "  inflating: dataset/labels/train/rainy day (457).txt  \n",
            "  inflating: dataset/labels/train/rainy day (458).txt  \n",
            "  inflating: dataset/labels/train/rainy day (459).txt  \n",
            "  inflating: dataset/labels/train/rainy day (46).txt  \n",
            "  inflating: dataset/labels/train/rainy day (460).txt  \n",
            "  inflating: dataset/labels/train/rainy day (461).txt  \n",
            "  inflating: dataset/labels/train/rainy day (462).txt  \n",
            "  inflating: dataset/labels/train/rainy day (463).txt  \n",
            "  inflating: dataset/labels/train/rainy day (464).txt  \n",
            "  inflating: dataset/labels/train/rainy day (465).txt  \n",
            "  inflating: dataset/labels/train/rainy day (466).txt  \n",
            "  inflating: dataset/labels/train/rainy day (467).txt  \n",
            " extracting: dataset/labels/train/rainy day (468).txt  \n",
            "  inflating: dataset/labels/train/rainy day (469).txt  \n",
            "  inflating: dataset/labels/train/rainy day (47).txt  \n",
            " extracting: dataset/labels/train/rainy day (470).txt  \n",
            " extracting: dataset/labels/train/rainy day (471).txt  \n",
            "  inflating: dataset/labels/train/rainy day (472).txt  \n",
            "  inflating: dataset/labels/train/rainy day (473).txt  \n",
            " extracting: dataset/labels/train/rainy day (474).txt  \n",
            "  inflating: dataset/labels/train/rainy day (475).txt  \n",
            " extracting: dataset/labels/train/rainy day (476).txt  \n",
            "  inflating: dataset/labels/train/rainy day (477).txt  \n",
            " extracting: dataset/labels/train/rainy day (478).txt  \n",
            "  inflating: dataset/labels/train/rainy day (479).txt  \n",
            "  inflating: dataset/labels/train/rainy day (48).txt  \n",
            "  inflating: dataset/labels/train/rainy day (480).txt  \n",
            "  inflating: dataset/labels/train/rainy day (481).txt  \n",
            "  inflating: dataset/labels/train/rainy day (482).txt  \n",
            "  inflating: dataset/labels/train/rainy day (483).txt  \n",
            "  inflating: dataset/labels/train/rainy day (484).txt  \n",
            "  inflating: dataset/labels/train/rainy day (485).txt  \n",
            "  inflating: dataset/labels/train/rainy day (486).txt  \n",
            "  inflating: dataset/labels/train/rainy day (487).txt  \n",
            "  inflating: dataset/labels/train/rainy day (488).txt  \n",
            "  inflating: dataset/labels/train/rainy day (489).txt  \n",
            "  inflating: dataset/labels/train/rainy day (49).txt  \n",
            "  inflating: dataset/labels/train/rainy day (490).txt  \n",
            "  inflating: dataset/labels/train/rainy day (491).txt  \n",
            "  inflating: dataset/labels/train/rainy day (492).txt  \n",
            "  inflating: dataset/labels/train/rainy day (493).txt  \n",
            "  inflating: dataset/labels/train/rainy day (494).txt  \n",
            "  inflating: dataset/labels/train/rainy day (495).txt  \n",
            "  inflating: dataset/labels/train/rainy day (496).txt  \n",
            "  inflating: dataset/labels/train/rainy day (497).txt  \n",
            "  inflating: dataset/labels/train/rainy day (498).txt  \n",
            "  inflating: dataset/labels/train/rainy day (499).txt  \n",
            "  inflating: dataset/labels/train/rainy day (5).txt  \n",
            "  inflating: dataset/labels/train/rainy day (50).txt  \n",
            " extracting: dataset/labels/train/rainy day (500).txt  \n",
            " extracting: dataset/labels/train/rainy day (501).txt  \n",
            "  inflating: dataset/labels/train/rainy day (502).txt  \n",
            "  inflating: dataset/labels/train/rainy day (503).txt  \n",
            "  inflating: dataset/labels/train/rainy day (504).txt  \n",
            "  inflating: dataset/labels/train/rainy day (505).txt  \n",
            "  inflating: dataset/labels/train/rainy day (506).txt  \n",
            "  inflating: dataset/labels/train/rainy day (507).txt  \n",
            "  inflating: dataset/labels/train/rainy day (508).txt  \n",
            "  inflating: dataset/labels/train/rainy day (509).txt  \n",
            "  inflating: dataset/labels/train/rainy day (51).txt  \n",
            "  inflating: dataset/labels/train/rainy day (510).txt  \n",
            "  inflating: dataset/labels/train/rainy day (511).txt  \n",
            "  inflating: dataset/labels/train/rainy day (512).txt  \n",
            "  inflating: dataset/labels/train/rainy day (513).txt  \n",
            "  inflating: dataset/labels/train/rainy day (514).txt  \n",
            "  inflating: dataset/labels/train/rainy day (515).txt  \n",
            "  inflating: dataset/labels/train/rainy day (516).txt  \n",
            "  inflating: dataset/labels/train/rainy day (517).txt  \n",
            "  inflating: dataset/labels/train/rainy day (518).txt  \n",
            "  inflating: dataset/labels/train/rainy day (519).txt  \n",
            "  inflating: dataset/labels/train/rainy day (52).txt  \n",
            "  inflating: dataset/labels/train/rainy day (520).txt  \n",
            " extracting: dataset/labels/train/rainy day (521).txt  \n",
            " extracting: dataset/labels/train/rainy day (522).txt  \n",
            " extracting: dataset/labels/train/rainy day (523).txt  \n",
            "  inflating: dataset/labels/train/rainy day (524).txt  \n",
            "  inflating: dataset/labels/train/rainy day (525).txt  \n",
            "  inflating: dataset/labels/train/rainy day (526).txt  \n",
            "  inflating: dataset/labels/train/rainy day (527).txt  \n",
            "  inflating: dataset/labels/train/rainy day (528).txt  \n",
            "  inflating: dataset/labels/train/rainy day (529).txt  \n",
            "  inflating: dataset/labels/train/rainy day (53).txt  \n",
            "  inflating: dataset/labels/train/rainy day (530).txt  \n",
            "  inflating: dataset/labels/train/rainy day (531).txt  \n",
            "  inflating: dataset/labels/train/rainy day (532).txt  \n",
            "  inflating: dataset/labels/train/rainy day (533).txt  \n",
            "  inflating: dataset/labels/train/rainy day (534).txt  \n",
            "  inflating: dataset/labels/train/rainy day (535).txt  \n",
            "  inflating: dataset/labels/train/rainy day (536).txt  \n",
            "  inflating: dataset/labels/train/rainy day (537).txt  \n",
            "  inflating: dataset/labels/train/rainy day (538).txt  \n",
            "  inflating: dataset/labels/train/rainy day (539).txt  \n",
            " extracting: dataset/labels/train/rainy day (54).txt  \n",
            "  inflating: dataset/labels/train/rainy day (540).txt  \n",
            "  inflating: dataset/labels/train/rainy day (541).txt  \n",
            "  inflating: dataset/labels/train/rainy day (542).txt  \n",
            "  inflating: dataset/labels/train/rainy day (543).txt  \n",
            "  inflating: dataset/labels/train/rainy day (544).txt  \n",
            "  inflating: dataset/labels/train/rainy day (545).txt  \n",
            "  inflating: dataset/labels/train/rainy day (546).txt  \n",
            "  inflating: dataset/labels/train/rainy day (547).txt  \n",
            "  inflating: dataset/labels/train/rainy day (548).txt  \n",
            "  inflating: dataset/labels/train/rainy day (549).txt  \n",
            "  inflating: dataset/labels/train/rainy day (55).txt  \n",
            "  inflating: dataset/labels/train/rainy day (550).txt  \n",
            "  inflating: dataset/labels/train/rainy day (551).txt  \n",
            "  inflating: dataset/labels/train/rainy day (552).txt  \n",
            "  inflating: dataset/labels/train/rainy day (553).txt  \n",
            "  inflating: dataset/labels/train/rainy day (554).txt  \n",
            "  inflating: dataset/labels/train/rainy day (555).txt  \n",
            "  inflating: dataset/labels/train/rainy day (556).txt  \n",
            "  inflating: dataset/labels/train/rainy day (557).txt  \n",
            "  inflating: dataset/labels/train/rainy day (558).txt  \n",
            "  inflating: dataset/labels/train/rainy day (559).txt  \n",
            "  inflating: dataset/labels/train/rainy day (56).txt  \n",
            "  inflating: dataset/labels/train/rainy day (560).txt  \n",
            "  inflating: dataset/labels/train/rainy day (561).txt  \n",
            "  inflating: dataset/labels/train/rainy day (562).txt  \n",
            "  inflating: dataset/labels/train/rainy day (563).txt  \n",
            "  inflating: dataset/labels/train/rainy day (564).txt  \n",
            "  inflating: dataset/labels/train/rainy day (565).txt  \n",
            "  inflating: dataset/labels/train/rainy day (566).txt  \n",
            "  inflating: dataset/labels/train/rainy day (567).txt  \n",
            "  inflating: dataset/labels/train/rainy day (568).txt  \n",
            "  inflating: dataset/labels/train/rainy day (569).txt  \n",
            "  inflating: dataset/labels/train/rainy day (57).txt  \n",
            "  inflating: dataset/labels/train/rainy day (570).txt  \n",
            "  inflating: dataset/labels/train/rainy day (571).txt  \n",
            "  inflating: dataset/labels/train/rainy day (572).txt  \n",
            "  inflating: dataset/labels/train/rainy day (573).txt  \n",
            "  inflating: dataset/labels/train/rainy day (574).txt  \n",
            "  inflating: dataset/labels/train/rainy day (575).txt  \n",
            "  inflating: dataset/labels/train/rainy day (576).txt  \n",
            "  inflating: dataset/labels/train/rainy day (577).txt  \n",
            "  inflating: dataset/labels/train/rainy day (578).txt  \n",
            "  inflating: dataset/labels/train/rainy day (579).txt  \n",
            "  inflating: dataset/labels/train/rainy day (58).txt  \n",
            "  inflating: dataset/labels/train/rainy day (580).txt  \n",
            "  inflating: dataset/labels/train/rainy day (581).txt  \n",
            "  inflating: dataset/labels/train/rainy day (582).txt  \n",
            "  inflating: dataset/labels/train/rainy day (583).txt  \n",
            "  inflating: dataset/labels/train/rainy day (584).txt  \n",
            "  inflating: dataset/labels/train/rainy day (585).txt  \n",
            "  inflating: dataset/labels/train/rainy day (586).txt  \n",
            "  inflating: dataset/labels/train/rainy day (587).txt  \n",
            "  inflating: dataset/labels/train/rainy day (588).txt  \n",
            "  inflating: dataset/labels/train/rainy day (589).txt  \n",
            "  inflating: dataset/labels/train/rainy day (59).txt  \n",
            "  inflating: dataset/labels/train/rainy day (590).txt  \n",
            "  inflating: dataset/labels/train/rainy day (591).txt  \n",
            "  inflating: dataset/labels/train/rainy day (592).txt  \n",
            "  inflating: dataset/labels/train/rainy day (593).txt  \n",
            "  inflating: dataset/labels/train/rainy day (594).txt  \n",
            "  inflating: dataset/labels/train/rainy day (595).txt  \n",
            "  inflating: dataset/labels/train/rainy day (596).txt  \n",
            "  inflating: dataset/labels/train/rainy day (597).txt  \n",
            "  inflating: dataset/labels/train/rainy day (598).txt  \n",
            "  inflating: dataset/labels/train/rainy day (599).txt  \n",
            "  inflating: dataset/labels/train/rainy day (6).txt  \n",
            "  inflating: dataset/labels/train/rainy day (60).txt  \n",
            "  inflating: dataset/labels/train/rainy day (600).txt  \n",
            "  inflating: dataset/labels/train/rainy day (601).txt  \n",
            "  inflating: dataset/labels/train/rainy day (602).txt  \n",
            "  inflating: dataset/labels/train/rainy day (603).txt  \n",
            "  inflating: dataset/labels/train/rainy day (604).txt  \n",
            "  inflating: dataset/labels/train/rainy day (605).txt  \n",
            "  inflating: dataset/labels/train/rainy day (606).txt  \n",
            "  inflating: dataset/labels/train/rainy day (607).txt  \n",
            "  inflating: dataset/labels/train/rainy day (608).txt  \n",
            "  inflating: dataset/labels/train/rainy day (609).txt  \n",
            "  inflating: dataset/labels/train/rainy day (61).txt  \n",
            "  inflating: dataset/labels/train/rainy day (610).txt  \n",
            "  inflating: dataset/labels/train/rainy day (611).txt  \n",
            "  inflating: dataset/labels/train/rainy day (612).txt  \n",
            "  inflating: dataset/labels/train/rainy day (613).txt  \n",
            " extracting: dataset/labels/train/rainy day (614).txt  \n",
            "  inflating: dataset/labels/train/rainy day (615).txt  \n",
            " extracting: dataset/labels/train/rainy day (616).txt  \n",
            "  inflating: dataset/labels/train/rainy day (617).txt  \n",
            " extracting: dataset/labels/train/rainy day (618).txt  \n",
            " extracting: dataset/labels/train/rainy day (619).txt  \n",
            "  inflating: dataset/labels/train/rainy day (62).txt  \n",
            " extracting: dataset/labels/train/rainy day (620).txt  \n",
            "  inflating: dataset/labels/train/rainy day (621).txt  \n",
            "  inflating: dataset/labels/train/rainy day (622).txt  \n",
            " extracting: dataset/labels/train/rainy day (623).txt  \n",
            " extracting: dataset/labels/train/rainy day (624).txt  \n",
            "  inflating: dataset/labels/train/rainy day (625).txt  \n",
            "  inflating: dataset/labels/train/rainy day (626).txt  \n",
            "  inflating: dataset/labels/train/rainy day (627).txt  \n",
            "  inflating: dataset/labels/train/rainy day (628).txt  \n",
            "  inflating: dataset/labels/train/rainy day (629).txt  \n",
            "  inflating: dataset/labels/train/rainy day (63).txt  \n",
            "  inflating: dataset/labels/train/rainy day (630).txt  \n",
            " extracting: dataset/labels/train/rainy day (631).txt  \n",
            " extracting: dataset/labels/train/rainy day (632).txt  \n",
            " extracting: dataset/labels/train/rainy day (633).txt  \n",
            "  inflating: dataset/labels/train/rainy day (634).txt  \n",
            "  inflating: dataset/labels/train/rainy day (635).txt  \n",
            " extracting: dataset/labels/train/rainy day (636).txt  \n",
            " extracting: dataset/labels/train/rainy day (637).txt  \n",
            " extracting: dataset/labels/train/rainy day (638).txt  \n",
            " extracting: dataset/labels/train/rainy day (639).txt  \n",
            "  inflating: dataset/labels/train/rainy day (64).txt  \n",
            "  inflating: dataset/labels/train/rainy day (640).txt  \n",
            " extracting: dataset/labels/train/rainy day (641).txt  \n",
            " extracting: dataset/labels/train/rainy day (642).txt  \n",
            " extracting: dataset/labels/train/rainy day (643).txt  \n",
            "  inflating: dataset/labels/train/rainy day (644).txt  \n",
            "  inflating: dataset/labels/train/rainy day (645).txt  \n",
            "  inflating: dataset/labels/train/rainy day (646).txt  \n",
            "  inflating: dataset/labels/train/rainy day (647).txt  \n",
            "  inflating: dataset/labels/train/rainy day (648).txt  \n",
            "  inflating: dataset/labels/train/rainy day (649).txt  \n",
            " extracting: dataset/labels/train/rainy day (65).txt  \n",
            "  inflating: dataset/labels/train/rainy day (650).txt  \n",
            " extracting: dataset/labels/train/rainy day (66).txt  \n",
            " extracting: dataset/labels/train/rainy day (67).txt  \n",
            "  inflating: dataset/labels/train/rainy day (68).txt  \n",
            "  inflating: dataset/labels/train/rainy day (69).txt  \n",
            "  inflating: dataset/labels/train/rainy day (7).txt  \n",
            "  inflating: dataset/labels/train/rainy day (70).txt  \n",
            "  inflating: dataset/labels/train/rainy day (71).txt  \n",
            "  inflating: dataset/labels/train/rainy day (72).txt  \n",
            " extracting: dataset/labels/train/rainy day (73).txt  \n",
            "  inflating: dataset/labels/train/rainy day (74).txt  \n",
            "  inflating: dataset/labels/train/rainy day (75).txt  \n",
            "  inflating: dataset/labels/train/rainy day (76).txt  \n",
            "  inflating: dataset/labels/train/rainy day (77).txt  \n",
            "  inflating: dataset/labels/train/rainy day (78).txt  \n",
            " extracting: dataset/labels/train/rainy day (79).txt  \n",
            "  inflating: dataset/labels/train/rainy day (8).txt  \n",
            "  inflating: dataset/labels/train/rainy day (80).txt  \n",
            " extracting: dataset/labels/train/rainy day (81).txt  \n",
            " extracting: dataset/labels/train/rainy day (82).txt  \n",
            " extracting: dataset/labels/train/rainy day (83).txt  \n",
            " extracting: dataset/labels/train/rainy day (84).txt  \n",
            "  inflating: dataset/labels/train/rainy day (85).txt  \n",
            "  inflating: dataset/labels/train/rainy day (86).txt  \n",
            "  inflating: dataset/labels/train/rainy day (87).txt  \n",
            "  inflating: dataset/labels/train/rainy day (88).txt  \n",
            "  inflating: dataset/labels/train/rainy day (89).txt  \n",
            "  inflating: dataset/labels/train/rainy day (9).txt  \n",
            "  inflating: dataset/labels/train/rainy day (90).txt  \n",
            "  inflating: dataset/labels/train/rainy day (91).txt  \n",
            "  inflating: dataset/labels/train/rainy day (92).txt  \n",
            "  inflating: dataset/labels/train/rainy day (93).txt  \n",
            "  inflating: dataset/labels/train/rainy day (94).txt  \n",
            "  inflating: dataset/labels/train/rainy day (95).txt  \n",
            "  inflating: dataset/labels/train/rainy day (96).txt  \n",
            "  inflating: dataset/labels/train/rainy day (97).txt  \n",
            "  inflating: dataset/labels/train/rainy day (98).txt  \n",
            "  inflating: dataset/labels/train/rainy day (99).txt  \n",
            "  inflating: dataset/labels/train/rainynight (1).txt  \n",
            "  inflating: dataset/labels/train/rainynight (10).txt  \n",
            "  inflating: dataset/labels/train/rainynight (100).txt  \n",
            "  inflating: dataset/labels/train/rainynight (101).txt  \n",
            "  inflating: dataset/labels/train/rainynight (102).txt  \n",
            "  inflating: dataset/labels/train/rainynight (103).txt  \n",
            "  inflating: dataset/labels/train/rainynight (104).txt  \n",
            "  inflating: dataset/labels/train/rainynight (105).txt  \n",
            "  inflating: dataset/labels/train/rainynight (106).txt  \n",
            "  inflating: dataset/labels/train/rainynight (107).txt  \n",
            "  inflating: dataset/labels/train/rainynight (108).txt  \n",
            "  inflating: dataset/labels/train/rainynight (109).txt  \n",
            "  inflating: dataset/labels/train/rainynight (11).txt  \n",
            "  inflating: dataset/labels/train/rainynight (110).txt  \n",
            "  inflating: dataset/labels/train/rainynight (111).txt  \n",
            "  inflating: dataset/labels/train/rainynight (112).txt  \n",
            "  inflating: dataset/labels/train/rainynight (113).txt  \n",
            "  inflating: dataset/labels/train/rainynight (114).txt  \n",
            "  inflating: dataset/labels/train/rainynight (115).txt  \n",
            "  inflating: dataset/labels/train/rainynight (116).txt  \n",
            "  inflating: dataset/labels/train/rainynight (117).txt  \n",
            "  inflating: dataset/labels/train/rainynight (118).txt  \n",
            "  inflating: dataset/labels/train/rainynight (119).txt  \n",
            "  inflating: dataset/labels/train/rainynight (12).txt  \n",
            "  inflating: dataset/labels/train/rainynight (120).txt  \n",
            "  inflating: dataset/labels/train/rainynight (121).txt  \n",
            "  inflating: dataset/labels/train/rainynight (122).txt  \n",
            "  inflating: dataset/labels/train/rainynight (123).txt  \n",
            "  inflating: dataset/labels/train/rainynight (124).txt  \n",
            "  inflating: dataset/labels/train/rainynight (125).txt  \n",
            "  inflating: dataset/labels/train/rainynight (126).txt  \n",
            "  inflating: dataset/labels/train/rainynight (127).txt  \n",
            "  inflating: dataset/labels/train/rainynight (128).txt  \n",
            "  inflating: dataset/labels/train/rainynight (129).txt  \n",
            "  inflating: dataset/labels/train/rainynight (13).txt  \n",
            "  inflating: dataset/labels/train/rainynight (130).txt  \n",
            "  inflating: dataset/labels/train/rainynight (131).txt  \n",
            "  inflating: dataset/labels/train/rainynight (132).txt  \n",
            "  inflating: dataset/labels/train/rainynight (133).txt  \n",
            "  inflating: dataset/labels/train/rainynight (134).txt  \n",
            "  inflating: dataset/labels/train/rainynight (135).txt  \n",
            "  inflating: dataset/labels/train/rainynight (136).txt  \n",
            "  inflating: dataset/labels/train/rainynight (137).txt  \n",
            "  inflating: dataset/labels/train/rainynight (138).txt  \n",
            "  inflating: dataset/labels/train/rainynight (139).txt  \n",
            "  inflating: dataset/labels/train/rainynight (14).txt  \n",
            "  inflating: dataset/labels/train/rainynight (140).txt  \n",
            "  inflating: dataset/labels/train/rainynight (141).txt  \n",
            "  inflating: dataset/labels/train/rainynight (142).txt  \n",
            "  inflating: dataset/labels/train/rainynight (143).txt  \n",
            "  inflating: dataset/labels/train/rainynight (144).txt  \n",
            "  inflating: dataset/labels/train/rainynight (145).txt  \n",
            "  inflating: dataset/labels/train/rainynight (146).txt  \n",
            "  inflating: dataset/labels/train/rainynight (147).txt  \n",
            "  inflating: dataset/labels/train/rainynight (148).txt  \n",
            "  inflating: dataset/labels/train/rainynight (149).txt  \n",
            "  inflating: dataset/labels/train/rainynight (15).txt  \n",
            "  inflating: dataset/labels/train/rainynight (150).txt  \n",
            "  inflating: dataset/labels/train/rainynight (151).txt  \n",
            "  inflating: dataset/labels/train/rainynight (152).txt  \n",
            "  inflating: dataset/labels/train/rainynight (153).txt  \n",
            "  inflating: dataset/labels/train/rainynight (154).txt  \n",
            "  inflating: dataset/labels/train/rainynight (155).txt  \n",
            "  inflating: dataset/labels/train/rainynight (156).txt  \n",
            "  inflating: dataset/labels/train/rainynight (157).txt  \n",
            "  inflating: dataset/labels/train/rainynight (158).txt  \n",
            "  inflating: dataset/labels/train/rainynight (159).txt  \n",
            "  inflating: dataset/labels/train/rainynight (16).txt  \n",
            "  inflating: dataset/labels/train/rainynight (160).txt  \n",
            "  inflating: dataset/labels/train/rainynight (161).txt  \n",
            "  inflating: dataset/labels/train/rainynight (162).txt  \n",
            "  inflating: dataset/labels/train/rainynight (163).txt  \n",
            "  inflating: dataset/labels/train/rainynight (164).txt  \n",
            "  inflating: dataset/labels/train/rainynight (165).txt  \n",
            "  inflating: dataset/labels/train/rainynight (166).txt  \n",
            "  inflating: dataset/labels/train/rainynight (167).txt  \n",
            "  inflating: dataset/labels/train/rainynight (168).txt  \n",
            "  inflating: dataset/labels/train/rainynight (169).txt  \n",
            "  inflating: dataset/labels/train/rainynight (17).txt  \n",
            "  inflating: dataset/labels/train/rainynight (170).txt  \n",
            "  inflating: dataset/labels/train/rainynight (171).txt  \n",
            "  inflating: dataset/labels/train/rainynight (172).txt  \n",
            "  inflating: dataset/labels/train/rainynight (173).txt  \n",
            "  inflating: dataset/labels/train/rainynight (174).txt  \n",
            "  inflating: dataset/labels/train/rainynight (175).txt  \n",
            "  inflating: dataset/labels/train/rainynight (176).txt  \n",
            "  inflating: dataset/labels/train/rainynight (177).txt  \n",
            "  inflating: dataset/labels/train/rainynight (178).txt  \n",
            "  inflating: dataset/labels/train/rainynight (179).txt  \n",
            " extracting: dataset/labels/train/rainynight (18).txt  \n",
            "  inflating: dataset/labels/train/rainynight (180).txt  \n",
            "  inflating: dataset/labels/train/rainynight (181).txt  \n",
            "  inflating: dataset/labels/train/rainynight (182).txt  \n",
            "  inflating: dataset/labels/train/rainynight (183).txt  \n",
            "  inflating: dataset/labels/train/rainynight (184).txt  \n",
            "  inflating: dataset/labels/train/rainynight (185).txt  \n",
            "  inflating: dataset/labels/train/rainynight (186).txt  \n",
            "  inflating: dataset/labels/train/rainynight (187).txt  \n",
            "  inflating: dataset/labels/train/rainynight (188).txt  \n",
            "  inflating: dataset/labels/train/rainynight (189).txt  \n",
            " extracting: dataset/labels/train/rainynight (19).txt  \n",
            "  inflating: dataset/labels/train/rainynight (190).txt  \n",
            "  inflating: dataset/labels/train/rainynight (191).txt  \n",
            "  inflating: dataset/labels/train/rainynight (192).txt  \n",
            "  inflating: dataset/labels/train/rainynight (193).txt  \n",
            "  inflating: dataset/labels/train/rainynight (194).txt  \n",
            "  inflating: dataset/labels/train/rainynight (195).txt  \n",
            "  inflating: dataset/labels/train/rainynight (196).txt  \n",
            "  inflating: dataset/labels/train/rainynight (197).txt  \n",
            "  inflating: dataset/labels/train/rainynight (198).txt  \n",
            "  inflating: dataset/labels/train/rainynight (199).txt  \n",
            "  inflating: dataset/labels/train/rainynight (2).txt  \n",
            "  inflating: dataset/labels/train/rainynight (20).txt  \n",
            "  inflating: dataset/labels/train/rainynight (200).txt  \n",
            "  inflating: dataset/labels/train/rainynight (201).txt  \n",
            "  inflating: dataset/labels/train/rainynight (202).txt  \n",
            "  inflating: dataset/labels/train/rainynight (203).txt  \n",
            "  inflating: dataset/labels/train/rainynight (204).txt  \n",
            "  inflating: dataset/labels/train/rainynight (205).txt  \n",
            "  inflating: dataset/labels/train/rainynight (206).txt  \n",
            "  inflating: dataset/labels/train/rainynight (207).txt  \n",
            "  inflating: dataset/labels/train/rainynight (208).txt  \n",
            "  inflating: dataset/labels/train/rainynight (209).txt  \n",
            "  inflating: dataset/labels/train/rainynight (21).txt  \n",
            "  inflating: dataset/labels/train/rainynight (210).txt  \n",
            "  inflating: dataset/labels/train/rainynight (211).txt  \n",
            "  inflating: dataset/labels/train/rainynight (212).txt  \n",
            "  inflating: dataset/labels/train/rainynight (213).txt  \n",
            "  inflating: dataset/labels/train/rainynight (214).txt  \n",
            "  inflating: dataset/labels/train/rainynight (215).txt  \n",
            "  inflating: dataset/labels/train/rainynight (216).txt  \n",
            "  inflating: dataset/labels/train/rainynight (217).txt  \n",
            "  inflating: dataset/labels/train/rainynight (218).txt  \n",
            "  inflating: dataset/labels/train/rainynight (219).txt  \n",
            "  inflating: dataset/labels/train/rainynight (22).txt  \n",
            "  inflating: dataset/labels/train/rainynight (220).txt  \n",
            "  inflating: dataset/labels/train/rainynight (221).txt  \n",
            "  inflating: dataset/labels/train/rainynight (222).txt  \n",
            "  inflating: dataset/labels/train/rainynight (223).txt  \n",
            "  inflating: dataset/labels/train/rainynight (224).txt  \n",
            "  inflating: dataset/labels/train/rainynight (225).txt  \n",
            "  inflating: dataset/labels/train/rainynight (226).txt  \n",
            "  inflating: dataset/labels/train/rainynight (227).txt  \n",
            "  inflating: dataset/labels/train/rainynight (228).txt  \n",
            "  inflating: dataset/labels/train/rainynight (229).txt  \n",
            "  inflating: dataset/labels/train/rainynight (23).txt  \n",
            "  inflating: dataset/labels/train/rainynight (230).txt  \n",
            "  inflating: dataset/labels/train/rainynight (231).txt  \n",
            "  inflating: dataset/labels/train/rainynight (232).txt  \n",
            "  inflating: dataset/labels/train/rainynight (233).txt  \n",
            "  inflating: dataset/labels/train/rainynight (234).txt  \n",
            "  inflating: dataset/labels/train/rainynight (235).txt  \n",
            "  inflating: dataset/labels/train/rainynight (236).txt  \n",
            "  inflating: dataset/labels/train/rainynight (237).txt  \n",
            "  inflating: dataset/labels/train/rainynight (238).txt  \n",
            "  inflating: dataset/labels/train/rainynight (239).txt  \n",
            "  inflating: dataset/labels/train/rainynight (24).txt  \n",
            "  inflating: dataset/labels/train/rainynight (240).txt  \n",
            "  inflating: dataset/labels/train/rainynight (241).txt  \n",
            "  inflating: dataset/labels/train/rainynight (242).txt  \n",
            "  inflating: dataset/labels/train/rainynight (243).txt  \n",
            "  inflating: dataset/labels/train/rainynight (244).txt  \n",
            "  inflating: dataset/labels/train/rainynight (245).txt  \n",
            "  inflating: dataset/labels/train/rainynight (246).txt  \n",
            "  inflating: dataset/labels/train/rainynight (247).txt  \n",
            "  inflating: dataset/labels/train/rainynight (248).txt  \n",
            "  inflating: dataset/labels/train/rainynight (249).txt  \n",
            "  inflating: dataset/labels/train/rainynight (25).txt  \n",
            "  inflating: dataset/labels/train/rainynight (250).txt  \n",
            "  inflating: dataset/labels/train/rainynight (251).txt  \n",
            "  inflating: dataset/labels/train/rainynight (252).txt  \n",
            "  inflating: dataset/labels/train/rainynight (253).txt  \n",
            "  inflating: dataset/labels/train/rainynight (254).txt  \n",
            "  inflating: dataset/labels/train/rainynight (255).txt  \n",
            "  inflating: dataset/labels/train/rainynight (256).txt  \n",
            "  inflating: dataset/labels/train/rainynight (257).txt  \n",
            "  inflating: dataset/labels/train/rainynight (258).txt  \n",
            "  inflating: dataset/labels/train/rainynight (259).txt  \n",
            "  inflating: dataset/labels/train/rainynight (26).txt  \n",
            "  inflating: dataset/labels/train/rainynight (260).txt  \n",
            "  inflating: dataset/labels/train/rainynight (261).txt  \n",
            "  inflating: dataset/labels/train/rainynight (262).txt  \n",
            "  inflating: dataset/labels/train/rainynight (263).txt  \n",
            "  inflating: dataset/labels/train/rainynight (264).txt  \n",
            "  inflating: dataset/labels/train/rainynight (265).txt  \n",
            "  inflating: dataset/labels/train/rainynight (266).txt  \n",
            "  inflating: dataset/labels/train/rainynight (267).txt  \n",
            "  inflating: dataset/labels/train/rainynight (268).txt  \n",
            "  inflating: dataset/labels/train/rainynight (269).txt  \n",
            "  inflating: dataset/labels/train/rainynight (27).txt  \n",
            "  inflating: dataset/labels/train/rainynight (270).txt  \n",
            "  inflating: dataset/labels/train/rainynight (271).txt  \n",
            " extracting: dataset/labels/train/rainynight (272).txt  \n",
            " extracting: dataset/labels/train/rainynight (273).txt  \n",
            "  inflating: dataset/labels/train/rainynight (274).txt  \n",
            "  inflating: dataset/labels/train/rainynight (275).txt  \n",
            "  inflating: dataset/labels/train/rainynight (276).txt  \n",
            "  inflating: dataset/labels/train/rainynight (277).txt  \n",
            "  inflating: dataset/labels/train/rainynight (278).txt  \n",
            "  inflating: dataset/labels/train/rainynight (279).txt  \n",
            "  inflating: dataset/labels/train/rainynight (28).txt  \n",
            "  inflating: dataset/labels/train/rainynight (280).txt  \n",
            "  inflating: dataset/labels/train/rainynight (281).txt  \n",
            "  inflating: dataset/labels/train/rainynight (282).txt  \n",
            "  inflating: dataset/labels/train/rainynight (283).txt  \n",
            "  inflating: dataset/labels/train/rainynight (284).txt  \n",
            "  inflating: dataset/labels/train/rainynight (285).txt  \n",
            "  inflating: dataset/labels/train/rainynight (286).txt  \n",
            "  inflating: dataset/labels/train/rainynight (287).txt  \n",
            "  inflating: dataset/labels/train/rainynight (288).txt  \n",
            "  inflating: dataset/labels/train/rainynight (289).txt  \n",
            "  inflating: dataset/labels/train/rainynight (29).txt  \n",
            "  inflating: dataset/labels/train/rainynight (290).txt  \n",
            "  inflating: dataset/labels/train/rainynight (291).txt  \n",
            "  inflating: dataset/labels/train/rainynight (292).txt  \n",
            "  inflating: dataset/labels/train/rainynight (293).txt  \n",
            " extracting: dataset/labels/train/rainynight (294).txt  \n",
            "  inflating: dataset/labels/train/rainynight (295).txt  \n",
            "  inflating: dataset/labels/train/rainynight (296).txt  \n",
            "  inflating: dataset/labels/train/rainynight (297).txt  \n",
            "  inflating: dataset/labels/train/rainynight (298).txt  \n",
            "  inflating: dataset/labels/train/rainynight (299).txt  \n",
            "  inflating: dataset/labels/train/rainynight (3).txt  \n",
            "  inflating: dataset/labels/train/rainynight (30).txt  \n",
            " extracting: dataset/labels/train/rainynight (300).txt  \n",
            "  inflating: dataset/labels/train/rainynight (301).txt  \n",
            "  inflating: dataset/labels/train/rainynight (302).txt  \n",
            "  inflating: dataset/labels/train/rainynight (303).txt  \n",
            " extracting: dataset/labels/train/rainynight (304).txt  \n",
            "  inflating: dataset/labels/train/rainynight (305).txt  \n",
            "  inflating: dataset/labels/train/rainynight (306).txt  \n",
            "  inflating: dataset/labels/train/rainynight (307).txt  \n",
            "  inflating: dataset/labels/train/rainynight (308).txt  \n",
            "  inflating: dataset/labels/train/rainynight (309).txt  \n",
            "  inflating: dataset/labels/train/rainynight (31).txt  \n",
            "  inflating: dataset/labels/train/rainynight (310).txt  \n",
            "  inflating: dataset/labels/train/rainynight (311).txt  \n",
            "  inflating: dataset/labels/train/rainynight (312).txt  \n",
            "  inflating: dataset/labels/train/rainynight (313).txt  \n",
            " extracting: dataset/labels/train/rainynight (314).txt  \n",
            " extracting: dataset/labels/train/rainynight (315).txt  \n",
            " extracting: dataset/labels/train/rainynight (316).txt  \n",
            "  inflating: dataset/labels/train/rainynight (317).txt  \n",
            "  inflating: dataset/labels/train/rainynight (318).txt  \n",
            "  inflating: dataset/labels/train/rainynight (319).txt  \n",
            "  inflating: dataset/labels/train/rainynight (32).txt  \n",
            "  inflating: dataset/labels/train/rainynight (320).txt  \n",
            "  inflating: dataset/labels/train/rainynight (321).txt  \n",
            "  inflating: dataset/labels/train/rainynight (322).txt  \n",
            "  inflating: dataset/labels/train/rainynight (323).txt  \n",
            "  inflating: dataset/labels/train/rainynight (324).txt  \n",
            "  inflating: dataset/labels/train/rainynight (325).txt  \n",
            "  inflating: dataset/labels/train/rainynight (326).txt  \n",
            "  inflating: dataset/labels/train/rainynight (327).txt  \n",
            "  inflating: dataset/labels/train/rainynight (328).txt  \n",
            "  inflating: dataset/labels/train/rainynight (329).txt  \n",
            "  inflating: dataset/labels/train/rainynight (33).txt  \n",
            "  inflating: dataset/labels/train/rainynight (330).txt  \n",
            "  inflating: dataset/labels/train/rainynight (331).txt  \n",
            "  inflating: dataset/labels/train/rainynight (332).txt  \n",
            "  inflating: dataset/labels/train/rainynight (333).txt  \n",
            "  inflating: dataset/labels/train/rainynight (334).txt  \n",
            "  inflating: dataset/labels/train/rainynight (335).txt  \n",
            "  inflating: dataset/labels/train/rainynight (336).txt  \n",
            "  inflating: dataset/labels/train/rainynight (337).txt  \n",
            "  inflating: dataset/labels/train/rainynight (338).txt  \n",
            "  inflating: dataset/labels/train/rainynight (339).txt  \n",
            "  inflating: dataset/labels/train/rainynight (34).txt  \n",
            "  inflating: dataset/labels/train/rainynight (340).txt  \n",
            "  inflating: dataset/labels/train/rainynight (341).txt  \n",
            "  inflating: dataset/labels/train/rainynight (342).txt  \n",
            " extracting: dataset/labels/train/rainynight (343).txt  \n",
            " extracting: dataset/labels/train/rainynight (344).txt  \n",
            " extracting: dataset/labels/train/rainynight (345).txt  \n",
            " extracting: dataset/labels/train/rainynight (346).txt  \n",
            "  inflating: dataset/labels/train/rainynight (347).txt  \n",
            "  inflating: dataset/labels/train/rainynight (348).txt  \n",
            "  inflating: dataset/labels/train/rainynight (349).txt  \n",
            "  inflating: dataset/labels/train/rainynight (35).txt  \n",
            "  inflating: dataset/labels/train/rainynight (350).txt  \n",
            "  inflating: dataset/labels/train/rainynight (351).txt  \n",
            "  inflating: dataset/labels/train/rainynight (352).txt  \n",
            "  inflating: dataset/labels/train/rainynight (353).txt  \n",
            "  inflating: dataset/labels/train/rainynight (354).txt  \n",
            "  inflating: dataset/labels/train/rainynight (355).txt  \n",
            "  inflating: dataset/labels/train/rainynight (356).txt  \n",
            "  inflating: dataset/labels/train/rainynight (357).txt  \n",
            "  inflating: dataset/labels/train/rainynight (358).txt  \n",
            "  inflating: dataset/labels/train/rainynight (359).txt  \n",
            "  inflating: dataset/labels/train/rainynight (36).txt  \n",
            "  inflating: dataset/labels/train/rainynight (360).txt  \n",
            "  inflating: dataset/labels/train/rainynight (361).txt  \n",
            "  inflating: dataset/labels/train/rainynight (362).txt  \n",
            "  inflating: dataset/labels/train/rainynight (363).txt  \n",
            "  inflating: dataset/labels/train/rainynight (364).txt  \n",
            "  inflating: dataset/labels/train/rainynight (365).txt  \n",
            "  inflating: dataset/labels/train/rainynight (366).txt  \n",
            "  inflating: dataset/labels/train/rainynight (367).txt  \n",
            "  inflating: dataset/labels/train/rainynight (368).txt  \n",
            "  inflating: dataset/labels/train/rainynight (369).txt  \n",
            "  inflating: dataset/labels/train/rainynight (37).txt  \n",
            "  inflating: dataset/labels/train/rainynight (370).txt  \n",
            "  inflating: dataset/labels/train/rainynight (371).txt  \n",
            "  inflating: dataset/labels/train/rainynight (372).txt  \n",
            "  inflating: dataset/labels/train/rainynight (373).txt  \n",
            "  inflating: dataset/labels/train/rainynight (374).txt  \n",
            "  inflating: dataset/labels/train/rainynight (375).txt  \n",
            "  inflating: dataset/labels/train/rainynight (376).txt  \n",
            "  inflating: dataset/labels/train/rainynight (377).txt  \n",
            "  inflating: dataset/labels/train/rainynight (378).txt  \n",
            "  inflating: dataset/labels/train/rainynight (379).txt  \n",
            "  inflating: dataset/labels/train/rainynight (38).txt  \n",
            "  inflating: dataset/labels/train/rainynight (380).txt  \n",
            "  inflating: dataset/labels/train/rainynight (381).txt  \n",
            "  inflating: dataset/labels/train/rainynight (382).txt  \n",
            "  inflating: dataset/labels/train/rainynight (383).txt  \n",
            "  inflating: dataset/labels/train/rainynight (384).txt  \n",
            "  inflating: dataset/labels/train/rainynight (385).txt  \n",
            "  inflating: dataset/labels/train/rainynight (386).txt  \n",
            "  inflating: dataset/labels/train/rainynight (387).txt  \n",
            "  inflating: dataset/labels/train/rainynight (388).txt  \n",
            "  inflating: dataset/labels/train/rainynight (389).txt  \n",
            "  inflating: dataset/labels/train/rainynight (39).txt  \n",
            "  inflating: dataset/labels/train/rainynight (390).txt  \n",
            "  inflating: dataset/labels/train/rainynight (391).txt  \n",
            "  inflating: dataset/labels/train/rainynight (392).txt  \n",
            "  inflating: dataset/labels/train/rainynight (393).txt  \n",
            "  inflating: dataset/labels/train/rainynight (394).txt  \n",
            "  inflating: dataset/labels/train/rainynight (395).txt  \n",
            "  inflating: dataset/labels/train/rainynight (396).txt  \n",
            "  inflating: dataset/labels/train/rainynight (397).txt  \n",
            "  inflating: dataset/labels/train/rainynight (398).txt  \n",
            "  inflating: dataset/labels/train/rainynight (399).txt  \n",
            "  inflating: dataset/labels/train/rainynight (4).txt  \n",
            "  inflating: dataset/labels/train/rainynight (40).txt  \n",
            "  inflating: dataset/labels/train/rainynight (400).txt  \n",
            "  inflating: dataset/labels/train/rainynight (401).txt  \n",
            "  inflating: dataset/labels/train/rainynight (402).txt  \n",
            "  inflating: dataset/labels/train/rainynight (403).txt  \n",
            "  inflating: dataset/labels/train/rainynight (404).txt  \n",
            "  inflating: dataset/labels/train/rainynight (405).txt  \n",
            "  inflating: dataset/labels/train/rainynight (406).txt  \n",
            "  inflating: dataset/labels/train/rainynight (407).txt  \n",
            "  inflating: dataset/labels/train/rainynight (408).txt  \n",
            "  inflating: dataset/labels/train/rainynight (409).txt  \n",
            "  inflating: dataset/labels/train/rainynight (41).txt  \n",
            "  inflating: dataset/labels/train/rainynight (410).txt  \n",
            "  inflating: dataset/labels/train/rainynight (411).txt  \n",
            "  inflating: dataset/labels/train/rainynight (412).txt  \n",
            "  inflating: dataset/labels/train/rainynight (413).txt  \n",
            "  inflating: dataset/labels/train/rainynight (414).txt  \n",
            "  inflating: dataset/labels/train/rainynight (415).txt  \n",
            "  inflating: dataset/labels/train/rainynight (416).txt  \n",
            "  inflating: dataset/labels/train/rainynight (417).txt  \n",
            "  inflating: dataset/labels/train/rainynight (418).txt  \n",
            "  inflating: dataset/labels/train/rainynight (419).txt  \n",
            "  inflating: dataset/labels/train/rainynight (42).txt  \n",
            "  inflating: dataset/labels/train/rainynight (420).txt  \n",
            "  inflating: dataset/labels/train/rainynight (421).txt  \n",
            "  inflating: dataset/labels/train/rainynight (422).txt  \n",
            "  inflating: dataset/labels/train/rainynight (423).txt  \n",
            "  inflating: dataset/labels/train/rainynight (424).txt  \n",
            "  inflating: dataset/labels/train/rainynight (425).txt  \n",
            "  inflating: dataset/labels/train/rainynight (426).txt  \n",
            "  inflating: dataset/labels/train/rainynight (427).txt  \n",
            "  inflating: dataset/labels/train/rainynight (428).txt  \n",
            "  inflating: dataset/labels/train/rainynight (429).txt  \n",
            "  inflating: dataset/labels/train/rainynight (43).txt  \n",
            "  inflating: dataset/labels/train/rainynight (430).txt  \n",
            "  inflating: dataset/labels/train/rainynight (431).txt  \n",
            "  inflating: dataset/labels/train/rainynight (432).txt  \n",
            "  inflating: dataset/labels/train/rainynight (433).txt  \n",
            "  inflating: dataset/labels/train/rainynight (434).txt  \n",
            "  inflating: dataset/labels/train/rainynight (435).txt  \n",
            "  inflating: dataset/labels/train/rainynight (436).txt  \n",
            "  inflating: dataset/labels/train/rainynight (437).txt  \n",
            "  inflating: dataset/labels/train/rainynight (438).txt  \n",
            "  inflating: dataset/labels/train/rainynight (439).txt  \n",
            "  inflating: dataset/labels/train/rainynight (44).txt  \n",
            "  inflating: dataset/labels/train/rainynight (440).txt  \n",
            " extracting: dataset/labels/train/rainynight (441).txt  \n",
            " extracting: dataset/labels/train/rainynight (442).txt  \n",
            " extracting: dataset/labels/train/rainynight (443).txt  \n",
            "  inflating: dataset/labels/train/rainynight (444).txt  \n",
            "  inflating: dataset/labels/train/rainynight (445).txt  \n",
            "  inflating: dataset/labels/train/rainynight (446).txt  \n",
            "  inflating: dataset/labels/train/rainynight (447).txt  \n",
            "  inflating: dataset/labels/train/rainynight (448).txt  \n",
            "  inflating: dataset/labels/train/rainynight (449).txt  \n",
            "  inflating: dataset/labels/train/rainynight (45).txt  \n",
            "  inflating: dataset/labels/train/rainynight (450).txt  \n",
            "  inflating: dataset/labels/train/rainynight (451).txt  \n",
            "  inflating: dataset/labels/train/rainynight (452).txt  \n",
            "  inflating: dataset/labels/train/rainynight (453).txt  \n",
            "  inflating: dataset/labels/train/rainynight (454).txt  \n",
            "  inflating: dataset/labels/train/rainynight (455).txt  \n",
            "  inflating: dataset/labels/train/rainynight (456).txt  \n",
            "  inflating: dataset/labels/train/rainynight (457).txt  \n",
            "  inflating: dataset/labels/train/rainynight (458).txt  \n",
            "  inflating: dataset/labels/train/rainynight (459).txt  \n",
            "  inflating: dataset/labels/train/rainynight (46).txt  \n",
            "  inflating: dataset/labels/train/rainynight (460).txt  \n",
            "  inflating: dataset/labels/train/rainynight (461).txt  \n",
            "  inflating: dataset/labels/train/rainynight (462).txt  \n",
            "  inflating: dataset/labels/train/rainynight (463).txt  \n",
            "  inflating: dataset/labels/train/rainynight (464).txt  \n",
            "  inflating: dataset/labels/train/rainynight (465).txt  \n",
            "  inflating: dataset/labels/train/rainynight (466).txt  \n",
            "  inflating: dataset/labels/train/rainynight (467).txt  \n",
            "  inflating: dataset/labels/train/rainynight (468).txt  \n",
            "  inflating: dataset/labels/train/rainynight (469).txt  \n",
            "  inflating: dataset/labels/train/rainynight (47).txt  \n",
            "  inflating: dataset/labels/train/rainynight (470).txt  \n",
            "  inflating: dataset/labels/train/rainynight (471).txt  \n",
            "  inflating: dataset/labels/train/rainynight (472).txt  \n",
            "  inflating: dataset/labels/train/rainynight (473).txt  \n",
            "  inflating: dataset/labels/train/rainynight (474).txt  \n",
            "  inflating: dataset/labels/train/rainynight (475).txt  \n",
            "  inflating: dataset/labels/train/rainynight (476).txt  \n",
            "  inflating: dataset/labels/train/rainynight (477).txt  \n",
            "  inflating: dataset/labels/train/rainynight (478).txt  \n",
            "  inflating: dataset/labels/train/rainynight (479).txt  \n",
            "  inflating: dataset/labels/train/rainynight (48).txt  \n",
            "  inflating: dataset/labels/train/rainynight (480).txt  \n",
            "  inflating: dataset/labels/train/rainynight (481).txt  \n",
            "  inflating: dataset/labels/train/rainynight (482).txt  \n",
            "  inflating: dataset/labels/train/rainynight (483).txt  \n",
            "  inflating: dataset/labels/train/rainynight (484).txt  \n",
            "  inflating: dataset/labels/train/rainynight (485).txt  \n",
            "  inflating: dataset/labels/train/rainynight (486).txt  \n",
            "  inflating: dataset/labels/train/rainynight (487).txt  \n",
            "  inflating: dataset/labels/train/rainynight (488).txt  \n",
            "  inflating: dataset/labels/train/rainynight (489).txt  \n",
            "  inflating: dataset/labels/train/rainynight (49).txt  \n",
            "  inflating: dataset/labels/train/rainynight (490).txt  \n",
            "  inflating: dataset/labels/train/rainynight (491).txt  \n",
            "  inflating: dataset/labels/train/rainynight (492).txt  \n",
            "  inflating: dataset/labels/train/rainynight (493).txt  \n",
            "  inflating: dataset/labels/train/rainynight (494).txt  \n",
            "  inflating: dataset/labels/train/rainynight (495).txt  \n",
            "  inflating: dataset/labels/train/rainynight (496).txt  \n",
            "  inflating: dataset/labels/train/rainynight (497).txt  \n",
            "  inflating: dataset/labels/train/rainynight (498).txt  \n",
            "  inflating: dataset/labels/train/rainynight (499).txt  \n",
            "  inflating: dataset/labels/train/rainynight (5).txt  \n",
            "  inflating: dataset/labels/train/rainynight (50).txt  \n",
            "  inflating: dataset/labels/train/rainynight (500).txt  \n",
            "  inflating: dataset/labels/train/rainynight (501).txt  \n",
            "  inflating: dataset/labels/train/rainynight (502).txt  \n",
            "  inflating: dataset/labels/train/rainynight (503).txt  \n",
            "  inflating: dataset/labels/train/rainynight (504).txt  \n",
            "  inflating: dataset/labels/train/rainynight (505).txt  \n",
            "  inflating: dataset/labels/train/rainynight (506).txt  \n",
            "  inflating: dataset/labels/train/rainynight (507).txt  \n",
            "  inflating: dataset/labels/train/rainynight (508).txt  \n",
            "  inflating: dataset/labels/train/rainynight (509).txt  \n",
            "  inflating: dataset/labels/train/rainynight (51).txt  \n",
            "  inflating: dataset/labels/train/rainynight (510).txt  \n",
            "  inflating: dataset/labels/train/rainynight (511).txt  \n",
            "  inflating: dataset/labels/train/rainynight (512).txt  \n",
            "  inflating: dataset/labels/train/rainynight (513).txt  \n",
            "  inflating: dataset/labels/train/rainynight (514).txt  \n",
            "  inflating: dataset/labels/train/rainynight (515).txt  \n",
            "  inflating: dataset/labels/train/rainynight (516).txt  \n",
            "  inflating: dataset/labels/train/rainynight (517).txt  \n",
            "  inflating: dataset/labels/train/rainynight (518).txt  \n",
            "  inflating: dataset/labels/train/rainynight (519).txt  \n",
            "  inflating: dataset/labels/train/rainynight (52).txt  \n",
            "  inflating: dataset/labels/train/rainynight (520).txt  \n",
            "  inflating: dataset/labels/train/rainynight (521).txt  \n",
            "  inflating: dataset/labels/train/rainynight (522).txt  \n",
            "  inflating: dataset/labels/train/rainynight (523).txt  \n",
            "  inflating: dataset/labels/train/rainynight (524).txt  \n",
            "  inflating: dataset/labels/train/rainynight (525).txt  \n",
            "  inflating: dataset/labels/train/rainynight (526).txt  \n",
            "  inflating: dataset/labels/train/rainynight (527).txt  \n",
            "  inflating: dataset/labels/train/rainynight (528).txt  \n",
            "  inflating: dataset/labels/train/rainynight (529).txt  \n",
            "  inflating: dataset/labels/train/rainynight (53).txt  \n",
            "  inflating: dataset/labels/train/rainynight (530).txt  \n",
            "  inflating: dataset/labels/train/rainynight (531).txt  \n",
            "  inflating: dataset/labels/train/rainynight (532).txt  \n",
            "  inflating: dataset/labels/train/rainynight (533).txt  \n",
            "  inflating: dataset/labels/train/rainynight (534).txt  \n",
            "  inflating: dataset/labels/train/rainynight (535).txt  \n",
            "  inflating: dataset/labels/train/rainynight (536).txt  \n",
            "  inflating: dataset/labels/train/rainynight (537).txt  \n",
            "  inflating: dataset/labels/train/rainynight (538).txt  \n",
            "  inflating: dataset/labels/train/rainynight (539).txt  \n",
            "  inflating: dataset/labels/train/rainynight (54).txt  \n",
            "  inflating: dataset/labels/train/rainynight (540).txt  \n",
            "  inflating: dataset/labels/train/rainynight (541).txt  \n",
            "  inflating: dataset/labels/train/rainynight (542).txt  \n",
            "  inflating: dataset/labels/train/rainynight (543).txt  \n",
            "  inflating: dataset/labels/train/rainynight (544).txt  \n",
            "  inflating: dataset/labels/train/rainynight (545).txt  \n",
            "  inflating: dataset/labels/train/rainynight (546).txt  \n",
            "  inflating: dataset/labels/train/rainynight (547).txt  \n",
            "  inflating: dataset/labels/train/rainynight (548).txt  \n",
            "  inflating: dataset/labels/train/rainynight (549).txt  \n",
            "  inflating: dataset/labels/train/rainynight (55).txt  \n",
            "  inflating: dataset/labels/train/rainynight (550).txt  \n",
            "  inflating: dataset/labels/train/rainynight (551).txt  \n",
            "  inflating: dataset/labels/train/rainynight (552).txt  \n",
            "  inflating: dataset/labels/train/rainynight (553).txt  \n",
            "  inflating: dataset/labels/train/rainynight (554).txt  \n",
            "  inflating: dataset/labels/train/rainynight (555).txt  \n",
            "  inflating: dataset/labels/train/rainynight (556).txt  \n",
            "  inflating: dataset/labels/train/rainynight (557).txt  \n",
            "  inflating: dataset/labels/train/rainynight (558).txt  \n",
            "  inflating: dataset/labels/train/rainynight (559).txt  \n",
            "  inflating: dataset/labels/train/rainynight (56).txt  \n",
            "  inflating: dataset/labels/train/rainynight (560).txt  \n",
            "  inflating: dataset/labels/train/rainynight (561).txt  \n",
            "  inflating: dataset/labels/train/rainynight (562).txt  \n",
            "  inflating: dataset/labels/train/rainynight (563).txt  \n",
            "  inflating: dataset/labels/train/rainynight (564).txt  \n",
            "  inflating: dataset/labels/train/rainynight (565).txt  \n",
            "  inflating: dataset/labels/train/rainynight (566).txt  \n",
            "  inflating: dataset/labels/train/rainynight (567).txt  \n",
            "  inflating: dataset/labels/train/rainynight (568).txt  \n",
            "  inflating: dataset/labels/train/rainynight (569).txt  \n",
            "  inflating: dataset/labels/train/rainynight (57).txt  \n",
            "  inflating: dataset/labels/train/rainynight (570).txt  \n",
            "  inflating: dataset/labels/train/rainynight (571).txt  \n",
            "  inflating: dataset/labels/train/rainynight (572).txt  \n",
            "  inflating: dataset/labels/train/rainynight (573).txt  \n",
            "  inflating: dataset/labels/train/rainynight (574).txt  \n",
            "  inflating: dataset/labels/train/rainynight (575).txt  \n",
            " extracting: dataset/labels/train/rainynight (576).txt  \n",
            " extracting: dataset/labels/train/rainynight (577).txt  \n",
            "  inflating: dataset/labels/train/rainynight (578).txt  \n",
            " extracting: dataset/labels/train/rainynight (579).txt  \n",
            "  inflating: dataset/labels/train/rainynight (58).txt  \n",
            "  inflating: dataset/labels/train/rainynight (580).txt  \n",
            "  inflating: dataset/labels/train/rainynight (581).txt  \n",
            "  inflating: dataset/labels/train/rainynight (582).txt  \n",
            " extracting: dataset/labels/train/rainynight (583).txt  \n",
            " extracting: dataset/labels/train/rainynight (584).txt  \n",
            " extracting: dataset/labels/train/rainynight (585).txt  \n",
            " extracting: dataset/labels/train/rainynight (586).txt  \n",
            "  inflating: dataset/labels/train/rainynight (587).txt  \n",
            " extracting: dataset/labels/train/rainynight (588).txt  \n",
            " extracting: dataset/labels/train/rainynight (589).txt  \n",
            "  inflating: dataset/labels/train/rainynight (59).txt  \n",
            "  inflating: dataset/labels/train/rainynight (590).txt  \n",
            "  inflating: dataset/labels/train/rainynight (591).txt  \n",
            "  inflating: dataset/labels/train/rainynight (592).txt  \n",
            "  inflating: dataset/labels/train/rainynight (593).txt  \n",
            "  inflating: dataset/labels/train/rainynight (594).txt  \n",
            "  inflating: dataset/labels/train/rainynight (595).txt  \n",
            "  inflating: dataset/labels/train/rainynight (596).txt  \n",
            "  inflating: dataset/labels/train/rainynight (597).txt  \n",
            "  inflating: dataset/labels/train/rainynight (598).txt  \n",
            "  inflating: dataset/labels/train/rainynight (599).txt  \n",
            "  inflating: dataset/labels/train/rainynight (6).txt  \n",
            "  inflating: dataset/labels/train/rainynight (60).txt  \n",
            "  inflating: dataset/labels/train/rainynight (600).txt  \n",
            "  inflating: dataset/labels/train/rainynight (601).txt  \n",
            "  inflating: dataset/labels/train/rainynight (602).txt  \n",
            "  inflating: dataset/labels/train/rainynight (603).txt  \n",
            "  inflating: dataset/labels/train/rainynight (604).txt  \n",
            "  inflating: dataset/labels/train/rainynight (605).txt  \n",
            "  inflating: dataset/labels/train/rainynight (606).txt  \n",
            "  inflating: dataset/labels/train/rainynight (607).txt  \n",
            "  inflating: dataset/labels/train/rainynight (608).txt  \n",
            "  inflating: dataset/labels/train/rainynight (609).txt  \n",
            "  inflating: dataset/labels/train/rainynight (61).txt  \n",
            "  inflating: dataset/labels/train/rainynight (610).txt  \n",
            "  inflating: dataset/labels/train/rainynight (611).txt  \n",
            "  inflating: dataset/labels/train/rainynight (612).txt  \n",
            "  inflating: dataset/labels/train/rainynight (613).txt  \n",
            "  inflating: dataset/labels/train/rainynight (614).txt  \n",
            "  inflating: dataset/labels/train/rainynight (615).txt  \n",
            "  inflating: dataset/labels/train/rainynight (616).txt  \n",
            "  inflating: dataset/labels/train/rainynight (617).txt  \n",
            "  inflating: dataset/labels/train/rainynight (618).txt  \n",
            "  inflating: dataset/labels/train/rainynight (619).txt  \n",
            "  inflating: dataset/labels/train/rainynight (62).txt  \n",
            "  inflating: dataset/labels/train/rainynight (620).txt  \n",
            "  inflating: dataset/labels/train/rainynight (621).txt  \n",
            "  inflating: dataset/labels/train/rainynight (622).txt  \n",
            "  inflating: dataset/labels/train/rainynight (623).txt  \n",
            "  inflating: dataset/labels/train/rainynight (624).txt  \n",
            "  inflating: dataset/labels/train/rainynight (625).txt  \n",
            "  inflating: dataset/labels/train/rainynight (626).txt  \n",
            "  inflating: dataset/labels/train/rainynight (627).txt  \n",
            "  inflating: dataset/labels/train/rainynight (628).txt  \n",
            "  inflating: dataset/labels/train/rainynight (629).txt  \n",
            "  inflating: dataset/labels/train/rainynight (63).txt  \n",
            "  inflating: dataset/labels/train/rainynight (630).txt  \n",
            "  inflating: dataset/labels/train/rainynight (631).txt  \n",
            "  inflating: dataset/labels/train/rainynight (632).txt  \n",
            "  inflating: dataset/labels/train/rainynight (633).txt  \n",
            "  inflating: dataset/labels/train/rainynight (634).txt  \n",
            "  inflating: dataset/labels/train/rainynight (635).txt  \n",
            "  inflating: dataset/labels/train/rainynight (636).txt  \n",
            "  inflating: dataset/labels/train/rainynight (637).txt  \n",
            "  inflating: dataset/labels/train/rainynight (638).txt  \n",
            "  inflating: dataset/labels/train/rainynight (639).txt  \n",
            "  inflating: dataset/labels/train/rainynight (64).txt  \n",
            "  inflating: dataset/labels/train/rainynight (640).txt  \n",
            "  inflating: dataset/labels/train/rainynight (641).txt  \n",
            "  inflating: dataset/labels/train/rainynight (642).txt  \n",
            "  inflating: dataset/labels/train/rainynight (643).txt  \n",
            "  inflating: dataset/labels/train/rainynight (644).txt  \n",
            "  inflating: dataset/labels/train/rainynight (645).txt  \n",
            "  inflating: dataset/labels/train/rainynight (646).txt  \n",
            "  inflating: dataset/labels/train/rainynight (647).txt  \n",
            "  inflating: dataset/labels/train/rainynight (648).txt  \n",
            "  inflating: dataset/labels/train/rainynight (649).txt  \n",
            "  inflating: dataset/labels/train/rainynight (65).txt  \n",
            "  inflating: dataset/labels/train/rainynight (650).txt  \n",
            "  inflating: dataset/labels/train/rainynight (66).txt  \n",
            "  inflating: dataset/labels/train/rainynight (67).txt  \n",
            "  inflating: dataset/labels/train/rainynight (68).txt  \n",
            "  inflating: dataset/labels/train/rainynight (69).txt  \n",
            "  inflating: dataset/labels/train/rainynight (7).txt  \n",
            "  inflating: dataset/labels/train/rainynight (70).txt  \n",
            "  inflating: dataset/labels/train/rainynight (71).txt  \n",
            "  inflating: dataset/labels/train/rainynight (72).txt  \n",
            "  inflating: dataset/labels/train/rainynight (73).txt  \n",
            "  inflating: dataset/labels/train/rainynight (74).txt  \n",
            "  inflating: dataset/labels/train/rainynight (75).txt  \n",
            "  inflating: dataset/labels/train/rainynight (76).txt  \n",
            "  inflating: dataset/labels/train/rainynight (77).txt  \n",
            "  inflating: dataset/labels/train/rainynight (78).txt  \n",
            "  inflating: dataset/labels/train/rainynight (79).txt  \n",
            "  inflating: dataset/labels/train/rainynight (8).txt  \n",
            "  inflating: dataset/labels/train/rainynight (80).txt  \n",
            "  inflating: dataset/labels/train/rainynight (81).txt  \n",
            "  inflating: dataset/labels/train/rainynight (82).txt  \n",
            "  inflating: dataset/labels/train/rainynight (83).txt  \n",
            "  inflating: dataset/labels/train/rainynight (84).txt  \n",
            "  inflating: dataset/labels/train/rainynight (85).txt  \n",
            "  inflating: dataset/labels/train/rainynight (86).txt  \n",
            "  inflating: dataset/labels/train/rainynight (87).txt  \n",
            "  inflating: dataset/labels/train/rainynight (88).txt  \n",
            "  inflating: dataset/labels/train/rainynight (89).txt  \n",
            "  inflating: dataset/labels/train/rainynight (9).txt  \n",
            "  inflating: dataset/labels/train/rainynight (90).txt  \n",
            "  inflating: dataset/labels/train/rainynight (91).txt  \n",
            "  inflating: dataset/labels/train/rainynight (92).txt  \n",
            "  inflating: dataset/labels/train/rainynight (93).txt  \n",
            "  inflating: dataset/labels/train/rainynight (94).txt  \n",
            "  inflating: dataset/labels/train/rainynight (95).txt  \n",
            "  inflating: dataset/labels/train/rainynight (96).txt  \n",
            "  inflating: dataset/labels/train/rainynight (97).txt  \n",
            "  inflating: dataset/labels/train/rainynight (98).txt  \n",
            "  inflating: dataset/labels/train/rainynight (99).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (1).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (10).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (100).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (103).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (104).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (105).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (106).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (11).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (117).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (118).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (119).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (12).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (120).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (121).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (122).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (123).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (124).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (125).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (126).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (127).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (128).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (129).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (13).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (130).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (131).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (132).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (133).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (134).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (135).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (136).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (137).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (138).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (139).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (14).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (140).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (141).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (142).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (143).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (144).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (145).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (147).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (148).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (149).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (15).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (150).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (151).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (152).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (153).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (154).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (155).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (156).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (157).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (158).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (159).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (16).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (160).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (161).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (162).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (163).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (164).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (165).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (166).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (167).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (168).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (169).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (17).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (170).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (171).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (173).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (174).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (175).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (176).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (177).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (179).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (18).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (180).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (181).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (182).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (184).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (185).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (186).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (187).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (188).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (189).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (19).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (190).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (191).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (192).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (193).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (194).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (195).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (196).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (197).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (198).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (199).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (2).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (20).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (200).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (202).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (203).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (204).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (21).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (213).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (215).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (216).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (217).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (219).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (22).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (220).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (221).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (222).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (224).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (229).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (23).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (230).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (231).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (232).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (233).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (234).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (236).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (237).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (24).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (240).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (244).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (246).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (248).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (25).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (250).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (254).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (258).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (26).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (260).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (261).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (263).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (268).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (27).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (270).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (272).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (273).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (277).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (279).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (28).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (280).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (281).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (284).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (285).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (287).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (288).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (29).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (290).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (291).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (293).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (294).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (296).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (3).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (30).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (300).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (301).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (303).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (304).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (305).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (306).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (307).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (31).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (310).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (311).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (314).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (316).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (318).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (319).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (32).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (320).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (323).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (324).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (327).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (329).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (33).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (330).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (332).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (333).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (336).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (337).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (34).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (342).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (344).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (347).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (349).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (35).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (350).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (351).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (352).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (353).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (354).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (355).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (356).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (357).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (358).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (359).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (36).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (360).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (361).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (362).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (363).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (364).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (365).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (366).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (367).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (368).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (369).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (37).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (370).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (371).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (372).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (373).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (374).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (376).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (378).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (379).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (38).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (380).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (381).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (382).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (384).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (385).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (386).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (387).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (388).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (39).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (390).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (391).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (392).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (393).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (394).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (395).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (396).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (397).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (398).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (399).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (4).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (40).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (400).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (401).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (402).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (403).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (404).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (405).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (406).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (407).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (408).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (41).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (410).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (412).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (413).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (414).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (416).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (417).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (419).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (422).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (423).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (424).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (425).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (426).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (427).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (428).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (429).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (43).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (431).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (432).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (433).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (434).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (435).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (436).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (437).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (439).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (44).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (440).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (443).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (444).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (445).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (447).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (45).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (450).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (451).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (452).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (453).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (454).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (456).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (457).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (458).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (459).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (46).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (463).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (464).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (466).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (467).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (468).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (47).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (470).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (471).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (472).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (473).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (474).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (476).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (477).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (478).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (479).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (48).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (480).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (481).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (482).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (483).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (484).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (485).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (486).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (487).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (488).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (489).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (49).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (490).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (491).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (493).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (494).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (495).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (496).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (497).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (498).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (499).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (5).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (50).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (500).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (501).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (503).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (504).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (505).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (506).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (507).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (508).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (509).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (51).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (510).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (511).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (512).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (513).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (514).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (515).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (516).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (517).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (519).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (52).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (520).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (521).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (522).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (523).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (524).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (525).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (527).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (528).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (529).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (53).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (530).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (531).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (532).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (533).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (534).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (535).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (536).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (537).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (538).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (539).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (54).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (540).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (541).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (542).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (543).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (544).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (545).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (546).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (547).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (548).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (549).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (55).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (551).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (552).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (554).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (555).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (556).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (560).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (562).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (566).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (567).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (57).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (570).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (571).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (574).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (575).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (576).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (578).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (579).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (58).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (580).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (582).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (584).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (585).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (586).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (588).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (591).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (593).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (594).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (595).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (596).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (599).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (6).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (60).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (600).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (601).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (602).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (603).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (604).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (605).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (606).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (607).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (608).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (61).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (610).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (612).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (613).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (614).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (615).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (616).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (617).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (618).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (619).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (62).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (620).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (621).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (622).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (623).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (624).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (625).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (626).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (627).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (628).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (629).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (63).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (630).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (631).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (632).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (634).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (635).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (636).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (637).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (638).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (639).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (64).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (640).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (641).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (643).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (644).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (646).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (647).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (649).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (65).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (650).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (651).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (652).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (653).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (654).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (655).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (656).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (657).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (658).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (659).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (66).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (660).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (661).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (664).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (665).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (666).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (667).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (668).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (669).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (67).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (670).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (671).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (675).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (677).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (678).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (679).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (68).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (680).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (681).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (682).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (683).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (684).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (686).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (687).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (689).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (69).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (690).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (7).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (70).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (71).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (72).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (74).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (75).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (77).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (78).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (79).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (8).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (80).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (81).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (85).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (86).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (87).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (88).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (89).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (9).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (90).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (93).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day (94).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (95).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day (96).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(691).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(692).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(693).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(694).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(695).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(696).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(697).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(698).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(699).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(700).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(701).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(702).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(703).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(704).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(705).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(706).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(707).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(708).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(709).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(710).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(711).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(712).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(713).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(714).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(715).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(716).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(717).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(718).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(719).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(720).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(721).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(722).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(723).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(724).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(725).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(726).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(727).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(728).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(729).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(730).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(731).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(732).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(733).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(734).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(735).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(736).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(737).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(738).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(739).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(740).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(741).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(742).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(743).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(744).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(745).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(746).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(747).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(748).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(749).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(750).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(751).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(752).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(753).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(754).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(755).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(756).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(757).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(758).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(759).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(760).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(761).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(762).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(763).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(764).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(765).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(766).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(767).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(768).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(769).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(770).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(771).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(772).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(773).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(774).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(775).txt  \n",
            " extracting: dataset/labels/train/Sunny-Day(776).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(777).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(778).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(779).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(780).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(781).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(782).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(783).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(784).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(785).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(786).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(787).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(788).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(789).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(790).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(791).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(792).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(793).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(794).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(795).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(796).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(797).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(798).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(799).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(800).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(801).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(802).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(803).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(804).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(805).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(806).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(807).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(808).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(809).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(810).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(811).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(812).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(813).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(814).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(815).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(816).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(817).txt  \n",
            "  inflating: dataset/labels/train/Sunny-Day(818).txt  \n",
            "  inflating: dataset/labels/train.cache  \n",
            "   creating: dataset/labels/val/\n",
            "  inflating: dataset/labels/val/label-class-counter.py  \n",
            "  inflating: dataset/labels/val/night (651).txt  \n",
            "  inflating: dataset/labels/val/night (652).txt  \n",
            "  inflating: dataset/labels/val/night (653).txt  \n",
            "  inflating: dataset/labels/val/night (654).txt  \n",
            "  inflating: dataset/labels/val/night (655).txt  \n",
            "  inflating: dataset/labels/val/night (656).txt  \n",
            "  inflating: dataset/labels/val/night (657).txt  \n",
            "  inflating: dataset/labels/val/night (658).txt  \n",
            "  inflating: dataset/labels/val/night (659).txt  \n",
            "  inflating: dataset/labels/val/night (660).txt  \n",
            "  inflating: dataset/labels/val/night (661).txt  \n",
            "  inflating: dataset/labels/val/night (662).txt  \n",
            "  inflating: dataset/labels/val/night (663).txt  \n",
            "  inflating: dataset/labels/val/night (664).txt  \n",
            "  inflating: dataset/labels/val/night (665).txt  \n",
            "  inflating: dataset/labels/val/night (666).txt  \n",
            "  inflating: dataset/labels/val/night (667).txt  \n",
            "  inflating: dataset/labels/val/night (668).txt  \n",
            "  inflating: dataset/labels/val/night (669).txt  \n",
            "  inflating: dataset/labels/val/night (670).txt  \n",
            "  inflating: dataset/labels/val/night (671).txt  \n",
            "  inflating: dataset/labels/val/night (672).txt  \n",
            "  inflating: dataset/labels/val/night (673).txt  \n",
            "  inflating: dataset/labels/val/night (674).txt  \n",
            "  inflating: dataset/labels/val/night (675).txt  \n",
            "  inflating: dataset/labels/val/night (676).txt  \n",
            "  inflating: dataset/labels/val/night (677).txt  \n",
            "  inflating: dataset/labels/val/night (678).txt  \n",
            "  inflating: dataset/labels/val/night (679).txt  \n",
            "  inflating: dataset/labels/val/night (680).txt  \n",
            "  inflating: dataset/labels/val/night (681).txt  \n",
            "  inflating: dataset/labels/val/night (682).txt  \n",
            "  inflating: dataset/labels/val/night (683).txt  \n",
            "  inflating: dataset/labels/val/night (684).txt  \n",
            "  inflating: dataset/labels/val/night (685).txt  \n",
            "  inflating: dataset/labels/val/night (686).txt  \n",
            "  inflating: dataset/labels/val/night (687).txt  \n",
            "  inflating: dataset/labels/val/night (688).txt  \n",
            "  inflating: dataset/labels/val/night (689).txt  \n",
            "  inflating: dataset/labels/val/night (690).txt  \n",
            "  inflating: dataset/labels/val/night (691).txt  \n",
            "  inflating: dataset/labels/val/night (692).txt  \n",
            "  inflating: dataset/labels/val/night (693).txt  \n",
            "  inflating: dataset/labels/val/night (694).txt  \n",
            "  inflating: dataset/labels/val/night (695).txt  \n",
            "  inflating: dataset/labels/val/night (696).txt  \n",
            "  inflating: dataset/labels/val/night (697).txt  \n",
            "  inflating: dataset/labels/val/night (698).txt  \n",
            "  inflating: dataset/labels/val/night (699).txt  \n",
            "  inflating: dataset/labels/val/night (700).txt  \n",
            "  inflating: dataset/labels/val/rainy day (651).txt  \n",
            "  inflating: dataset/labels/val/rainy day (652).txt  \n",
            "  inflating: dataset/labels/val/rainy day (653).txt  \n",
            "  inflating: dataset/labels/val/rainy day (654).txt  \n",
            "  inflating: dataset/labels/val/rainy day (655).txt  \n",
            "  inflating: dataset/labels/val/rainy day (656).txt  \n",
            "  inflating: dataset/labels/val/rainy day (657).txt  \n",
            "  inflating: dataset/labels/val/rainy day (658).txt  \n",
            "  inflating: dataset/labels/val/rainy day (659).txt  \n",
            "  inflating: dataset/labels/val/rainy day (660).txt  \n",
            "  inflating: dataset/labels/val/rainy day (661).txt  \n",
            "  inflating: dataset/labels/val/rainy day (662).txt  \n",
            "  inflating: dataset/labels/val/rainy day (663).txt  \n",
            "  inflating: dataset/labels/val/rainy day (664).txt  \n",
            "  inflating: dataset/labels/val/rainy day (665).txt  \n",
            "  inflating: dataset/labels/val/rainy day (666).txt  \n",
            "  inflating: dataset/labels/val/rainy day (667).txt  \n",
            "  inflating: dataset/labels/val/rainy day (668).txt  \n",
            "  inflating: dataset/labels/val/rainy day (669).txt  \n",
            "  inflating: dataset/labels/val/rainy day (670).txt  \n",
            "  inflating: dataset/labels/val/rainy day (671).txt  \n",
            "  inflating: dataset/labels/val/rainy day (672).txt  \n",
            "  inflating: dataset/labels/val/rainy day (673).txt  \n",
            "  inflating: dataset/labels/val/rainy day (674).txt  \n",
            "  inflating: dataset/labels/val/rainy day (675).txt  \n",
            "  inflating: dataset/labels/val/rainy day (676).txt  \n",
            "  inflating: dataset/labels/val/rainy day (677).txt  \n",
            "  inflating: dataset/labels/val/rainy day (678).txt  \n",
            "  inflating: dataset/labels/val/rainy day (679).txt  \n",
            "  inflating: dataset/labels/val/rainy day (680).txt  \n",
            "  inflating: dataset/labels/val/rainy day (681).txt  \n",
            "  inflating: dataset/labels/val/rainy day (682).txt  \n",
            "  inflating: dataset/labels/val/rainy day (683).txt  \n",
            "  inflating: dataset/labels/val/rainy day (684).txt  \n",
            "  inflating: dataset/labels/val/rainy day (685).txt  \n",
            "  inflating: dataset/labels/val/rainy day (686).txt  \n",
            "  inflating: dataset/labels/val/rainy day (687).txt  \n",
            "  inflating: dataset/labels/val/rainy day (688).txt  \n",
            "  inflating: dataset/labels/val/rainy day (689).txt  \n",
            "  inflating: dataset/labels/val/rainy day (690).txt  \n",
            "  inflating: dataset/labels/val/rainy day (691).txt  \n",
            "  inflating: dataset/labels/val/rainy day (692).txt  \n",
            "  inflating: dataset/labels/val/rainy day (693).txt  \n",
            "  inflating: dataset/labels/val/rainy day (694).txt  \n",
            "  inflating: dataset/labels/val/rainy day (695).txt  \n",
            "  inflating: dataset/labels/val/rainy day (696).txt  \n",
            "  inflating: dataset/labels/val/rainy day (697).txt  \n",
            "  inflating: dataset/labels/val/rainy day (698).txt  \n",
            "  inflating: dataset/labels/val/rainy day (699).txt  \n",
            "  inflating: dataset/labels/val/rainy day (700).txt  \n",
            "  inflating: dataset/labels/val/rainynight (651).txt  \n",
            "  inflating: dataset/labels/val/rainynight (652).txt  \n",
            "  inflating: dataset/labels/val/rainynight (653).txt  \n",
            "  inflating: dataset/labels/val/rainynight (654).txt  \n",
            "  inflating: dataset/labels/val/rainynight (655).txt  \n",
            "  inflating: dataset/labels/val/rainynight (656).txt  \n",
            "  inflating: dataset/labels/val/rainynight (657).txt  \n",
            "  inflating: dataset/labels/val/rainynight (658).txt  \n",
            "  inflating: dataset/labels/val/rainynight (659).txt  \n",
            "  inflating: dataset/labels/val/rainynight (660).txt  \n",
            "  inflating: dataset/labels/val/rainynight (661).txt  \n",
            "  inflating: dataset/labels/val/rainynight (662).txt  \n",
            "  inflating: dataset/labels/val/rainynight (663).txt  \n",
            "  inflating: dataset/labels/val/rainynight (664).txt  \n",
            "  inflating: dataset/labels/val/rainynight (665).txt  \n",
            "  inflating: dataset/labels/val/rainynight (666).txt  \n",
            "  inflating: dataset/labels/val/rainynight (667).txt  \n",
            "  inflating: dataset/labels/val/rainynight (668).txt  \n",
            "  inflating: dataset/labels/val/rainynight (669).txt  \n",
            "  inflating: dataset/labels/val/rainynight (670).txt  \n",
            "  inflating: dataset/labels/val/rainynight (671).txt  \n",
            "  inflating: dataset/labels/val/rainynight (672).txt  \n",
            "  inflating: dataset/labels/val/rainynight (673).txt  \n",
            "  inflating: dataset/labels/val/rainynight (674).txt  \n",
            "  inflating: dataset/labels/val/rainynight (675).txt  \n",
            "  inflating: dataset/labels/val/rainynight (676).txt  \n",
            "  inflating: dataset/labels/val/rainynight (677).txt  \n",
            "  inflating: dataset/labels/val/rainynight (678).txt  \n",
            "  inflating: dataset/labels/val/rainynight (679).txt  \n",
            "  inflating: dataset/labels/val/rainynight (680).txt  \n",
            "  inflating: dataset/labels/val/rainynight (681).txt  \n",
            "  inflating: dataset/labels/val/rainynight (682).txt  \n",
            "  inflating: dataset/labels/val/rainynight (683).txt  \n",
            "  inflating: dataset/labels/val/rainynight (684).txt  \n",
            "  inflating: dataset/labels/val/rainynight (685).txt  \n",
            "  inflating: dataset/labels/val/rainynight (686).txt  \n",
            "  inflating: dataset/labels/val/rainynight (687).txt  \n",
            "  inflating: dataset/labels/val/rainynight (688).txt  \n",
            "  inflating: dataset/labels/val/rainynight (689).txt  \n",
            "  inflating: dataset/labels/val/rainynight (690).txt  \n",
            "  inflating: dataset/labels/val/rainynight (691).txt  \n",
            "  inflating: dataset/labels/val/rainynight (692).txt  \n",
            "  inflating: dataset/labels/val/rainynight (693).txt  \n",
            "  inflating: dataset/labels/val/rainynight (694).txt  \n",
            "  inflating: dataset/labels/val/rainynight (695).txt  \n",
            "  inflating: dataset/labels/val/rainynight (696).txt  \n",
            "  inflating: dataset/labels/val/rainynight (697).txt  \n",
            "  inflating: dataset/labels/val/rainynight (698).txt  \n",
            "  inflating: dataset/labels/val/rainynight (699).txt  \n",
            "  inflating: dataset/labels/val/rainynight (700).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (1).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (10).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (11).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (12).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (13).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (14).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (15).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (16).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (17).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (18).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (19).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (2).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (20).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (21).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (22).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (23).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (24).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (25).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (26).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (27).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (28).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (29).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (3).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (30).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (31).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (32).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (33).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (34).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (35).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (36).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (37).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (38).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (39).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (4).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (40).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (41).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (42).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (43).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (44).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (45).txt  \n",
            " extracting: dataset/labels/val/sunnayday1 (46).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (47).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (48).txt  \n",
            " extracting: dataset/labels/val/sunnayday1 (49).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (5).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (50).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (6).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (7).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (8).txt  \n",
            "  inflating: dataset/labels/val/sunnayday1 (9).txt  \n",
            "  inflating: dataset/labels/val.cache  \n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.56-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 ultralytics-8.2.56 ultralytics-thop-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### USING OPTUNA TO TUNE LEARNING RATE AND NUMBER OF EPOCHS (primary focus)"
      ],
      "metadata": {
        "id": "vT3VGTJW4NCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USING SDG OPTIMIZER (best result 0.527 mAP50 and 0.267 mAP50-95), LATER IMPROVED BY USING ADAM OPTIMIZER"
      ],
      "metadata": {
        "id": "s3kKI63Z4UPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to optimize\n",
        "    hyperparameters = {\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-6, 1e-2),\n",
        "        \"epochs\": trial.suggest_int(\"epochs\", 5, 10),\n",
        "        'batch_size': trial.suggest_categorical('batch_size', [8, 16]),\n",
        "        'img_size': trial.suggest_categorical('img_size', [416, 512, 640]),\n",
        "        'warmup_epochs': trial.suggest_int('warmup_epochs', 0, 3),\n",
        "        'fliplr': trial.suggest_uniform('fliplr', 0.0, 0.5),\n",
        "        'mosaic': trial.suggest_uniform('mosaic', 0.0, 1.0),\n",
        "    }\n",
        "\n",
        "    # Create the model\n",
        "    model = YOLO('yolov10m.pt')  # or 'yolov8n.pt' for a pretrained model\n",
        "\n",
        "    # Train the model\n",
        "    results = model.train(\n",
        "        data='data.yaml',\n",
        "        epochs=hyperparameters['epochs'],\n",
        "        imgsz=hyperparameters['img_size'],\n",
        "        batch=hyperparameters['batch_size'],\n",
        "        lr0=hyperparameters['learning_rate'],\n",
        "        warmup_epochs=hyperparameters['warmup_epochs'],\n",
        "        fliplr=hyperparameters['fliplr'],\n",
        "        mosaic=hyperparameters['mosaic'],\n",
        "        optimizer='SGD',\n",
        "    )\n",
        "\n",
        "    # source_folder = '/content/runs'\n",
        "    # destination_folder = '/content/drive/My Drive/ML/runs'\n",
        "\n",
        "    # # Check if the destination folder already exists\n",
        "    # if os.path.exists(destination_folder):\n",
        "    #     # Remove the existing folder in Google Drive to avoid conflicts\n",
        "    #     shutil.rmtree(destination_folder)\n",
        "\n",
        "    # # Copy the updated 'runs' folder to Google Drive\n",
        "    # shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "    # # Print a success message\n",
        "    # print(f\"The 'runs' folder has been successfully updated in {destination_folder} in Google Drive.\")\n",
        "\n",
        "    # Get the best mAP value\n",
        "    best_map = results.results_dict['metrics/mAP50-95(B)']\n",
        "\n",
        "    # Save the best model\n",
        "    if best_map > objective.best_value:\n",
        "        objective.best_value = best_map\n",
        "        print(f\"BEST in {trial.number}\")\n",
        "        model.save(f'best_model_951_{trial.number}.pt')\n",
        "\n",
        "    return best_map\n",
        "\n",
        "def main():\n",
        "    # Initialize best_value attribute\n",
        "    objective.best_value = 0\n",
        "\n",
        "    # Create a study object and optimize the objective function\n",
        "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(),study_name='example-study', storage='sqlite:///example.db', load_if_exists=True)\n",
        "    study.optimize(objective, n_trials=5)  # Reduced number of trials\n",
        "\n",
        "    print('Best trial:')\n",
        "    trial = study.best_trial\n",
        "    print('  Value: ', trial.value)\n",
        "    print('  Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    # Load and return the best model\n",
        "    best_model_path = f'best_model_{trial.number}.pt'\n",
        "    if os.path.exists(best_model_path):\n",
        "        best_model = YOLO(best_model_path)\n",
        "        print(f\"Best model loaded from {best_model_path}\")\n",
        "    else:\n",
        "        print(\"Best model file not found.\")\n",
        "if __name__ =='__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ9DMYl0YnPo",
        "outputId": "03e2b7a2-1f2d-4f56-ed42-4497ee74933a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 18:20:05,541] Using an existing study with name 'example-study' instead of creating a new one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0005571359139922319, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=2, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.2552470652868386, bgr=0.0, mosaic=0.1338469059025429, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0005571359139922319, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train4\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5      5.13G      4.153      7.059      2.539         44        416: 100%|██████████| 163/163 [01:22<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:06<00:00,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199       0.36      0.116      0.132     0.0668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/5      4.98G      3.897      3.856      2.403         36        416: 100%|██████████| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.321      0.191      0.214      0.101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/5      5.01G       3.77      3.142       2.36         49        416: 100%|██████████| 163/163 [01:15<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.505      0.335      0.373      0.189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/5      4.99G      3.688      2.749       2.32         57        416: 100%|██████████| 163/163 [01:14<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.542      0.402      0.407      0.222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/5      5.02G      3.641      2.593        2.3         67        416: 100%|██████████| 163/163 [01:15<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.565      0.411      0.434       0.23\n",
            "\n",
            "5 epochs completed in 0.122 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16,466,596 parameters, 0 gradients, 63.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:07<00:00,  1.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.567       0.41      0.434       0.23\n",
            "                   car        159        743      0.616      0.784       0.76      0.367\n",
            "                  bike         99        125       0.47      0.696      0.689      0.386\n",
            "                  auto         47         60      0.272        0.2      0.168     0.0738\n",
            "                 cycle         29         46      0.431      0.087      0.209     0.0844\n",
            "                   bus         48         52        0.5      0.442      0.491      0.231\n",
            "             minitruck         54         58      0.747      0.356      0.407      0.226\n",
            "                 truck         32         47      0.575      0.574      0.556      0.282\n",
            "                   van         25         28      0.157     0.0714     0.0537      0.025\n",
            "                  taxi         10         10      0.899      0.894      0.886       0.55\n",
            "                  toto         28         30          1          0       0.12     0.0701\n",
            "Speed: 0.2ms preprocess, 4.4ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "BEST in 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 18:27:56,793] Trial 3 finished with value: 0.22953712030232484 and parameters: {'learning_rate': 0.0005571359139922319, 'epochs': 5, 'batch_size': 16, 'img_size': 416, 'warmup_epochs': 2, 'fliplr': 0.2552470652868386, 'mosaic': 0.1338469059025429}. Best is trial 0 with value: 0.2670423989589354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0004998309118968842, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.07765986456331364, bgr=0.0, mosaic=0.5138057920239044, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train5/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0004998309118968842, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5      6.17G      4.002       8.25       2.75         67        640: 100%|██████████| 325/325 [02:02<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:07<00:00,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.534       0.13      0.164     0.0799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/5      5.97G      3.703      3.601      2.541         69        640: 100%|██████████| 325/325 [02:01<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.339      0.352      0.349      0.181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/5      5.97G      3.598      2.942      2.495         46        640: 100%|██████████| 325/325 [02:02<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.542      0.352      0.417      0.221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/5      5.94G      3.541      2.669      2.489         58        640: 100%|██████████| 325/325 [02:01<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.458       0.42       0.46       0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/5      5.98G      3.509      2.509      2.469         76        640: 100%|██████████| 325/325 [02:02<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.485      0.461      0.473      0.259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5 epochs completed in 0.204 hours.\n",
            "Optimizer stripped from runs/detect/train5/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train5/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train5/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16,466,596 parameters, 0 gradients, 63.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:12<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.486       0.46      0.473      0.261\n",
            "                   car        159        743      0.629      0.872      0.839      0.429\n",
            "                  bike         99        125      0.578      0.769      0.767      0.466\n",
            "                  auto         47         60      0.456      0.322      0.362      0.185\n",
            "                 cycle         29         46      0.324       0.13      0.249     0.0763\n",
            "                   bus         48         52      0.383      0.577      0.456      0.182\n",
            "             minitruck         54         58      0.498      0.224      0.263      0.128\n",
            "                 truck         32         47      0.685      0.462      0.597      0.368\n",
            "                   van         25         28      0.312      0.214      0.139     0.0753\n",
            "                  taxi         10         10      0.572          1      0.944       0.64\n",
            "                  toto         28         30      0.424     0.0282      0.114     0.0565\n",
            "Speed: 0.5ms preprocess, 11.1ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train5\u001b[0m\n",
            "BEST in 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 18:40:44,375] Trial 4 finished with value: 0.26057179365016003 and parameters: {'learning_rate': 0.0004998309118968842, 'epochs': 5, 'batch_size': 8, 'img_size': 640, 'warmup_epochs': 0, 'fliplr': 0.07765986456331364, 'mosaic': 0.5138057920239044}. Best is trial 0 with value: 0.2670423989589354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=5, time=None, patience=100, batch=8, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00013167141872407804, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.33710103206883374, bgr=0.0, mosaic=0.8670007069807509, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train6/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.00013167141872407804, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train6\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/5      4.29G        4.1      8.186      2.651        109        512: 100%|██████████| 325/325 [01:49<00:00,  2.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.206     0.0833     0.0785     0.0374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/5         4G      4.009      5.215      2.618         77        512: 100%|██████████| 325/325 [01:43<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  3.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.447      0.108      0.125     0.0611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/5      4.03G      3.899      4.402      2.548         48        512: 100%|██████████| 325/325 [01:42<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  3.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.335      0.117      0.174     0.0901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/5      3.99G      3.863      3.925       2.52         92        512: 100%|██████████| 325/325 [01:42<00:00,  3.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.305      0.205      0.213      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/5      4.04G      3.814      3.681      2.492        122        512: 100%|██████████| 325/325 [01:44<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  4.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.256      0.229      0.236      0.116\n",
            "\n",
            "5 epochs completed in 0.171 hours.\n",
            "Optimizer stripped from runs/detect/train6/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train6/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train6/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16,466,596 parameters, 0 gradients, 63.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:09<00:00,  1.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.258       0.23      0.237      0.116\n",
            "                   car        159        743      0.498      0.816       0.71      0.336\n",
            "                  bike         99        125      0.367      0.648       0.58      0.342\n",
            "                  auto         47         60      0.104       0.15      0.101     0.0352\n",
            "                 cycle         29         46      0.176      0.033     0.0407     0.0134\n",
            "                   bus         48         52      0.321      0.272      0.235       0.06\n",
            "             minitruck         54         58      0.421     0.0145      0.157     0.0868\n",
            "                 truck         32         47      0.697      0.362      0.514      0.268\n",
            "                   van         25         28          0          0     0.0114    0.00561\n",
            "                  taxi         10         10          0          0     0.0181     0.0105\n",
            "                  toto         28         30          0          0   0.000333   0.000166\n",
            "Speed: 0.3ms preprocess, 7.1ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train6\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 18:51:34,190] Trial 5 finished with value: 0.11572404810508431 and parameters: {'learning_rate': 0.00013167141872407804, 'epochs': 5, 'batch_size': 8, 'img_size': 512, 'warmup_epochs': 3, 'fliplr': 0.33710103206883374, 'mosaic': 0.8670007069807509}. Best is trial 0 with value: 0.2670423989589354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=8, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=5.3835214661932546e-05, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=2, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.39292229503269976, bgr=0.0, mosaic=0.31680495547311016, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train7', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train7/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=5.3835214661932546e-05, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_folder = '/content/runs'\n",
        "destination_folder = '/content/drive/MyDrive/ML/runs'\n",
        "\n",
        "# Check if the destination folder already exists\n",
        "if os.path.exists(destination_folder):\n",
        "    # Remove the existing folder in Google Drive to avoid conflicts\n",
        "    shutil.rmtree(destination_folder)\n",
        "\n",
        "# Copy the updated 'runs' folder to Google Drive\n",
        "shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "# Print a success message\n",
        "print(f\"The 'runs' folder has been successfully updated in {destination_folder} in Google Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIAIIJvqnfNq",
        "outputId": "a747bb84-4786-4c68-bf35-1b8bd4a2e220"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 'runs' folder has been successfully updated in /content/drive/MyDrive/ML/runs in Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING WITH ADAM OPTIMIZER"
      ],
      "metadata": {
        "id": "6Mx_rlBt4wyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to optimize\n",
        "    hyperparameters = {\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-2),\n",
        "        \"epochs\": trial.suggest_int(\"epochs\", 5, 10),\n",
        "        'batch_size': trial.suggest_categorical('batch_size', [8, 16]),\n",
        "        'img_size': trial.suggest_categorical('img_size', [416, 512, 640]),\n",
        "        'fliplr': trial.suggest_uniform('fliplr', 0.0, 0.5),\n",
        "        'mosaic': trial.suggest_uniform('mosaic', 0.0, 1.0),\n",
        "    }\n",
        "\n",
        "    # Create the model\n",
        "    model = YOLO('yolov10m.pt')  # or 'yolov8n.pt' for a pretrained model\n",
        "\n",
        "    # Train the model\n",
        "    results = model.train(\n",
        "        data='data.yaml',\n",
        "        epochs=hyperparameters['epochs'],\n",
        "        imgsz=hyperparameters['img_size'],\n",
        "        batch=hyperparameters['batch_size'],\n",
        "        lr0=hyperparameters['learning_rate'],\n",
        "        fliplr=hyperparameters['fliplr'],\n",
        "        mosaic=hyperparameters['mosaic'],\n",
        "        optimizer='Adam',\n",
        "    )\n",
        "\n",
        "    # source_folder = '/content/runs'\n",
        "    # destination_folder = '/content/drive/My Drive/ML/runs'\n",
        "\n",
        "    # # Check if the destination folder already exists\n",
        "    # if os.path.exists(destination_folder):\n",
        "    #     # Remove the existing folder in Google Drive to avoid conflicts\n",
        "    #     shutil.rmtree(destination_folder)\n",
        "\n",
        "    # # Copy the updated 'runs' folder to Google Drive\n",
        "    # shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "    # # Print a success message\n",
        "    # print(f\"The 'runs' folder has been successfully updated in {destination_folder} in Google Drive.\")\n",
        "\n",
        "    # Get the best mAP value\n",
        "    best_map = results.results_dict['metrics/mAP50-95(B)']\n",
        "\n",
        "    # Save the best model\n",
        "    if best_map > objective.best_value:\n",
        "        objective.best_value = best_map\n",
        "        print(f\"BEST in {trial.number}\")\n",
        "        model.save(f'best_model_952_{trial.number}.pt')\n",
        "\n",
        "    return best_map\n",
        "\n",
        "def main():\n",
        "    # Initialize best_value attribute\n",
        "    objective.best_value = 0\n",
        "\n",
        "    # Create a study object and optimize the objective function\n",
        "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(),study_name='example-study', storage='sqlite:///example.db', load_if_exists=True)\n",
        "    study.optimize(objective, n_trials=5)  # Reduced number of trials\n",
        "\n",
        "    print('Best trial:')\n",
        "    trial = study.best_trial\n",
        "    print('  Value: ', trial.value)\n",
        "    print('  Params: ')\n",
        "    for key, value in trial.params.items():\n",
        "        print('    {}: {}'.format(key, value))\n",
        "\n",
        "    # Load and return the best model\n",
        "    best_model_path = f'best_model_{trial.number}.pt'\n",
        "    if os.path.exists(best_model_path):\n",
        "        best_model = YOLO(best_model_path)\n",
        "        print(f\"Best model loaded from {best_model_path}\")\n",
        "    else:\n",
        "        print(\"Best model file not found.\")\n",
        "if __name__ =='__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpcKPcdunoC_",
        "outputId": "a3636e33-515a-4d95-b40b-a3c2a38eb39d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 19:05:06,355] Using an existing study with name 'example-study' instead of creating a new one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001195036443658167, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.03945966344522073, bgr=0.0, mosaic=0.6419103521344854, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train9\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train9', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train9/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001195036443658167, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train9\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      4.35G      4.263      4.638      2.668         63        416: 100%|██████████| 163/163 [01:23<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:07<00:00,  1.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.368      0.151      0.136     0.0557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      4.28G      4.292      3.533      2.758         44        416: 100%|██████████| 163/163 [01:15<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.525      0.133      0.106     0.0396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10       4.3G      4.248      3.293      2.729         57        416: 100%|██████████| 163/163 [01:14<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.432      0.173      0.147      0.061\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      4.29G      4.162      3.106      2.686         58        416: 100%|██████████| 163/163 [01:15<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.202      0.204      0.191     0.0885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      4.27G      4.012      2.761      2.611         39        416: 100%|██████████| 163/163 [01:14<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199       0.43      0.287       0.29       0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      4.32G      3.918      2.546      2.552         51        416: 100%|██████████| 163/163 [01:14<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.373      0.263      0.299      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      4.25G      3.818      2.383      2.496         78        416: 100%|██████████| 163/163 [01:14<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.532      0.319      0.348      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      4.29G      3.748      2.196      2.458         54        416: 100%|██████████| 163/163 [01:13<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.441      0.346      0.371       0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      4.27G      3.617      2.048       2.41         61        416: 100%|██████████| 163/163 [01:15<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.758      0.286      0.382      0.188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      4.29G      3.537      1.928      2.362         50        416: 100%|██████████| 163/163 [01:14<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199       0.46      0.339      0.403      0.207\n",
            "\n",
            "10 epochs completed in 0.235 hours.\n",
            "Optimizer stripped from runs/detect/train9/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train9/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train9/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16,466,596 parameters, 0 gradients, 63.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:10<00:00,  1.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.461      0.338      0.403      0.207\n",
            "                   car        159        743      0.637      0.735       0.74      0.357\n",
            "                  bike         99        125      0.609      0.672      0.667      0.387\n",
            "                  auto         47         60      0.541      0.317      0.375      0.172\n",
            "                 cycle         29         46      0.319      0.109     0.0871     0.0523\n",
            "                   bus         48         52      0.692      0.558      0.548      0.265\n",
            "             minitruck         54         58      0.266      0.069     0.0831     0.0345\n",
            "                 truck         32         47      0.901      0.194      0.573      0.297\n",
            "                   van         25         28          0          0     0.0648     0.0227\n",
            "                  taxi         10         10      0.644      0.725      0.783      0.421\n",
            "                  toto         28         30          0          0      0.108     0.0574\n",
            "Speed: 0.2ms preprocess, 7.5ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train9\u001b[0m\n",
            "BEST in 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 19:19:41,462] Trial 9 finished with value: 0.20650130290448973 and parameters: {'learning_rate': 0.001195036443658167, 'epochs': 10, 'batch_size': 16, 'img_size': 416, 'fliplr': 0.03945966344522073, 'mosaic': 0.6419103521344854}. Best is trial 0 with value: 0.2670423989589354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=8, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.005497070627229782, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.42167734304640253, bgr=0.0, mosaic=0.8690012466427148, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train10', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train10/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.005497070627229782, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train10\u001b[0m\n",
            "Starting training for 8 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/8      4.48G      4.676      5.087      2.939         74        416: 100%|██████████| 163/163 [01:24<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.154     0.0866     0.0199    0.00489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/8       4.3G       4.72      4.574      2.991         80        416: 100%|██████████| 163/163 [01:18<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.787     0.0888     0.0847     0.0228\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/8      4.31G      4.568      4.148      2.896         57        416: 100%|██████████| 163/163 [01:19<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199       0.33      0.181      0.118     0.0467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/8       4.3G      4.391      3.801      2.811         68        416: 100%|██████████| 163/163 [01:17<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.591      0.159      0.162     0.0688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/8      4.32G      4.298      3.516      2.734         92        416: 100%|██████████| 163/163 [01:15<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.209      0.222      0.202     0.0831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        6/8      4.33G      4.179      3.201       2.66         85        416: 100%|██████████| 163/163 [01:16<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.278      0.203      0.195     0.0763\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        7/8      4.27G      4.047      3.001      2.626         67        416: 100%|██████████| 163/163 [01:16<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.464      0.269      0.273      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        8/8      4.39G      3.932      2.794      2.575        146        416: 100%|██████████| 163/163 [01:17<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.404      0.272      0.306      0.134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "8 epochs completed in 0.201 hours.\n",
            "Optimizer stripped from runs/detect/train10/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train10/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train10/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16,466,596 parameters, 0 gradients, 63.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:10<00:00,  1.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.404      0.272      0.306      0.135\n",
            "                   car        159        743      0.602      0.634      0.655      0.291\n",
            "                  bike         99        125      0.403      0.508      0.437      0.212\n",
            "                  auto         47         60      0.412      0.283      0.336      0.157\n",
            "                 cycle         29         46      0.498      0.087     0.0689     0.0492\n",
            "                   bus         48         52      0.663      0.577      0.565      0.215\n",
            "             minitruck         54         58          0          0     0.0141    0.00552\n",
            "                 truck         32         47      0.676      0.133      0.323      0.133\n",
            "                   van         25         28          0          0     0.0363     0.0144\n",
            "                  taxi         10         10      0.785        0.5      0.589       0.25\n",
            "                  toto         28         30          0          0     0.0376     0.0194\n",
            "Speed: 1.2ms preprocess, 5.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train10\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 19:32:15,050] Trial 10 finished with value: 0.13456316556535872 and parameters: {'learning_rate': 0.005497070627229782, 'epochs': 8, 'batch_size': 16, 'img_size': 416, 'fliplr': 0.42167734304640253, 'mosaic': 0.8690012466427148}. Best is trial 0 with value: 0.2670423989589354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=6, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0005298704007012706, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.3917656381512565, bgr=0.0, mosaic=0.6501039120254829, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train11\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train11', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train11/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0005298704007012706, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train11\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/6      6.28G      4.024      4.347      2.588         54        512: 100%|██████████| 163/163 [01:36<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.626      0.268      0.281      0.139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/6      6.08G      3.955      3.057      2.635         80        512: 100%|██████████| 163/163 [01:28<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.631      0.272       0.31       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/6      6.08G      3.895      2.827      2.611         40        512: 100%|██████████| 163/163 [01:27<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.626      0.289       0.33      0.145\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/6      6.08G      3.809      2.576      2.569         86        512: 100%|██████████| 163/163 [01:26<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.463      0.331      0.396      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/6      6.11G       3.71      2.327      2.524         96        512: 100%|██████████| 163/163 [01:26<00:00,  1.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.464       0.36      0.404      0.196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        6/6      6.09G       3.61      2.099      2.481        115        512: 100%|██████████| 163/163 [01:24<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.534      0.388      0.469      0.234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "6 epochs completed in 0.182 hours.\n",
            "Optimizer stripped from runs/detect/train11/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train11/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train11/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16,466,596 parameters, 0 gradients, 63.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:09<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.537      0.387      0.469      0.234\n",
            "                   car        159        743      0.743      0.773      0.803      0.387\n",
            "                  bike         99        125       0.62      0.664      0.689       0.38\n",
            "                  auto         47         60      0.734      0.414      0.526      0.237\n",
            "                 cycle         29         46      0.354      0.087      0.141     0.0835\n",
            "                   bus         48         52      0.796      0.635      0.625      0.295\n",
            "             minitruck         54         58      0.321      0.069      0.136     0.0586\n",
            "                 truck         32         47      0.792      0.362      0.607      0.299\n",
            "                   van         25         28      0.202     0.0714     0.0894     0.0452\n",
            "                  taxi         10         10      0.805        0.8      0.871      0.466\n",
            "                  toto         28         30          0          0      0.208     0.0899\n",
            "Speed: 0.6ms preprocess, 7.1ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train11\u001b[0m\n",
            "BEST in 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 19:43:43,937] Trial 11 finished with value: 0.23423040602897086 and parameters: {'learning_rate': 0.0005298704007012706, 'epochs': 6, 'batch_size': 16, 'img_size': 512, 'fliplr': 0.3917656381512565, 'mosaic': 0.6501039120254829}. Best is trial 0 with value: 0.2670423989589354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=8, time=None, patience=100, batch=8, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0003422729959319013, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.013579357108739143, bgr=0.0, mosaic=0.0862606022494592, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train12\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train12', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train12/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0003422729959319013, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train12\u001b[0m\n",
            "Starting training for 8 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/8      3.51G      4.056      4.163      2.659         38        512: 100%|██████████| 325/325 [01:49<00:00,  2.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.708      0.131      0.176     0.0783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/8      3.29G      3.888      2.913      2.617         38        512: 100%|██████████| 325/325 [01:41<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.503      0.269      0.318      0.154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/8      3.36G      3.817      2.639      2.565         58        512: 100%|██████████| 325/325 [01:39<00:00,  3.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.391      0.283      0.307      0.146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/8      3.29G      3.736      2.356      2.541         53        512: 100%|██████████| 325/325 [01:40<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.434      0.357      0.356      0.175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/8      3.33G      3.636      2.146      2.504         74        512: 100%|██████████| 325/325 [01:40<00:00,  3.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.557      0.364      0.424      0.208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        6/8      3.34G      3.559      1.973      2.455         38        512: 100%|██████████| 325/325 [01:39<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:04<00:00,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.557      0.334      0.381      0.187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        7/8      3.35G      3.473      1.836       2.42         50        512: 100%|██████████| 325/325 [01:41<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.466      0.458       0.51      0.262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        8/8      3.34G      3.392      1.684      2.372         46        512: 100%|██████████| 325/325 [01:40<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:03<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199       0.53      0.493      0.544      0.274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "8 epochs completed in 0.264 hours.\n",
            "Optimizer stripped from runs/detect/train12/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train12/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train12/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16,466,596 parameters, 0 gradients, 63.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:12<00:00,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.531      0.493      0.544      0.273\n",
            "                   car        159        743      0.541      0.857      0.823      0.394\n",
            "                  bike         99        125      0.435      0.744      0.728      0.457\n",
            "                  auto         47         60      0.512      0.467      0.458      0.231\n",
            "                 cycle         29         46      0.284      0.109      0.108      0.068\n",
            "                   bus         48         52      0.705      0.689      0.726       0.32\n",
            "             minitruck         54         58      0.332      0.293      0.299      0.119\n",
            "                 truck         32         47      0.669      0.596      0.641      0.325\n",
            "                   van         25         28      0.224      0.179      0.152     0.0705\n",
            "                  taxi         10         10      0.751      0.602       0.73      0.391\n",
            "                  toto         28         30      0.857      0.399      0.771      0.359\n",
            "Speed: 0.2ms preprocess, 7.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train12\u001b[0m\n",
            "BEST in 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 20:00:02,285] Trial 12 finished with value: 0.27340935385702486 and parameters: {'learning_rate': 0.0003422729959319013, 'epochs': 8, 'batch_size': 8, 'img_size': 512, 'fliplr': 0.013579357108739143, 'mosaic': 0.0862606022494592}. Best is trial 12 with value: 0.27340935385702486.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New https://pypi.org/project/ultralytics/8.2.57 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov10m.pt, data=data.yaml, epochs=6, time=None, patience=100, batch=16, imgsz=512, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00043873738629791816, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.16772357173645847, bgr=0.0, mosaic=0.655474085609502, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train13\n",
            "Overriding model.yaml nc=80 with nc=14\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1     78720  ultralytics.nn.modules.block.SCDown          [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1    228672  ultralytics.nn.modules.block.SCDown          [384, 576, 3, 2]              \n",
            "  8                  -1  2   1689984  ultralytics.nn.modules.block.C2fCIB          [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1   1253088  ultralytics.nn.modules.block.PSA             [576, 576]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 17                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2    831744  ultralytics.nn.modules.block.C2fCIB          [576, 384, 2, True]           \n",
            " 20                  -1  1    152448  ultralytics.nn.modules.block.SCDown          [384, 384, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   1911168  ultralytics.nn.modules.block.C2fCIB          [960, 576, 2, True]           \n",
            " 23        [16, 19, 22]  1   2297188  ultralytics.nn.modules.head.v10Detect        [14, [192, 384, 576]]         \n",
            "YOLOv10m summary: 498 layers, 16,500,340 parameters, 16,500,324 gradients, 64.1 GFLOPs\n",
            "\n",
            "Transferred 787/799 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train13', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/dataset/images/train/rainy day (236).jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train13/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.00043873738629791816, momentum=0.937) with parameter groups 129 weight(decay=0.0), 142 weight(decay=0.0005), 141 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 512 train, 512 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train13\u001b[0m\n",
            "Starting training for 6 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/6       6.3G      3.975      4.246      2.566         54        512: 100%|██████████| 163/163 [01:33<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.226       0.23      0.245      0.122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/6      6.07G      3.899      2.942      2.579         80        512: 100%|██████████| 163/163 [01:28<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:05<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.569      0.269      0.336      0.171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/6       6.1G      3.843      2.669      2.563         63        512: 100%|██████████| 163/163 [01:25<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.506      0.321      0.347      0.158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        4/6      6.05G      3.735      2.437      2.514         64        512: 100%|██████████| 163/163 [01:24<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.415      0.353      0.377      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        5/6      6.03G      3.642      2.188       2.46         82        512: 100%|██████████| 163/163 [01:26<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.661      0.381      0.454      0.225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        6/6      6.05G      3.551      2.014      2.398         91        512: 100%|██████████| 163/163 [01:26<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.508      0.385      0.435      0.217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "6 epochs completed in 0.179 hours.\n",
            "Optimizer stripped from runs/detect/train13/weights/last.pt, 33.5MB\n",
            "Optimizer stripped from runs/detect/train13/weights/best.pt, 33.5MB\n",
            "\n",
            "Validating runs/detect/train13/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.56 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv10m summary (fused): 369 layers, 16,466,596 parameters, 0 gradients, 63.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:09<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200       1199      0.659       0.38      0.453      0.225\n",
            "                   car        159        743       0.72      0.791      0.798      0.367\n",
            "                  bike         99        125      0.595      0.416      0.459       0.24\n",
            "                  auto         47         60      0.479      0.433      0.426      0.171\n",
            "                 cycle         29         46      0.308     0.0652     0.0907     0.0502\n",
            "                   bus         48         52      0.791      0.581      0.675      0.325\n",
            "             minitruck         54         58      0.597      0.102      0.142      0.053\n",
            "                 truck         32         47      0.767      0.489      0.723      0.368\n",
            "                   van         25         28      0.334     0.0357     0.0996     0.0474\n",
            "                  taxi         10         10          1      0.886      0.902      0.547\n",
            "                  toto         28         30          1          0      0.219     0.0821\n",
            "Speed: 0.7ms preprocess, 7.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train13\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-14 20:11:14,776] Trial 13 finished with value: 0.2250185117159155 and parameters: {'learning_rate': 0.00043873738629791816, 'epochs': 6, 'batch_size': 16, 'img_size': 512, 'fliplr': 0.16772357173645847, 'mosaic': 0.655474085609502}. Best is trial 12 with value: 0.27340935385702486.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "  Value:  0.27340935385702486\n",
            "  Params: \n",
            "    learning_rate: 0.0003422729959319013\n",
            "    epochs: 8\n",
            "    batch_size: 8\n",
            "    img_size: 512\n",
            "    fliplr: 0.013579357108739143\n",
            "    mosaic: 0.0862606022494592\n",
            "Best model file not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_folder = '/content/runs'\n",
        "destination_folder = '/content/drive/MyDrive/ML/runs'\n",
        "\n",
        "# Check if the destination folder already exists\n",
        "if os.path.exists(destination_folder):\n",
        "    # Remove the existing folder in Google Drive to avoid conflicts\n",
        "    shutil.rmtree(destination_folder)\n",
        "\n",
        "# Copy the updated 'runs' folder to Google Drive\n",
        "shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "# Print a success message\n",
        "print(f\"The 'runs' folder has been successfully updated in {destination_folder} in Google Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40yefsNI34iC",
        "outputId": "2c0eb448-5b57-4dc5-b79b-8aba375a0c52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 'runs' folder has been successfully updated in /content/drive/MyDrive/ML/runs in Google Drive.\n"
          ]
        }
      ]
    }
  ]
}